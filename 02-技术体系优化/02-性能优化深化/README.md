# Goè¯­è¨€æ€§èƒ½ä¼˜åŒ–æ·±åŒ–

<!-- TOC START -->
- [Goè¯­è¨€æ€§èƒ½ä¼˜åŒ–æ·±åŒ–](#goè¯­è¨€æ€§èƒ½ä¼˜åŒ–æ·±åŒ–)
  - [1.1 âš¡ é›¶æ‹·è´æŠ€æœ¯](#11--é›¶æ‹·è´æŠ€æœ¯)
    - [1.1.1 é›¶æ‹·è´åŸç†](#111-é›¶æ‹·è´åŸç†)
    - [1.1.2 sendfileå®ç°](#112-sendfileå®ç°)
    - [1.1.3 spliceå®ç°](#113-spliceå®ç°)
  - [1.2 ğŸ§  å†…å­˜ä¼˜åŒ–](#12--å†…å­˜ä¼˜åŒ–)
    - [1.2.1 å¯¹è±¡æ± è®¾è®¡](#121-å¯¹è±¡æ± è®¾è®¡)
    - [1.2.2 å†…å­˜å¯¹é½ä¼˜åŒ–](#122-å†…å­˜å¯¹é½ä¼˜åŒ–)
    - [1.2.3 åƒåœ¾å›æ”¶ä¼˜åŒ–](#123-åƒåœ¾å›æ”¶ä¼˜åŒ–)
  - [1.3 ğŸ”„ å¹¶å‘ä¼˜åŒ–](#13--å¹¶å‘ä¼˜åŒ–)
    - [1.3.1 å·¥ä½œæ± ä¼˜åŒ–](#131-å·¥ä½œæ± ä¼˜åŒ–)
    - [1.3.2 æ— é”æ•°æ®ç»“æ„](#132-æ— é”æ•°æ®ç»“æ„)
  - [1.4 ğŸ“¡ I/Oä¼˜åŒ–](#14--ioä¼˜åŒ–)
    - [1.4.1 å¼‚æ­¥I/Oæ¨¡å¼](#141-å¼‚æ­¥ioæ¨¡å¼)
    - [1.4.2 æ‰¹é‡å¤„ç†ä¼˜åŒ–](#142-æ‰¹é‡å¤„ç†ä¼˜åŒ–)
  - [1.5 ğŸ“Š æ€§èƒ½ç›‘æ§](#15--æ€§èƒ½ç›‘æ§)
    - [1.5.1 å®æ—¶æ€§èƒ½ç›‘æ§](#151-å®æ—¶æ€§èƒ½ç›‘æ§)
    - [1.5.2 æ€§èƒ½åŸºå‡†æµ‹è¯•](#152-æ€§èƒ½åŸºå‡†æµ‹è¯•)
<!-- TOC END -->

## 1.1 âš¡ é›¶æ‹·è´æŠ€æœ¯

### 1.1.1 é›¶æ‹·è´åŸç†

**ä¼ ç»Ÿæ–‡ä»¶ä¼ è¾“**:

```
ç”¨æˆ·ç©ºé—´ â†â†’ å†…æ ¸ç©ºé—´ â†â†’ ç£ç›˜
    â†“         â†“
  æ•°æ®æ‹·è´   æ•°æ®æ‹·è´
```

**é›¶æ‹·è´ä¼ è¾“**:

```
ç”¨æˆ·ç©ºé—´ â†â†’ å†…æ ¸ç©ºé—´ â†â†’ ç£ç›˜
    â†“
  ç›´æ¥ä¼ è¾“
```

### 1.1.2 sendfileå®ç°

```go
package main

import (
    "fmt"
    "net"
    "os"
    "syscall"
)

// ZeroCopyFileServer é›¶æ‹·è´æ–‡ä»¶æœåŠ¡å™¨
type ZeroCopyFileServer struct {
    rootDir string
}

func NewZeroCopyFileServer(rootDir string) *ZeroCopyFileServer {
    return &ZeroCopyFileServer{rootDir: rootDir}
}

// sendFileZeroCopy é›¶æ‹·è´æ–‡ä»¶ä¼ è¾“
func (s *ZeroCopyFileServer) sendFileZeroCopy(conn net.Conn, file *os.File, size int64) error {
    // è·å–TCPè¿æ¥çš„æ–‡ä»¶æè¿°ç¬¦
    tcpConn, ok := conn.(*net.TCPConn)
    if !ok {
        return fmt.Errorf("unsupported connection type")
    }
    
    // è·å–æ–‡ä»¶æè¿°ç¬¦
    fileFd := int(file.Fd())
    connFd := int(tcpConn.Fd())
    
    // ä½¿ç”¨sendfileç³»ç»Ÿè°ƒç”¨å®ç°é›¶æ‹·è´
    written, err := syscall.Sendfile(connFd, fileFd, nil, int(size))
    if err != nil {
        return fmt.Errorf("sendfile failed: %w", err)
    }
    
    if int64(written) != size {
        return fmt.Errorf("incomplete transfer: %d/%d bytes", written, size)
    }
    
    return nil
}

// ServeFile æä¾›æ–‡ä»¶æœåŠ¡
func (s *ZeroCopyFileServer) ServeFile(conn net.Conn, filename string) error {
    filepath := s.rootDir + "/" + filename
    file, err := os.Open(filepath)
    if err != nil {
        return fmt.Errorf("failed to open file: %w", err)
    }
    defer file.Close()
    
    // è·å–æ–‡ä»¶ä¿¡æ¯
    stat, err := file.Stat()
    if err != nil {
        return fmt.Errorf("failed to get file stat: %w", err)
    }
    
    // å‘é€HTTPå“åº”å¤´
    header := fmt.Sprintf("HTTP/1.1 200 OK\r\nContent-Length: %d\r\n\r\n", stat.Size())
    _, err = conn.Write([]byte(header))
    if err != nil {
        return fmt.Errorf("failed to write header: %w", err)
    }
    
    // é›¶æ‹·è´ä¼ è¾“æ–‡ä»¶å†…å®¹
    return s.sendFileZeroCopy(conn, file, stat.Size())
}
```

### 1.1.3 spliceå®ç°

```go
// spliceZeroCopy ä½¿ç”¨spliceå®ç°é›¶æ‹·è´
func (s *ZeroCopyFileServer) spliceZeroCopy(conn net.Conn, file *os.File, size int64) error {
    // åˆ›å»ºç®¡é“
    r, w, err := os.Pipe()
    if err != nil {
        return fmt.Errorf("failed to create pipe: %w", err)
    }
    defer r.Close()
    defer w.Close()
    
    // ä½¿ç”¨spliceå°†æ–‡ä»¶æ•°æ®å†™å…¥ç®¡é“
    go func() {
        defer w.Close()
        syscall.Splice(int(file.Fd()), nil, int(w.Fd()), nil, int(size), 0)
    }()
    
    // ä½¿ç”¨spliceå°†ç®¡é“æ•°æ®å†™å…¥è¿æ¥
    tcpConn := conn.(*net.TCPConn)
    _, err = syscall.Splice(int(r.Fd()), nil, int(tcpConn.Fd()), nil, int(size), 0)
    
    return err
}
```

## 1.2 ğŸ§  å†…å­˜ä¼˜åŒ–

### 1.2.1 å¯¹è±¡æ± è®¾è®¡

```go
package main

import (
    "sync"
    "time"
)

// ObjectPool å¯¹è±¡æ± 
type ObjectPool[T any] struct {
    pool    sync.Pool
    factory func() T
    reset   func(T) T
}

// NewObjectPool åˆ›å»ºå¯¹è±¡æ± 
func NewObjectPool[T any](factory func() T, reset func(T) T) *ObjectPool[T] {
    return &ObjectPool[T]{
        factory: factory,
        reset:   reset,
        pool: sync.Pool{
            New: func() interface{} {
                return factory()
            },
        },
    }
}

// Get è·å–å¯¹è±¡
func (p *ObjectPool[T]) Get() T {
    obj := p.pool.Get().(T)
    if p.reset != nil {
        obj = p.reset(obj)
    }
    return obj
}

// Put å½’è¿˜å¯¹è±¡
func (p *ObjectPool[T]) Put(obj T) {
    p.pool.Put(obj)
}

// BufferPool ç¼“å†²åŒºæ± 
type BufferPool struct {
    pool sync.Pool
}

func NewBufferPool() *BufferPool {
    return &BufferPool{
        pool: sync.Pool{
            New: func() interface{} {
                return make([]byte, 0, 4096) // 4KBåˆå§‹å®¹é‡
            },
        },
    }
}

func (bp *BufferPool) Get() []byte {
    return bp.pool.Get().([]byte)
}

func (bp *BufferPool) Put(buf []byte) {
    // é‡ç½®ç¼“å†²åŒº
    buf = buf[:0]
    bp.pool.Put(buf)
}
```

### 1.2.2 å†…å­˜å¯¹é½ä¼˜åŒ–

```go
// å†…å­˜å¯¹é½ä¼˜åŒ–ç¤ºä¾‹
type OptimizedStruct struct {
    // 8å­—èŠ‚å¯¹é½
    ID       int64    // 8å­—èŠ‚
    Active   bool     // 1å­—èŠ‚ + 7å­—èŠ‚å¡«å……
    Name     [32]byte // 32å­—èŠ‚
    Score    float64  // 8å­—èŠ‚
    Created  int64    // 8å­—èŠ‚
}

// é¿å…å†…å­˜å¯¹é½é—®é¢˜
type UnoptimizedStruct struct {
    Active   bool     // 1å­—èŠ‚
    ID       int64    // 8å­—èŠ‚ï¼Œéœ€è¦7å­—èŠ‚å¡«å……
    Name     [32]byte // 32å­—èŠ‚
    Score    float64  // 8å­—èŠ‚
    Created  int64    // 8å­—èŠ‚
}

// ä½¿ç”¨unsafeåŒ…è¿›è¡Œå†…å­˜æ“ä½œ
import "unsafe"

func GetStructSize() {
    var opt OptimizedStruct
    var unopt UnoptimizedStruct
    
    fmt.Printf("Optimized size: %d bytes\n", unsafe.Sizeof(opt))
    fmt.Printf("Unoptimized size: %d bytes\n", unsafe.Sizeof(unopt))
}
```

### 1.2.3 åƒåœ¾å›æ”¶ä¼˜åŒ–

```go
// GCä¼˜åŒ–é…ç½®
func optimizeGC() {
    // è®¾ç½®GCç›®æ ‡ç™¾åˆ†æ¯”
    debug.SetGCPercent(100) // é»˜è®¤100%
    
    // è®¾ç½®å†…å­˜é™åˆ¶
    debug.SetMemoryLimit(1 << 30) // 1GB
    
    // æ‰‹åŠ¨è§¦å‘GC
    runtime.GC()
    
    // è·å–GCç»Ÿè®¡ä¿¡æ¯
    var m runtime.MemStats
    runtime.ReadMemStats(&m)
    
    fmt.Printf("GC cycles: %d\n", m.NumGC)
    fmt.Printf("GC pause time: %v\n", time.Duration(m.PauseTotalNs))
    fmt.Printf("Heap size: %d bytes\n", m.HeapAlloc)
}
```

## 1.3 ğŸ”„ å¹¶å‘ä¼˜åŒ–

### 1.3.1 å·¥ä½œæ± ä¼˜åŒ–

```go
// é«˜æ€§èƒ½å·¥ä½œæ± 
type HighPerformanceWorkerPool[T any] struct {
    workers    int
    jobQueue   chan Job[T]
    resultChan chan Result[T]
    wg         sync.WaitGroup
    ctx        context.Context
    cancel     context.CancelFunc
    
    // æ€§èƒ½ä¼˜åŒ–å­—æ®µ
    batchSize  int
    timeout    time.Duration
    metrics    *PoolMetrics
    mu         sync.RWMutex
}

type PoolMetrics struct {
    ProcessedJobs    int64
    FailedJobs       int64
    AverageDuration  time.Duration
    LastProcessedAt  time.Time
    QueueLength      int64
}

// NewHighPerformanceWorkerPool åˆ›å»ºé«˜æ€§èƒ½å·¥ä½œæ± 
func NewHighPerformanceWorkerPool[T any](workers, queueSize, batchSize int) *HighPerformanceWorkerPool[T] {
    ctx, cancel := context.WithCancel(context.Background())
    
    return &HighPerformanceWorkerPool[T]{
        workers:    workers,
        jobQueue:   make(chan Job[T], queueSize),
        resultChan: make(chan Result[T], queueSize),
        ctx:        ctx,
        cancel:     cancel,
        batchSize:  batchSize,
        timeout:    30 * time.Second,
        metrics:    &PoolMetrics{},
    }
}

// Start å¯åŠ¨å·¥ä½œæ± 
func (wp *HighPerformanceWorkerPool[T]) Start() error {
    for i := 0; i < wp.workers; i++ {
        wp.wg.Add(1)
        go wp.optimizedWorker(i)
    }
    return nil
}

// optimizedWorker ä¼˜åŒ–çš„å·¥ä½œè€…
func (wp *HighPerformanceWorkerPool[T]) optimizedWorker(id int) {
    defer wp.wg.Done()
    
    // æ‰¹é‡å¤„ç†ç¼“å†²åŒº
    batch := make([]Job[T], 0, wp.batchSize)
    ticker := time.NewTicker(10 * time.Millisecond) // 10msæ‰¹é‡å¤„ç†
    defer ticker.Stop()
    
    for {
        select {
        case job := <-wp.jobQueue:
            batch = append(batch, job)
            
            // æ‰¹é‡å¤„ç†
            if len(batch) >= wp.batchSize {
                wp.processBatch(batch)
                batch = batch[:0] // é‡ç½®åˆ‡ç‰‡
            }
            
        case <-ticker.C:
            // å®šæ—¶æ‰¹é‡å¤„ç†
            if len(batch) > 0 {
                wp.processBatch(batch)
                batch = batch[:0]
            }
            
        case <-wp.ctx.Done():
            // å¤„ç†å‰©ä½™ä»»åŠ¡
            if len(batch) > 0 {
                wp.processBatch(batch)
            }
            return
        }
    }
}

// processBatch æ‰¹é‡å¤„ç†ä»»åŠ¡
func (wp *HighPerformanceWorkerPool[T]) processBatch(batch []Job[T]) {
    for _, job := range batch {
        result := wp.processJob(job)
        wp.updateMetrics(result)
        
        select {
        case wp.resultChan <- result:
        case <-wp.ctx.Done():
            return
        }
    }
}
```

### 1.3.2 æ— é”æ•°æ®ç»“æ„

```go
// æ— é”ç¯å½¢ç¼“å†²åŒº
type LockFreeRingBuffer[T any] struct {
    buffer []T
    mask   uint64
    head   uint64
    tail   uint64
}

// NewLockFreeRingBuffer åˆ›å»ºæ— é”ç¯å½¢ç¼“å†²åŒº
func NewLockFreeRingBuffer[T any](size int) *LockFreeRingBuffer[T] {
    // ç¡®ä¿sizeæ˜¯2çš„å¹‚
    if size&(size-1) != 0 {
        size = 1 << (64 - bits.LeadingZeros64(uint64(size)))
    }
    
    return &LockFreeRingBuffer[T]{
        buffer: make([]T, size),
        mask:   uint64(size - 1),
    }
}

// Push æ— é”æ¨å…¥
func (rb *LockFreeRingBuffer[T]) Push(item T) bool {
    head := atomic.LoadUint64(&rb.head)
    tail := atomic.LoadUint64(&rb.tail)
    
    // æ£€æŸ¥æ˜¯å¦å·²æ»¡
    if (head+1)&rb.mask == tail&rb.mask {
        return false
    }
    
    // å­˜å‚¨æ•°æ®
    rb.buffer[head&rb.mask] = item
    
    // æ›´æ–°head
    atomic.StoreUint64(&rb.head, head+1)
    return true
}

// Pop æ— é”å¼¹å‡º
func (rb *LockFreeRingBuffer[T]) Pop() (T, bool) {
    var zero T
    
    tail := atomic.LoadUint64(&rb.tail)
    head := atomic.LoadUint64(&rb.head)
    
    // æ£€æŸ¥æ˜¯å¦ä¸ºç©º
    if tail&rb.mask == head&rb.mask {
        return zero, false
    }
    
    // è¯»å–æ•°æ®
    item := rb.buffer[tail&rb.mask]
    
    // æ›´æ–°tail
    atomic.StoreUint64(&rb.tail, tail+1)
    return item, true
}
```

## 1.4 ğŸ“¡ I/Oä¼˜åŒ–

### 1.4.1 å¼‚æ­¥I/Oæ¨¡å¼

```go
// å¼‚æ­¥I/Oå¤„ç†å™¨
type AsyncIOProcessor struct {
    workers    int
    taskQueue  chan IOTask
    resultChan chan IOResult
    wg         sync.WaitGroup
    ctx        context.Context
    cancel     context.CancelFunc
}

type IOTask struct {
    ID       string
    Type     string // "read", "write", "copy"
    Source   string
    Target   string
    Data     []byte
    Callback func(IOResult)
}

type IOResult struct {
    TaskID string
    Data   []byte
    Error  error
    Size   int64
}

// NewAsyncIOProcessor åˆ›å»ºå¼‚æ­¥I/Oå¤„ç†å™¨
func NewAsyncIOProcessor(workers int) *AsyncIOProcessor {
    ctx, cancel := context.WithCancel(context.Background())
    
    return &AsyncIOProcessor{
        workers:    workers,
        taskQueue:  make(chan IOTask, 1000),
        resultChan: make(chan IOResult, 1000),
        ctx:        ctx,
        cancel:     cancel,
    }
}

// Start å¯åŠ¨å¼‚æ­¥I/Oå¤„ç†å™¨
func (aio *AsyncIOProcessor) Start() {
    for i := 0; i < aio.workers; i++ {
        aio.wg.Add(1)
        go aio.ioWorker(i)
    }
}

// ioWorker I/Oå·¥ä½œè€…
func (aio *AsyncIOProcessor) ioWorker(id int) {
    defer aio.wg.Done()
    
    for {
        select {
        case task := <-aio.taskQueue:
            result := aio.processIOTask(task)
            
            // æ‰§è¡Œå›è°ƒ
            if task.Callback != nil {
                task.Callback(result)
            }
            
            // å‘é€ç»“æœ
            select {
            case aio.resultChan <- result:
            case <-aio.ctx.Done():
                return
            }
            
        case <-aio.ctx.Done():
            return
        }
    }
}

// processIOTask å¤„ç†I/Oä»»åŠ¡
func (aio *AsyncIOProcessor) processIOTask(task IOTask) IOResult {
    result := IOResult{TaskID: task.ID}
    
    switch task.Type {
    case "read":
        data, err := os.ReadFile(task.Source)
        result.Data = data
        result.Error = err
        result.Size = int64(len(data))
        
    case "write":
        err := os.WriteFile(task.Target, task.Data, 0644)
        result.Error = err
        result.Size = int64(len(task.Data))
        
    case "copy":
        src, err := os.Open(task.Source)
        if err != nil {
            result.Error = err
            return result
        }
        defer src.Close()
        
        dst, err := os.Create(task.Target)
        if err != nil {
            result.Error = err
            return result
        }
        defer dst.Close()
        
        size, err := io.Copy(dst, src)
        result.Size = size
        result.Error = err
    }
    
    return result
}
```

### 1.4.2 æ‰¹é‡å¤„ç†ä¼˜åŒ–

```go
// æ‰¹é‡I/Oå¤„ç†å™¨
type BatchIOProcessor struct {
    batchSize    int
    flushTimeout time.Duration
    buffer       []IOTask
    mu           sync.Mutex
    processor    *AsyncIOProcessor
}

// NewBatchIOProcessor åˆ›å»ºæ‰¹é‡I/Oå¤„ç†å™¨
func NewBatchIOProcessor(batchSize int, flushTimeout time.Duration) *BatchIOProcessor {
    return &BatchIOProcessor{
        batchSize:    batchSize,
        flushTimeout: flushTimeout,
        buffer:       make([]IOTask, 0, batchSize),
        processor:    NewAsyncIOProcessor(4),
    }
}

// AddTask æ·»åŠ ä»»åŠ¡åˆ°æ‰¹é‡å¤„ç†å™¨
func (bio *BatchIOProcessor) AddTask(task IOTask) {
    bio.mu.Lock()
    defer bio.mu.Unlock()
    
    bio.buffer = append(bio.buffer, task)
    
    // è¾¾åˆ°æ‰¹é‡å¤§å°æ—¶ç«‹å³å¤„ç†
    if len(bio.buffer) >= bio.batchSize {
        bio.flush()
    }
}

// flush åˆ·æ–°ç¼“å†²åŒº
func (bio *BatchIOProcessor) flush() {
    if len(bio.buffer) == 0 {
        return
    }
    
    // æ‰¹é‡å‘é€ä»»åŠ¡
    for _, task := range bio.buffer {
        select {
        case bio.processor.taskQueue <- task:
        default:
            // é˜Ÿåˆ—æ»¡æ—¶ä¸¢å¼ƒä»»åŠ¡æˆ–ç­‰å¾…
        }
    }
    
    // æ¸…ç©ºç¼“å†²åŒº
    bio.buffer = bio.buffer[:0]
}
```

## 1.5 ğŸ“Š æ€§èƒ½ç›‘æ§

### 1.5.1 å®æ—¶æ€§èƒ½ç›‘æ§

```go
// æ€§èƒ½ç›‘æ§å™¨
type PerformanceMonitor struct {
    metrics    map[string]*Metric
    mu         sync.RWMutex
    interval   time.Duration
    stopChan   chan struct{}
    exporters  []MetricExporter
}

type Metric struct {
    Name      string
    Value     float64
    Count     int64
    Timestamp time.Time
    Labels    map[string]string
}

type MetricExporter interface {
    Export(metrics map[string]*Metric) error
}

// NewPerformanceMonitor åˆ›å»ºæ€§èƒ½ç›‘æ§å™¨
func NewPerformanceMonitor(interval time.Duration) *PerformanceMonitor {
    return &PerformanceMonitor{
        metrics:   make(map[string]*Metric),
        interval:  interval,
        stopChan:  make(chan struct{}),
        exporters: make([]MetricExporter, 0),
    }
}

// AddMetric æ·»åŠ æŒ‡æ ‡
func (pm *PerformanceMonitor) AddMetric(name string, value float64, labels map[string]string) {
    pm.mu.Lock()
    defer pm.mu.Unlock()
    
    key := pm.getMetricKey(name, labels)
    if metric, exists := pm.metrics[key]; exists {
        metric.Value = value
        metric.Count++
        metric.Timestamp = time.Now()
    } else {
        pm.metrics[key] = &Metric{
            Name:      name,
            Value:     value,
            Count:     1,
            Timestamp: time.Now(),
            Labels:    labels,
        }
    }
}

// Start å¯åŠ¨ç›‘æ§
func (pm *PerformanceMonitor) Start() {
    go pm.monitorLoop()
}

// monitorLoop ç›‘æ§å¾ªç¯
func (pm *PerformanceMonitor) monitorLoop() {
    ticker := time.NewTicker(pm.interval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            pm.exportMetrics()
        case <-pm.stopChan:
            return
        }
    }
}

// exportMetrics å¯¼å‡ºæŒ‡æ ‡
func (pm *PerformanceMonitor) exportMetrics() {
    pm.mu.RLock()
    metrics := make(map[string]*Metric)
    for k, v := range pm.metrics {
        metrics[k] = v
    }
    pm.mu.RUnlock()
    
    // å¯¼å‡ºåˆ°æ‰€æœ‰å¯¼å‡ºå™¨
    for _, exporter := range pm.exporters {
        if err := exporter.Export(metrics); err != nil {
            log.Printf("Failed to export metrics: %v", err)
        }
    }
}
```

### 1.5.2 æ€§èƒ½åŸºå‡†æµ‹è¯•

```go
// æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶
func BenchmarkZeroCopyFileTransfer(b *testing.B) {
    // åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    testFile := createTestFile(1024 * 1024) // 1MB
    defer os.Remove(testFile)
    
    // å¯åŠ¨æµ‹è¯•æœåŠ¡å™¨
    server := startTestServer()
    defer server.Close()
    
    b.ResetTimer()
    
    b.Run("ZeroCopy", func(b *testing.B) {
        for i := 0; i < b.N; i++ {
            err := transferFileZeroCopy(server.URL, testFile)
            if err != nil {
                b.Fatal(err)
            }
        }
    })
    
    b.Run("Traditional", func(b *testing.B) {
        for i := 0; i < b.N; i++ {
            err := transferFileTraditional(server.URL, testFile)
            if err != nil {
                b.Fatal(err)
            }
        }
    })
}

// å†…å­˜åˆ†é…åŸºå‡†æµ‹è¯•
func BenchmarkMemoryAllocation(b *testing.B) {
    b.Run("ObjectPool", func(b *testing.B) {
        pool := NewObjectPool(func() []byte {
            return make([]byte, 0, 1024)
        }, func(buf []byte) []byte {
            return buf[:0]
        })
        
        b.ResetTimer()
        for i := 0; i < b.N; i++ {
            buf := pool.Get()
            // ä½¿ç”¨ç¼“å†²åŒº
            buf = append(buf, []byte("test data")...)
            pool.Put(buf)
        }
    })
    
    b.Run("DirectAllocation", func(b *testing.B) {
        b.ResetTimer()
        for i := 0; i < b.N; i++ {
            buf := make([]byte, 0, 1024)
            // ä½¿ç”¨ç¼“å†²åŒº
            buf = append(buf, []byte("test data")...)
        }
    })
}
```

---

**æ€§èƒ½ä¼˜åŒ–æ·±åŒ–**: 2025å¹´1æœˆ  
**æ¨¡å—çŠ¶æ€**: âœ… **å·²å®Œæˆ**  
**è´¨é‡ç­‰çº§**: ğŸ† **ä¼ä¸šçº§**
