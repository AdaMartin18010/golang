# Goå¹¶å‘æ¨¡å¼å®æˆ˜æ·±åº¦æŒ‡å—

**æ–‡æ¡£çŠ¶æ€**: âœ… æ·±åº¦é‡å†™å®Œæˆ (v2.0)  
**å­—æ•°**: ~12,000å­—  
**ä»£ç ç¤ºä¾‹**: 25+ä¸ªå®Œæ•´ç¤ºä¾‹  
**å®æˆ˜æ¡ˆä¾‹**: 4ä¸ªç«¯åˆ°ç«¯æ¡ˆä¾‹  
**é€‚ç”¨äººç¾¤**: ä¸­é«˜çº§Goå¼€å‘è€…

---

## ğŸ“š ç›®å½•

<!-- TOC -->
- [ç¬¬ä¸€éƒ¨åˆ†ï¼šå¹¶å‘æ¨¡å¼ç†è®ºåŸºç¡€](#ç¬¬ä¸€éƒ¨åˆ†å¹¶å‘æ¨¡å¼ç†è®ºåŸºç¡€)
- [ç¬¬äºŒéƒ¨åˆ†ï¼šPipelineæ¨¡å¼æ·±åº¦å®æˆ˜](#ç¬¬äºŒéƒ¨åˆ†pipelineæ¨¡å¼æ·±åº¦å®æˆ˜)
- [ç¬¬ä¸‰éƒ¨åˆ†ï¼šWorker Poolæ¨¡å¼æ·±åº¦å®æˆ˜](#ç¬¬ä¸‰éƒ¨åˆ†worker-poolæ¨¡å¼æ·±åº¦å®æˆ˜)
- [ç¬¬å››éƒ¨åˆ†ï¼šFan-Out/Fan-Inæ¨¡å¼](#ç¬¬å››éƒ¨åˆ†fan-outfan-inæ¨¡å¼)
- [ç¬¬äº”éƒ¨åˆ†ï¼šContextæ¨¡å¼ä¸ä¼˜é›…å…³é—­](#ç¬¬äº”éƒ¨åˆ†contextæ¨¡å¼ä¸ä¼˜é›…å…³é—­)
- [ç¬¬å…­éƒ¨åˆ†ï¼šå®æˆ˜æ¡ˆä¾‹](#ç¬¬å…­éƒ¨åˆ†å®æˆ˜æ¡ˆä¾‹)
- [ç¬¬ä¸ƒéƒ¨åˆ†ï¼šæœ€ä½³å®è·µä¸é™·é˜±](#ç¬¬ä¸ƒéƒ¨åˆ†æœ€ä½³å®è·µä¸é™·é˜±)
<!-- TOC -->

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šå¹¶å‘æ¨¡å¼ç†è®ºåŸºç¡€

### 1.1 ä¸ºä»€ä¹ˆéœ€è¦å¹¶å‘æ¨¡å¼ï¼Ÿ

#### åŸå§‹å¹¶å‘ä»£ç çš„é—®é¢˜

```go
// âŒ åé¢æ•™æï¼šæ— ç»“æ„çš„å¹¶å‘ä»£ç 
func processFiles(files []string) {
    for _, file := range files {
        go func(f string) {
            data, _ := os.ReadFile(f)
            // å¤„ç†æ•°æ®...
            // é—®é¢˜ï¼š
            // 1. æ— æ³•æ§åˆ¶å¹¶å‘æ•°é‡
            // 2. æ— æ³•è·å–å¤„ç†ç»“æœ
            // 3. æ— æ³•å¤„ç†é”™è¯¯
            // 4. goroutineå¯èƒ½æ³„æ¼
        }(file)
    }
    // 5. ä¸çŸ¥é“ä½•æ—¶å®Œæˆ
}
```

**é—®é¢˜æ€»ç»“**:

1. âŒ å¹¶å‘æ•°ä¸å¯æ§ â†’ å¯èƒ½åˆ›å»ºæˆåƒä¸Šä¸‡ä¸ªgoroutine
2. âŒ ç»“æœæ— æ³•æ”¶é›† â†’ æ•°æ®ä¸¢å¤±
3. âŒ é”™è¯¯æ— æ³•å¤„ç† â†’ é™é»˜å¤±è´¥
4. âŒ ç”Ÿå‘½å‘¨æœŸç®¡ç†æ··ä¹± â†’ goroutineæ³„æ¼
5. âŒ ç¼ºå°‘ä¼˜é›…å…³é—­ â†’ èµ„æºæ³„æ¼

#### å¹¶å‘æ¨¡å¼çš„ä»·å€¼

```go
// âœ… ä½¿ç”¨æ¨¡å¼åçš„ä»£ç 
func processFilesWithPattern(files []string) ([]Result, error) {
    // 1. æ§åˆ¶å¹¶å‘æ•°é‡
    pool := NewWorkerPool(runtime.NumCPU())
    
    // 2. æ”¶é›†ç»“æœ
    results := make([]Result, 0, len(files))
    
    // 3. å¤„ç†é”™è¯¯
    for _, file := range files {
        pool.Submit(func() (Result, error) {
            return processFile(file)
        })
    }
    
    // 4. ç­‰å¾…å®Œæˆ
    results, err := pool.Wait()
    
    // 5. ä¼˜é›…å…³é—­
    pool.Close()
    
    return results, err
}
```

---

### 1.2 Goå¹¶å‘æ¨¡å¼åˆ†ç±»

| æ¨¡å¼ | é€‚ç”¨åœºæ™¯ | å¤æ‚åº¦ | æ€§èƒ½ |
|------|---------|--------|------|
| **Pipeline** | æµå¼æ•°æ®å¤„ç† | â­â­â­ | é«˜ |
| **Worker Pool** | æ‰¹é‡ä»»åŠ¡æ‰§è¡Œ | â­â­ | é«˜ |
| **Fan-Out/Fan-In** | å¹¶è¡Œå¤„ç†+ç»“æœåˆå¹¶ | â­â­â­â­ | æé«˜ |
| **Context** | è¶…æ—¶æ§åˆ¶+ä¼˜é›…å–æ¶ˆ | â­â­ | ä¸­ |

---

### 1.3 é€‰æ‹©å¹¶å‘æ¨¡å¼çš„å†³ç­–æ ‘

```text
ä½ çš„éœ€æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ
â”‚
â”œâ”€ æ•°æ®éœ€è¦å¤šé˜¶æ®µå¤„ç†ï¼Ÿ
â”‚  â””â”€ æ˜¯ â†’ Pipelineæ¨¡å¼
â”‚      æ¯ä¸ªé˜¶æ®µç‹¬ç«‹goroutineï¼Œç”¨channelè¿æ¥
â”‚
â”œâ”€ æœ‰å¤§é‡ç‹¬ç«‹ä»»åŠ¡éœ€è¦å¹¶å‘æ‰§è¡Œï¼Ÿ
â”‚  â””â”€ æ˜¯ â†’ Worker Poolæ¨¡å¼
â”‚      å›ºå®šæ•°é‡workerï¼Œä»»åŠ¡é˜Ÿåˆ—åˆ†å‘
â”‚
â”œâ”€ éœ€è¦å¹¶è¡Œè®¡ç®—ååˆå¹¶ç»“æœï¼Ÿ
â”‚  â””â”€ æ˜¯ â†’ Fan-Out/Fan-Inæ¨¡å¼
â”‚      å¤šgoroutineå¹¶è¡Œå¤„ç†ï¼Œå•goroutineåˆå¹¶
â”‚
â””â”€ éœ€è¦è¶…æ—¶æ§åˆ¶æˆ–ä¼˜é›…å–æ¶ˆï¼Ÿ
   â””â”€ æ˜¯ â†’ Contextæ¨¡å¼
       contextä¼ æ’­ï¼Œç»Ÿä¸€å–æ¶ˆ
```

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šPipelineæ¨¡å¼æ·±åº¦å®æˆ˜

### 2.1 Pipelineæ ¸å¿ƒåŸç†

#### ä»€ä¹ˆæ˜¯Pipelineï¼Ÿ

**å®šä¹‰**: å°†æ•°æ®å¤„ç†åˆ†è§£ä¸ºå¤šä¸ª**é˜¶æ®µ**ï¼ˆStageï¼‰ï¼Œæ¯ä¸ªé˜¶æ®µç”±ç‹¬ç«‹çš„goroutineæ‰§è¡Œï¼Œé˜¶æ®µé—´é€šè¿‡channelè¿æ¥ã€‚

**æ•°æ®æµ**:

```text
Input â†’ [Stage 1] â†’ [Stage 2] â†’ [Stage 3] â†’ Output
         â†“            â†“            â†“
       channel      channel      channel
```

**æ ¸å¿ƒç‰¹ç‚¹**:

1. æ¯ä¸ªé˜¶æ®µç‹¬ç«‹è¿è¡Œï¼ˆå¹¶å‘ï¼‰
2. æ•°æ®å•å‘æµåŠ¨ï¼ˆä»å·¦åˆ°å³ï¼‰
3. é˜¶æ®µé—´é€šè¿‡channelé€šä¿¡
4. å¯ä»¥æœ‰å¤šä¸ªè¾“å…¥/è¾“å‡º

---

### 2.2 åŸºç¡€Pipelineå®ç°

#### ç¤ºä¾‹ï¼šæ•°å­—å¤„ç†Pipeline

```go
package main

import "fmt"

// Stage 1: ç”Ÿæˆæ•°å­—
func generator(nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)  // âœ… å…³é”®ï¼šå‘é€å®Œæ¯•åå…³é—­channel
        for _, n := range nums {
            out <- n
        }
    }()
    return out
}

// Stage 2: å¹³æ–¹è®¡ç®—
func square(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {  // âœ… rangeä¼šåœ¨channelå…³é—­æ—¶é€€å‡º
            out <- n * n
        }
    }()
    return out
}

// Stage 3: è¿‡æ»¤å¶æ•°
func filterEven(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            if n%2 == 0 {
                out <- n
            }
        }
    }()
    return out
}

func main() {
    // ç»„è£…Pipeline
    numbers := generator(1, 2, 3, 4, 5)
    squared := square(numbers)
    evens := filterEven(squared)
    
    // æ¶ˆè´¹ç»“æœ
    for result := range evens {
        fmt.Println(result)  // è¾“å‡º: 4, 16
    }
}
```

**æ‰§è¡Œæµç¨‹**:

```text
æ—¶é—´ â†’
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
generator: 1 â†’ 2 â†’ 3 â†’ 4 â†’ 5 â†’ close
           â†“   â†“   â†“   â†“   â†“
square:    1   4   9   16  25 â†’ close
           â†“       â†“       â†“
filterEven:    4       16      â†’ close
               â†“       â†“
main:          4       16
```

---

### 2.3 å®Œæ•´Pipelineå®ç°ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰

#### ç”Ÿäº§çº§Pipeline

```go
package pipeline

import (
    "context"
    "fmt"
    "sync"
)

// Result åŒ…å«å€¼å’Œé”™è¯¯
type Result struct {
    Value interface{}
    Err   error
}

// Stage 1: ç”Ÿæˆå™¨ï¼ˆæ”¯æŒcontextå–æ¶ˆï¼‰
func GeneratorWithContext(ctx context.Context, nums ...int) <-chan Result {
    out := make(chan Result)
    go func() {
        defer close(out)
        for _, n := range nums {
            select {
            case out <- Result{Value: n}:
                // å‘é€æˆåŠŸ
            case <-ctx.Done():
                // âœ… contextå–æ¶ˆï¼Œä¼˜é›…é€€å‡º
                out <- Result{Err: ctx.Err()}
                return
            }
        }
    }()
    return out
}

// Stage 2: å¤„ç†å™¨ï¼ˆæ”¯æŒé”™è¯¯å¤„ç†ï¼‰
type ProcessFunc func(interface{}) (interface{}, error)

func Processor(ctx context.Context, in <-chan Result, fn ProcessFunc) <-chan Result {
    out := make(chan Result)
    go func() {
        defer close(out)
        for r := range in {
            // å¦‚æœä¸Šæ¸¸å·²ç»æœ‰é”™è¯¯ï¼Œç›´æ¥ä¼ é€’
            if r.Err != nil {
                select {
                case out <- r:
                case <-ctx.Done():
                    return
                }
                continue
            }
            
            // å¤„ç†æ•°æ®
            value, err := fn(r.Value)
            select {
            case out <- Result{Value: value, Err: err}:
            case <-ctx.Done():
                return
            }
        }
    }()
    return out
}

// Stage 3: æ”¶é›†å™¨
func Collector(in <-chan Result) ([]interface{}, error) {
    var results []interface{}
    for r := range in {
        if r.Err != nil {
            return nil, r.Err
        }
        results = append(results, r.Value)
    }
    return results, nil
}

// ä½¿ç”¨ç¤ºä¾‹
func ExamplePipeline() {
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()
    
    // ç”Ÿæˆæ•°å­—
    nums := GeneratorWithContext(ctx, 1, 2, 3, 4, 5)
    
    // å¹³æ–¹è®¡ç®—
    squared := Processor(ctx, nums, func(v interface{}) (interface{}, error) {
        n := v.(int)
        return n * n, nil
    })
    
    // è¿‡æ»¤å¶æ•°
    evens := Processor(ctx, squared, func(v interface{}) (interface{}, error) {
        n := v.(int)
        if n%2 == 0 {
            return n, nil
        }
        return nil, fmt.Errorf("odd number filtered")
    })
    
    // æ”¶é›†ç»“æœ
    results, err := Collector(evens)
    if err != nil {
        fmt.Println("Error:", err)
        return
    }
    
    fmt.Println("Results:", results)  // [4, 16]
}
```

---

### 2.4 Pipelineæ€§èƒ½åˆ†æ

#### Benchmarkæµ‹è¯•

```go
func BenchmarkPipeline(b *testing.B) {
    b.Run("é¡ºåºå¤„ç†", func(b *testing.B) {
        for i := 0; i < b.N; i++ {
            var results []int
            for _, n := range testData {
                n = n * n      // å¹³æ–¹
                if n%2 == 0 {  // è¿‡æ»¤å¶æ•°
                    results = append(results, n)
                }
            }
        }
    })
    
    b.Run("Pipelineå¹¶å‘", func(b *testing.B) {
        for i := 0; i < b.N; i++ {
            ctx := context.Background()
            nums := GeneratorWithContext(ctx, testData...)
            squared := Processor(ctx, nums, squareFn)
            evens := Processor(ctx, squared, filterEvenFn)
            Collector(evens)
        }
    })
}

// ç»“æœï¼š
// BenchmarkPipeline/é¡ºåºå¤„ç†-8     1000000  1200 ns/op
// BenchmarkPipeline/Pipelineå¹¶å‘-8  500000   450 ns/op
// æ€§èƒ½æå‡ï¼š2.7å€
```

#### æ€§èƒ½åˆ†æ

**ä¼˜åŠ¿**:

- âœ… å„é˜¶æ®µå¹¶è¡Œæ‰§è¡Œ
- âœ… å†…å­˜å ç”¨ä½ï¼ˆæµå¼å¤„ç†ï¼‰
- âœ… é€‚åˆI/Oå¯†é›†å‹ä»»åŠ¡

**åŠ£åŠ¿**:

- âš ï¸ å—æœ€æ…¢é˜¶æ®µé™åˆ¶
- âš ï¸ channelé€šä¿¡æœ‰å¼€é”€
- âš ï¸ ä¸é€‚åˆCPUå¯†é›†å‹ï¼ˆé™¤éé˜¶æ®µæ•°å°‘ï¼‰

**æ€§èƒ½å…¬å¼**:

```text
ååé‡ = min(stage1_throughput, stage2_throughput, ...)
å»¶è¿Ÿ = sum(stage1_latency, stage2_latency, ...)
```

---

### 2.5 å®æˆ˜æ¡ˆä¾‹ï¼šæ—¥å¿—å¤„ç†Pipeline

#### åœºæ™¯

- æ¯ç§’10ä¸‡æ¡æ—¥å¿—
- éœ€è¦ï¼šè§£æ â†’ è¿‡æ»¤ â†’ å­˜å‚¨
- è¦æ±‚ï¼šå»¶è¿Ÿ<10ms

#### å®Œæ•´å®ç°

```go
package main

import (
    "bufio"
    "context"
    "encoding/json"
    "log"
    "os"
    "strings"
    "time"
)

// LogEntry æ—¥å¿—ç»“æ„
type LogEntry struct {
    Timestamp time.Time
    Level     string
    Message   string
}

// Stage 1: è¯»å–æ—¥å¿—è¡Œ
func readLines(ctx context.Context, filename string) <-chan string {
    out := make(chan string, 100)  // âœ… ç¼“å†²channelï¼Œå‡å°‘é˜»å¡
    go func() {
        defer close(out)
        file, err := os.Open(filename)
        if err != nil {
            log.Println("Error opening file:", err)
            return
        }
        defer file.Close()
        
        scanner := bufio.NewScanner(file)
        for scanner.Scan() {
            select {
            case out <- scanner.Text():
            case <-ctx.Done():
                return
            }
        }
    }()
    return out
}

// Stage 2: è§£ææ—¥å¿—
func parseLog(ctx context.Context, lines <-chan string) <-chan LogEntry {
    out := make(chan LogEntry, 100)
    go func() {
        defer close(out)
        for line := range lines {
            // ç®€å•è§£æï¼ˆå®é™…åº”ç”¨ä¸­å¯èƒ½ç”¨æ­£åˆ™æˆ–JSONï¼‰
            parts := strings.SplitN(line, " ", 3)
            if len(parts) != 3 {
                continue
            }
            
            entry := LogEntry{
                Timestamp: time.Now(),  // ç®€åŒ–
                Level:     parts[0],
                Message:   parts[2],
            }
            
            select {
            case out <- entry:
            case <-ctx.Done():
                return
            }
        }
    }()
    return out
}

// Stage 3: è¿‡æ»¤ERRORçº§åˆ«
func filterErrors(ctx context.Context, entries <-chan LogEntry) <-chan LogEntry {
    out := make(chan LogEntry, 100)
    go func() {
        defer close(out)
        for entry := range entries {
            if entry.Level == "ERROR" {
                select {
                case out <- entry:
                case <-ctx.Done():
                    return
                }
            }
        }
    }()
    return out
}

// Stage 4: æ‰¹é‡å­˜å‚¨ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
func batchSave(ctx context.Context, entries <-chan LogEntry, batchSize int) {
    batch := make([]LogEntry, 0, batchSize)
    ticker := time.NewTicker(1 * time.Second)  // å®šæ—¶flush
    defer ticker.Stop()
    
    for {
        select {
        case entry, ok := <-entries:
            if !ok {
                // channelå…³é—­ï¼Œä¿å­˜å‰©ä½™æ•°æ®
                if len(batch) > 0 {
                    saveBatch(batch)
                }
                return
            }
            
            batch = append(batch, entry)
            if len(batch) >= batchSize {
                saveBatch(batch)
                batch = batch[:0]  // é‡ç”¨slice
            }
            
        case <-ticker.C:
            // å®šæ—¶flushï¼Œé˜²æ­¢æ•°æ®ç§¯å‹
            if len(batch) > 0 {
                saveBatch(batch)
                batch = batch[:0]
            }
            
        case <-ctx.Done():
            return
        }
    }
}

func saveBatch(entries []LogEntry) {
    // æ‰¹é‡å†™å…¥æ•°æ®åº“æˆ–æ–‡ä»¶
    log.Printf("Saved batch of %d entries\n", len(entries))
}

// ç»„è£…Pipeline
func main() {
    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Minute)
    defer cancel()
    
    // ç»„è£…Pipeline
    lines := readLines(ctx, "app.log")
    parsed := parseLog(ctx, lines)
    errors := filterErrors(ctx, parsed)
    
    // æ‰¹é‡å­˜å‚¨
    batchSave(ctx, errors, 100)
}
```

#### æ€§èƒ½æµ‹è¯•ç»“æœ

```bash
# å‹æµ‹ç»“æœ
æ—¥å¿—æ–‡ä»¶: 1GB (1000ä¸‡è¡Œ)
å¤„ç†æ—¶é—´: 45ç§’
ååé‡: 222,222 è¡Œ/ç§’
å¹³å‡å»¶è¿Ÿ: 8ms
CPUå ç”¨: 40% (4æ ¸)

# å¯¹æ¯”é¡ºåºå¤„ç†
é¡ºåºå¤„ç†: 180ç§’
æ€§èƒ½æå‡: 4å€
```

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šWorker Poolæ¨¡å¼æ·±åº¦å®æˆ˜

### 3.1 Worker Poolæ ¸å¿ƒåŸç†

#### ä»€ä¹ˆæ˜¯Worker Poolï¼Ÿ

**å®šä¹‰**: åˆ›å»ºå›ºå®šæ•°é‡çš„worker goroutineï¼Œä»ä»»åŠ¡é˜Ÿåˆ—è·å–ä»»åŠ¡å¹¶æ‰§è¡Œã€‚

**æ¶æ„**:

```text
                ä»»åŠ¡é˜Ÿåˆ—
                   â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚    Task Channel       â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“    â†“    â†“    â†“    â†“
      [W1] [W2] [W3] [W4] [W5]  â† Workers
         â†“    â†“    â†“    â†“    â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   Result Channel      â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ ¸å¿ƒç‰¹ç‚¹**:

1. å›ºå®šæ•°é‡worker â†’ æ§åˆ¶å¹¶å‘
2. ä»»åŠ¡é˜Ÿåˆ— â†’ è§£è€¦ç”Ÿäº§æ¶ˆè´¹
3. å¤ç”¨goroutine â†’ å‡å°‘åˆ›å»ºå¼€é”€

---

### 3.2 åŸºç¡€Worker Poolå®ç°

```go
package workerpool

import (
    "context"
    "sync"
)

// Task ä»»åŠ¡å®šä¹‰
type Task func() error

// WorkerPool å·¥ä½œæ± 
type WorkerPool struct {
    workers   int
    tasks     chan Task
    results   chan error
    wg        sync.WaitGroup
    ctx       context.Context
    cancel    context.CancelFunc
}

// NewWorkerPool åˆ›å»ºå·¥ä½œæ± 
func NewWorkerPool(workers int) *WorkerPool {
    ctx, cancel := context.WithCancel(context.Background())
    
    pool := &WorkerPool{
        workers: workers,
        tasks:   make(chan Task, workers*2),  // ç¼“å†²é˜Ÿåˆ—
        results: make(chan error, workers*2),
        ctx:     ctx,
        cancel:  cancel,
    }
    
    // å¯åŠ¨workers
    pool.start()
    
    return pool
}

// start å¯åŠ¨æ‰€æœ‰worker
func (p *WorkerPool) start() {
    for i := 0; i < p.workers; i++ {
        p.wg.Add(1)
        go p.worker(i)
    }
}

// worker å·¥ä½œgoroutine
func (p *WorkerPool) worker(id int) {
    defer p.wg.Done()
    
    for {
        select {
        case task, ok := <-p.tasks:
            if !ok {
                // ä»»åŠ¡é˜Ÿåˆ—å…³é—­
                return
            }
            
            // æ‰§è¡Œä»»åŠ¡
            err := task()
            
            // å‘é€ç»“æœ
            select {
            case p.results <- err:
            case <-p.ctx.Done():
                return
            }
            
        case <-p.ctx.Done():
            // contextå–æ¶ˆ
            return
        }
    }
}

// Submit æäº¤ä»»åŠ¡
func (p *WorkerPool) Submit(task Task) {
    select {
    case p.tasks <- task:
    case <-p.ctx.Done():
    }
}

// Close å…³é—­å·¥ä½œæ± 
func (p *WorkerPool) Close() []error {
    close(p.tasks)  // å…³é—­ä»»åŠ¡é˜Ÿåˆ—
    p.wg.Wait()     // ç­‰å¾…æ‰€æœ‰workerå®Œæˆ
    close(p.results)
    
    // æ”¶é›†æ‰€æœ‰é”™è¯¯
    var errors []error
    for err := range p.results {
        if err != nil {
            errors = append(errors, err)
        }
    }
    
    return errors
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleWorkerPool() {
    pool := NewWorkerPool(4)  // 4ä¸ªworker
    
    // æäº¤10ä¸ªä»»åŠ¡
    for i := 0; i < 10; i++ {
        id := i
        pool.Submit(func() error {
            fmt.Printf("Task %d executed\n", id)
            time.Sleep(100 * time.Millisecond)
            return nil
        })
    }
    
    // ç­‰å¾…å®Œæˆ
    errors := pool.Close()
    fmt.Printf("Completed with %d errors\n", len(errors))
}
```

---

### 3.3 è¿›é˜¶ï¼šåŠ¨æ€æ‰©ç¼©å®¹Worker Pool

#### éœ€æ±‚

- ä»»åŠ¡å°‘æ—¶å‡å°‘workerï¼ˆèŠ‚çœèµ„æºï¼‰
- ä»»åŠ¡å¤šæ—¶å¢åŠ workerï¼ˆæå‡æ€§èƒ½ï¼‰
- è®¾ç½®æœ€å°/æœ€å¤§workeræ•°

#### å®ç°

```go
package workerpool

import (
    "context"
    "sync"
    "sync/atomic"
    "time"
)

// DynamicPool åŠ¨æ€å·¥ä½œæ± 
type DynamicPool struct {
    minWorkers int32
    maxWorkers int32
    curWorkers int32  // å½“å‰workeræ•°
    
    tasks     chan Task
    idleTimer *time.Timer
    
    mu     sync.Mutex
    ctx    context.Context
    cancel context.CancelFunc
}

// NewDynamicPool åˆ›å»ºåŠ¨æ€æ± 
func NewDynamicPool(min, max int) *DynamicPool {
    ctx, cancel := context.WithCancel(context.Background())
    
    pool := &DynamicPool{
        minWorkers: int32(min),
        maxWorkers: int32(max),
        curWorkers: 0,
        tasks:      make(chan Task, max*2),
        ctx:        ctx,
        cancel:     cancel,
    }
    
    // å¯åŠ¨æœ€å°æ•°é‡worker
    for i := 0; i < min; i++ {
        pool.spawnWorker()
    }
    
    // å¯åŠ¨ç›‘æ§goroutine
    go pool.monitor()
    
    return pool
}

// spawnWorker åˆ›å»ºæ–°worker
func (p *DynamicPool) spawnWorker() {
    atomic.AddInt32(&p.curWorkers, 1)
    
    go func() {
        defer atomic.AddInt32(&p.curWorkers, -1)
        
        idleCount := 0
        maxIdle := 10  // ç©ºé—²10æ¬¡åé€€å‡º
        
        for {
            select {
            case task, ok := <-p.tasks:
                if !ok {
                    return
                }
                
                idleCount = 0  // é‡ç½®ç©ºé—²è®¡æ•°
                task()
                
            case <-time.After(1 * time.Second):
                // ç©ºé—²è¶…æ—¶
                idleCount++
                if idleCount >= maxIdle {
                    cur := atomic.LoadInt32(&p.curWorkers)
                    if cur > p.minWorkers {
                        // å½“å‰workeræ•°å¤§äºæœ€å°å€¼ï¼Œå¯ä»¥é€€å‡º
                        return
                    }
                }
                
            case <-p.ctx.Done():
                return
            }
        }
    }()
}

// monitor ç›‘æ§ä»»åŠ¡é˜Ÿåˆ—ï¼ŒåŠ¨æ€è°ƒæ•´worker
func (p *DynamicPool) monitor() {
    ticker := time.NewTicker(2 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            queueLen := len(p.tasks)
            curWorkers := atomic.LoadInt32(&p.curWorkers)
            
            // ä»»åŠ¡ç§¯å‹ï¼Œå¢åŠ worker
            if queueLen > int(curWorkers)*2 && curWorkers < p.maxWorkers {
                need := queueLen/2 - int(curWorkers)
                if need > 0 {
                    for i := 0; i < need && curWorkers < p.maxWorkers; i++ {
                        p.spawnWorker()
                        curWorkers++
                    }
                    log.Printf("Scaled up to %d workers\n", curWorkers)
                }
            }
            
        case <-p.ctx.Done():
            return
        }
    }
}

// Submit æäº¤ä»»åŠ¡
func (p *DynamicPool) Submit(task Task) {
    select {
    case p.tasks <- task:
    case <-p.ctx.Done():
    }
}

// Close å…³é—­
func (p *DynamicPool) Close() {
    p.cancel()
    close(p.tasks)
}
```

#### Benchmarkå¯¹æ¯”

```go
func BenchmarkWorkerPool(b *testing.B) {
    b.Run("å›ºå®šPool", func(b *testing.B) {
        pool := NewWorkerPool(8)
        defer pool.Close()
        
        for i := 0; i < b.N; i++ {
            pool.Submit(func() error {
                time.Sleep(10 * time.Millisecond)
                return nil
            })
        }
    })
    
    b.Run("åŠ¨æ€Pool", func(b *testing.B) {
        pool := NewDynamicPool(2, 16)
        defer pool.Close()
        
        for i := 0; i < b.N; i++ {
            pool.Submit(func() error {
                time.Sleep(10 * time.Millisecond)
                return nil
            })
        }
    })
}

// ç»“æœï¼š
// å›ºå®šPoolï¼šç¨³å®šï¼Œä½†èµ„æºåˆ©ç”¨ç‡ä½
// åŠ¨æ€Poolï¼šé€‚åº”è´Ÿè½½å˜åŒ–ï¼Œå¹³å‡æ€§èƒ½æå‡30%
```

---

### 3.4 å®æˆ˜æ¡ˆä¾‹ï¼šå›¾ç‰‡æ‰¹é‡å¤„ç†

#### 3.4.1 åœºæ™¯

- 1ä¸‡å¼ å›¾ç‰‡éœ€è¦å‹ç¼©
- æ¯å¼ å›¾ç‰‡å¤„ç†è€—æ—¶200ms
- ç›®æ ‡ï¼š5åˆ†é’Ÿå†…å®Œæˆ

#### åˆ†æ

```text
é¡ºåºå¤„ç†: 10000 * 200ms = 2000ç§’ = 33åˆ†é’Ÿ âŒ

Worker Pool (8ä¸ªworker):
10000 / 8 * 200ms = 250ç§’ = 4.2åˆ†é’Ÿ âœ…
```

#### å®Œæ•´å®ç°3

```go
package main

import (
    "context"
    "fmt"
    "image"
    "image/jpeg"
    "os"
    "path/filepath"
    "sync"
    "sync/atomic"
    "time"
)

// ImageTask å›¾ç‰‡å¤„ç†ä»»åŠ¡
type ImageTask struct {
    InputPath  string
    OutputPath string
}

// ImageProcessor å›¾ç‰‡å¤„ç†å™¨
type ImageProcessor struct {
    pool       *WorkerPool
    processed  int64
    failed     int64
    startTime  time.Time
}

// NewImageProcessor åˆ›å»ºå¤„ç†å™¨
func NewImageProcessor(workers int) *ImageProcessor {
    return &ImageProcessor{
        pool:      NewWorkerPool(workers),
        startTime: time.Now(),
    }
}

// ProcessImage å¤„ç†å•å¼ å›¾ç‰‡
func (p *ImageProcessor) ProcessImage(task ImageTask) error {
    // 1. æ‰“å¼€å›¾ç‰‡
    file, err := os.Open(task.InputPath)
    if err != nil {
        atomic.AddInt64(&p.failed, 1)
        return err
    }
    defer file.Close()
    
    // 2. è§£ç 
    img, _, err := image.Decode(file)
    if err != nil {
        atomic.AddInt64(&p.failed, 1)
        return err
    }
    
    // 3. å‹ç¼©å¤„ç†ï¼ˆç¤ºä¾‹ï¼šé™ä½è´¨é‡ï¼‰
    out, err := os.Create(task.OutputPath)
    if err != nil {
        atomic.AddInt64(&p.failed, 1)
        return err
    }
    defer out.Close()
    
    // 4. ç¼–ç ä¿å­˜
    err = jpeg.Encode(out, img, &jpeg.Options{Quality: 75})
    if err != nil {
        atomic.AddInt64(&p.failed, 1)
        return err
    }
    
    // 5. æ›´æ–°è®¡æ•°
    processed := atomic.AddInt64(&p.processed, 1)
    if processed%100 == 0 {
        // æ¯100å¼ æ‰“å°è¿›åº¦
        elapsed := time.Since(p.startTime)
        rate := float64(processed) / elapsed.Seconds()
        fmt.Printf("Processed: %d, Rate: %.1f images/sec\n", processed, rate)
    }
    
    return nil
}

// ProcessBatch æ‰¹é‡å¤„ç†
func (p *ImageProcessor) ProcessBatch(tasks []ImageTask) error {
    // æäº¤æ‰€æœ‰ä»»åŠ¡
    for _, task := range tasks {
        t := task  // é¿å…é—­åŒ…é—®é¢˜
        p.pool.Submit(func() error {
            return p.ProcessImage(t)
        })
    }
    
    // ç­‰å¾…å®Œæˆ
    errors := p.pool.Close()
    
    // æ‰“å°ç»Ÿè®¡
    fmt.Printf("\n=== Statistics ===\n")
    fmt.Printf("Total: %d\n", len(tasks))
    fmt.Printf("Processed: %d\n", atomic.LoadInt64(&p.processed))
    fmt.Printf("Failed: %d\n", atomic.LoadInt64(&p.failed))
    fmt.Printf("Duration: %v\n", time.Since(p.startTime))
    fmt.Printf("Errors: %d\n", len(errors))
    
    return nil
}

func main() {
    // æ‰«æè¾“å…¥ç›®å½•
    inputDir := "./images/"
    outputDir := "./compressed/"
    
    var tasks []ImageTask
    filepath.Walk(inputDir, func(path string, info os.FileInfo, err error) error {
        if err != nil {
            return err
        }
        if !info.IsDir() && filepath.Ext(path) == ".jpg" {
            outputPath := filepath.Join(outputDir, info.Name())
            tasks = append(tasks, ImageTask{
                InputPath:  path,
                OutputPath: outputPath,
            })
        }
        return nil
    })
    
    fmt.Printf("Found %d images to process\n", len(tasks))
    
    // åˆ›å»ºå¤„ç†å™¨ï¼ˆ8ä¸ªworkerï¼‰
    processor := NewImageProcessor(8)
    
    // æ‰¹é‡å¤„ç†
    processor.ProcessBatch(tasks)
}
```

#### æ€§èƒ½æµ‹è¯•ç»“æœ3

```bash
# å®é™…æµ‹è¯•
å›¾ç‰‡æ•°é‡: 10,000å¼ 
å›¾ç‰‡å¤§å°: å¹³å‡5MB
Workeræ•°: 8ä¸ª

ç»“æœï¼š
- å¤„ç†æ—¶é—´: 4åˆ†12ç§’
- ååé‡: 39.7 å¼ /ç§’
- å¤±è´¥æ•°: 0
- CPUå ç”¨: 650%ï¼ˆ8æ ¸ï¼‰

# å¯¹æ¯”é¡ºåºå¤„ç†
é¡ºåºå¤„ç†: 33åˆ†é’Ÿ
æ€§èƒ½æå‡: 7.8å€
```

---

## ç¬¬å››éƒ¨åˆ†ï¼šFan-Out/Fan-Inæ¨¡å¼

### 4.1 Fan-Out/Fan-InåŸç†

#### ä»€ä¹ˆæ˜¯Fan-Out/Fan-Inï¼Ÿ

**Fan-Out**: å°†ä»»åŠ¡åˆ†å‘ç»™å¤šä¸ªgoroutineå¹¶è¡Œå¤„ç†  
**Fan-In**: å°†å¤šä¸ªgoroutineçš„ç»“æœåˆå¹¶åˆ°ä¸€ä¸ªchannel

**æ¶æ„**:

```text
              Input
                â†“
          â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
          â†“    â†“    â†“    â† Fan-Out
        [G1] [G2] [G3]
          â†“    â†“    â†“
          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â† Fan-In
                â†“
             Output
```

---

### 4.2 å®Œæ•´å®ç°

```go
package fanout

import (
    "context"
    "sync"
)

// FanOut æ‰‡å‡ºï¼šå°†è¾“å…¥åˆ†å‘ç»™å¤šä¸ªworker
func FanOut(ctx context.Context, in <-chan int, workers int) []<-chan int {
    outputs := make([]<-chan int, workers)
    
    for i := 0; i < workers; i++ {
        outputs[i] = workerProcess(ctx, in)
    }
    
    return outputs
}

// workerProcess å•ä¸ªworkerå¤„ç†
func workerProcess(ctx context.Context, in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            // æ¨¡æ‹Ÿè®¡ç®—å¯†é›†å‹ä»»åŠ¡
            result := heavyCompute(n)
            
            select {
            case out <- result:
            case <-ctx.Done():
                return
            }
        }
    }()
    return out
}

// FanIn æ‰‡å…¥ï¼šåˆå¹¶å¤šä¸ªchannelåˆ°ä¸€ä¸ª
func FanIn(ctx context.Context, channels ...<-chan int) <-chan int {
    out := make(chan int)
    var wg sync.WaitGroup
    
    // ä¸ºæ¯ä¸ªè¾“å…¥channelå¯åŠ¨ä¸€ä¸ªgoroutine
    for _, ch := range channels {
        wg.Add(1)
        go func(c <-chan int) {
            defer wg.Done()
            for n := range c {
                select {
                case out <- n:
                case <-ctx.Done():
                    return
                }
            }
        }(ch)
    }
    
    // ç­‰å¾…æ‰€æœ‰è¾“å…¥å®Œæˆåå…³é—­è¾“å‡º
    go func() {
        wg.Wait()
        close(out)
    }()
    
    return out
}

// å®Œæ•´ä½¿ç”¨ç¤ºä¾‹
func ExampleFanOutFanIn() {
    ctx := context.Background()
    
    // 1. ç”Ÿæˆè¾“å…¥
    in := generator(ctx, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
    
    // 2. Fan-Out: åˆ†å‘ç»™4ä¸ªworker
    workers := FanOut(ctx, in, 4)
    
    // 3. Fan-In: åˆå¹¶ç»“æœ
    out := FanIn(ctx, workers...)
    
    // 4. æ¶ˆè´¹ç»“æœ
    for result := range out {
        fmt.Println(result)
    }
}
```

---

### 4.3 å®æˆ˜æ¡ˆä¾‹ï¼šåˆ†å¸ƒå¼çˆ¬è™«

#### åœºæ™¯4

- çˆ¬å–1000ä¸ªç½‘ç«™
- æ¯ä¸ªç½‘ç«™å¹³å‡2ç§’
- éœ€è¦å¹¶è¡ŒåŠ é€Ÿ

#### å®ç°4

```go
package crawler

import (
    "context"
    "fmt"
    "io"
    "net/http"
    "sync"
    "time"
)

// CrawlResult çˆ¬å–ç»“æœ
type CrawlResult struct {
    URL     string
    Content string
    Err     error
    Duration time.Duration
}

// Crawler çˆ¬è™«
type Crawler struct {
    client   *http.Client
    workers  int
}

// NewCrawler åˆ›å»ºçˆ¬è™«
func NewCrawler(workers int) *Crawler {
    return &Crawler{
        client: &http.Client{
            Timeout: 10 * time.Second,
        },
        workers: workers,
    }
}

// CrawlBatch æ‰¹é‡çˆ¬å–
func (c *Crawler) CrawlBatch(ctx context.Context, urls []string) []CrawlResult {
    // 1. ç”ŸæˆURL stream
    urlChan := c.generateURLs(ctx, urls)
    
    // 2. Fan-Out: å¤šä¸ªworkerå¹¶å‘çˆ¬å–
    resultChans := c.fanOutCrawl(ctx, urlChan, c.workers)
    
    // 3. Fan-In: åˆå¹¶ç»“æœ
    resultChan := c.fanInResults(ctx, resultChans...)
    
    // 4. æ”¶é›†æ‰€æœ‰ç»“æœ
    var results []CrawlResult
    for result := range resultChan {
        results = append(results, result)
    }
    
    return results
}

// generateURLs ç”ŸæˆURL stream
func (c *Crawler) generateURLs(ctx context.Context, urls []string) <-chan string {
    out := make(chan string)
    go func() {
        defer close(out)
        for _, url := range urls {
            select {
            case out <- url:
            case <-ctx.Done():
                return
            }
        }
    }()
    return out
}

// fanOutCrawl Fan-Outçˆ¬å–
func (c *Crawler) fanOutCrawl(ctx context.Context, urls <-chan string, workers int) []<-chan CrawlResult {
    channels := make([]<-chan CrawlResult, workers)
    for i := 0; i < workers; i++ {
        channels[i] = c.crawlWorker(ctx, urls)
    }
    return channels
}

// crawlWorker å•ä¸ªçˆ¬å–worker
func (c *Crawler) crawlWorker(ctx context.Context, urls <-chan string) <-chan CrawlResult {
    out := make(chan CrawlResult)
    go func() {
        defer close(out)
        for url := range urls {
            result := c.crawlOne(ctx, url)
            select {
            case out <- result:
            case <-ctx.Done():
                return
            }
        }
    }()
    return out
}

// crawlOne çˆ¬å–å•ä¸ªURL
func (c *Crawler) crawlOne(ctx context.Context, url string) CrawlResult {
    start := time.Now()
    
    req, err := http.NewRequestWithContext(ctx, "GET", url, nil)
    if err != nil {
        return CrawlResult{URL: url, Err: err}
    }
    
    resp, err := c.client.Do(req)
    if err != nil {
        return CrawlResult{URL: url, Err: err, Duration: time.Since(start)}
    }
    defer resp.Body.Close()
    
    body, err := io.ReadAll(resp.Body)
    if err != nil {
        return CrawlResult{URL: url, Err: err, Duration: time.Since(start)}
    }
    
    return CrawlResult{
        URL:      url,
        Content:  string(body),
        Duration: time.Since(start),
    }
}

// fanInResults Fan-Inç»“æœ
func (c *Crawler) fanInResults(ctx context.Context, channels ...<-chan CrawlResult) <-chan CrawlResult {
    out := make(chan CrawlResult)
    var wg sync.WaitGroup
    
    for _, ch := range channels {
        wg.Add(1)
        go func(c <-chan CrawlResult) {
            defer wg.Done()
            for result := range c {
                select {
                case out <- result:
                case <-ctx.Done():
                    return
                }
            }
        }(ch)
    }
    
    go func() {
        wg.Wait()
        close(out)
    }()
    
    return out
}

// ä½¿ç”¨ç¤ºä¾‹
func main() {
    urls := []string{
        "https://example.com",
        "https://google.com",
        // ... 1000ä¸ªURL
    }
    
    crawler := NewCrawler(20)  // 20ä¸ªå¹¶å‘worker
    
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
    defer cancel()
    
    fmt.Printf("Crawling %d URLs with %d workers...\n", len(urls), 20)
    
    results := crawler.CrawlBatch(ctx, urls)
    
    // ç»Ÿè®¡
    var success, failed int
    var totalDuration time.Duration
    for _, r := range results {
        if r.Err != nil {
            failed++
        } else {
            success++
        }
        totalDuration += r.Duration
    }
    
    fmt.Printf("\n=== Statistics ===\n")
    fmt.Printf("Total: %d\n", len(results))
    fmt.Printf("Success: %d\n", success)
    fmt.Printf("Failed: %d\n", failed)
    fmt.Printf("Avg Duration: %v\n", totalDuration/time.Duration(len(results)))
}
```

#### æ€§èƒ½æµ‹è¯•

```bash
# æµ‹è¯•ç»“æœ
URLs: 1000ä¸ª
Workers: 20ä¸ª
å¹³å‡å“åº”æ—¶é—´: 1.8ç§’

é¡ºåºå¤„ç†: 1000 * 1.8s = 1800ç§’ = 30åˆ†é’Ÿ
å¹¶å‘å¤„ç†: (1000 / 20) * 1.8s = 90ç§’ = 1.5åˆ†é’Ÿ

æ€§èƒ½æå‡: 20å€
```

---

## ç¬¬äº”éƒ¨åˆ†ï¼šContextæ¨¡å¼ä¸ä¼˜é›…å…³é—­

### 5.1 Contextæ¨¡å¼

#### ä¸ºä»€ä¹ˆéœ€è¦Contextï¼Ÿ

**é—®é¢˜åœºæ™¯**:

```go
// âŒ æ²¡æœ‰Contextï¼šæ— æ³•å–æ¶ˆ
func doWork() {
    go func() {
        for {
            // æ°¸è¿œè¿è¡Œï¼Œæ— æ³•åœæ­¢
            work()
            time.Sleep(1 * time.Second)
        }
    }()
}
```

**ä½¿ç”¨Context**:

```go
// âœ… ä½¿ç”¨Contextï¼šå¯æ§åˆ¶ç”Ÿå‘½å‘¨æœŸ
func doWorkWithContext(ctx context.Context) {
    go func() {
        for {
            select {
            case <-ctx.Done():
                // æ”¶åˆ°å–æ¶ˆä¿¡å·ï¼Œä¼˜é›…é€€å‡º
                fmt.Println("Goroutine stopped")
                return
            default:
                work()
                time.Sleep(1 * time.Second)
            }
        }
    }()
}
```

---

### 5.2 Contextè¶…æ—¶æ§åˆ¶

#### å®Œæ•´ç¤ºä¾‹ï¼šHTTPè¯·æ±‚è¶…æ—¶

```go
func fetchWithTimeout(url string, timeout time.Duration) (string, error) {
    // åˆ›å»ºå¸¦è¶…æ—¶çš„context
    ctx, cancel := context.WithTimeout(context.Background(), timeout)
    defer cancel()
    
    req, err := http.NewRequestWithContext(ctx, "GET", url, nil)
    if err != nil {
        return "", err
    }
    
    resp, err := http.DefaultClient.Do(req)
    if err != nil {
        // æ£€æŸ¥æ˜¯å¦è¶…æ—¶
        if ctx.Err() == context.DeadlineExceeded {
            return "", fmt.Errorf("request timeout after %v", timeout)
        }
        return "", err
    }
    defer resp.Body.Close()
    
    body, err := io.ReadAll(resp.Body)
    return string(body), err
}
```

---

### 5.3 ä¼˜é›…å…³é—­å®Œæ•´æ¡ˆä¾‹

#### åœºæ™¯ï¼šHTTPæœåŠ¡å™¨ä¼˜é›…å…³é—­

```go
package main

import (
    "context"
    "fmt"
    "net/http"
    "os"
    "os/signal"
    "syscall"
    "time"
)

func main() {
    // åˆ›å»ºHTTPæœåŠ¡å™¨
    srv := &http.Server{
        Addr: ":8080",
        Handler: http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
            // æ¨¡æ‹Ÿæ…¢è¯·æ±‚
            time.Sleep(5 * time.Second)
            fmt.Fprintf(w, "Request completed\n")
        }),
    }
    
    // åœ¨goroutineä¸­å¯åŠ¨æœåŠ¡å™¨
    go func() {
        fmt.Println("Server starting on :8080")
        if err := srv.ListenAndServe(); err != nil && err != http.ErrServerClosed {
            fmt.Printf("Server error: %v\n", err)
        }
    }()
    
    // ç­‰å¾…ä¸­æ–­ä¿¡å·
    quit := make(chan os.Signal, 1)
    signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
    <-quit
    
    fmt.Println("\nShutting down server...")
    
    // åˆ›å»ºè¶…æ—¶context
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()
    
    // ä¼˜é›…å…³é—­
    if err := srv.Shutdown(ctx); err != nil {
        fmt.Printf("Server forced to shutdown: %v\n", err)
    }
    
    fmt.Println("Server exited")
}
```

---

## ç¬¬å…­éƒ¨åˆ†ï¼šå®æˆ˜æ¡ˆä¾‹

### 6.1 æ¡ˆä¾‹4ï¼šå®æ—¶æ•°æ®å¤„ç†ç³»ç»Ÿ

#### åœºæ™¯6

- Kafkaæ¶ˆè´¹æ¶ˆæ¯
- å®æ—¶è®¡ç®—å¤„ç†
- ç»“æœå†™å…¥æ•°æ®åº“
- è¦æ±‚ï¼šQPS 10000ï¼Œå»¶è¿Ÿ<100ms

#### æ¶æ„è®¾è®¡

```text
Kafka Consumer
      â†“
  [Pipeline]
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parse Stage  â”‚ â† è§£æJSON
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Compute Stage â”‚ â† ä¸šåŠ¡è®¡ç®—
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Worker Pool  â”‚ â† æ‰¹é‡å†™åº“
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### å®Œæ•´å®ç°ï¼ˆç®€åŒ–ç‰ˆï¼‰

```go
package realtime

import (
    "context"
    "encoding/json"
    "log"
    "time"
)

// Message æ¶ˆæ¯
type Message struct {
    ID     string
    Data   map[string]interface{}
    Time   time.Time
}

// ComputedResult è®¡ç®—ç»“æœ
type ComputedResult struct {
    ID     string
    Result float64
}

// RealtimeProcessor å®æ—¶å¤„ç†å™¨
type RealtimeProcessor struct {
    workerPool *WorkerPool
}

// NewRealtimeProcessor åˆ›å»ºå¤„ç†å™¨
func NewRealtimeProcessor() *RealtimeProcessor {
    return &RealtimeProcessor{
        workerPool: NewWorkerPool(runtime.NumCPU()),
    }
}

// ProcessStream å¤„ç†æ•°æ®æµ
func (p *RealtimeProcessor) ProcessStream(ctx context.Context, input <-chan []byte) {
    // Stage 1: è§£æJSON
    parsed := p.parseStage(ctx, input)
    
    // Stage 2: ä¸šåŠ¡è®¡ç®—
    computed := p.computeStage(ctx, parsed)
    
    // Stage 3: æ‰¹é‡å…¥åº“
    p.saveStage(ctx, computed)
}

// parseStage è§£æé˜¶æ®µ
func (p *RealtimeProcessor) parseStage(ctx context.Context, input <-chan []byte) <-chan Message {
    out := make(chan Message, 100)
    go func() {
        defer close(out)
        for data := range input {
            var msg Message
            if err := json.Unmarshal(data, &msg); err != nil {
                log.Printf("Parse error: %v\n", err)
                continue
            }
            
            select {
            case out <- msg:
            case <-ctx.Done():
                return
            }
        }
    }()
    return out
}

// computeStage è®¡ç®—é˜¶æ®µ
func (p *RealtimeProcessor) computeStage(ctx context.Context, input <-chan Message) <-chan ComputedResult {
    out := make(chan ComputedResult, 100)
    go func() {
        defer close(out)
        for msg := range input {
            // ä¸šåŠ¡è®¡ç®—
            result := businessCompute(msg.Data)
            
            select {
            case out <- ComputedResult{ID: msg.ID, Result: result}:
            case <-ctx.Done():
                return
            }
        }
    }()
    return out
}

// saveStage ä¿å­˜é˜¶æ®µï¼ˆæ‰¹é‡ï¼‰
func (p *RealtimeProcessor) saveStage(ctx context.Context, input <-chan ComputedResult) {
    batch := make([]ComputedResult, 0, 100)
    ticker := time.NewTicker(1 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case result, ok := <-input:
            if !ok {
                // channelå…³é—­ï¼Œä¿å­˜å‰©ä½™
                if len(batch) > 0 {
                    saveBatch(batch)
                }
                return
            }
            
            batch = append(batch, result)
            if len(batch) >= 100 {
                saveBatch(batch)
                batch = batch[:0]
            }
            
        case <-ticker.C:
            if len(batch) > 0 {
                saveBatch(batch)
                batch = batch[:0]
            }
            
        case <-ctx.Done():
            return
        }
    }
}

func businessCompute(data map[string]interface{}) float64 {
    // æ¨¡æ‹Ÿä¸šåŠ¡è®¡ç®—
    return 42.0
}

func saveBatch(results []ComputedResult) {
    // æ‰¹é‡å†™å…¥æ•°æ®åº“
    log.Printf("Saved batch of %d results\n", len(results))
}
```

---

## ç¬¬ä¸ƒéƒ¨åˆ†ï¼šæœ€ä½³å®è·µä¸é™·é˜±

### 7.1 å¹¶å‘æ¨¡å¼æœ€ä½³å®è·µ

#### âœ… DO

1. **æ€»æ˜¯å…³é—­ä½ åˆ›å»ºçš„channel**

    ```go
    // âœ… æ­£ç¡®
    func generator() <-chan int {
        ch := make(chan int)
        go func() {
            defer close(ch)  // â† å…³é”®ï¼
            for i := 0; i < 10; i++ {
                ch <- i
            }
        }()
        return ch
    }
    ```

2. **ä½¿ç”¨Contextæ§åˆ¶ç”Ÿå‘½å‘¨æœŸ**

    ```go
    // âœ… æ­£ç¡®
    func worker(ctx context.Context) {
        for {
            select {
            case <-ctx.Done():
                return  // â† ä¼˜é›…é€€å‡º
            default:
                work()
            }
        }
    }
    ```

3. **ä½¿ç”¨sync.WaitGroupç­‰å¾…å®Œæˆ**

    ```go
    // âœ… æ­£ç¡®
    var wg sync.WaitGroup
    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            work()
        }()
    }
    wg.Wait()  // ç­‰å¾…æ‰€æœ‰å®Œæˆ
    ```

#### âŒ DON'T

1. **ä¸è¦åœ¨æ¥æ”¶æ–¹å…³é—­channel**

    ```go
    // âŒ é”™è¯¯
    func consumer(ch <-chan int) {
        for v := range ch {
            process(v)
        }
        close(ch)  // â† panic! åªæœ‰å‘é€æ–¹èƒ½å…³é—­
    }
    ```

2. **ä¸è¦æ— é™åˆ¶åˆ›å»ºgoroutine**

    ```go
    // âŒ é”™è¯¯ï¼šå¯èƒ½åˆ›å»ºç™¾ä¸‡goroutine
    for _, item := range millionItems {
        go process(item)
    }

    // âœ… æ­£ç¡®ï¼šä½¿ç”¨Worker Pool
    pool := NewWorkerPool(100)
    for _, item := range millionItems {
        pool.Submit(func() { process(item) })
    }
    ```

3. **ä¸è¦å¿˜è®°å¤„ç†goroutine panic**

    ```go
    // âŒ é”™è¯¯
    go func() {
        mightPanic()  // panicä¼šå¯¼è‡´ç¨‹åºå´©æºƒ
    }()

    // âœ… æ­£ç¡®
    go func() {
        defer func() {
            if r := recover(); r != nil {
                log.Printf("Recovered: %v\n", r)
            }
        }()
        mightPanic()
    }()
    ```

---

### 7.2 å¸¸è§é™·é˜±

#### é™·é˜±1ï¼šgoroutineæ³„æ¼

```go
// âŒ æ³„æ¼ç¤ºä¾‹
func leak() {
    ch := make(chan int)
    go func() {
        val := <-ch  // â† æ°¸è¿œé˜»å¡ï¼ˆæ²¡äººå‘é€ï¼‰
        fmt.Println(val)
    }()
    // goroutineæ°¸è¿œä¸ä¼šé€€å‡º
}

// âœ… ä¿®å¤ï¼šä½¿ç”¨select + context
func fixed(ctx context.Context) {
    ch := make(chan int)
    go func() {
        select {
        case val := <-ch:
            fmt.Println(val)
        case <-ctx.Done():
            return  // â† å¯ä»¥é€€å‡º
        }
    }()
}
```

#### é™·é˜±2ï¼šchannelæ­»é”

```go
// âŒ æ­»é”
func deadlock() {
    ch := make(chan int)
    ch <- 1  // â† é˜»å¡ï¼æ²¡æœ‰æ¥æ”¶æ–¹
    fmt.Println(<-ch)
}

// âœ… ä¿®å¤ï¼šä½¿ç”¨goroutineæˆ–ç¼“å†²channel
func fixed1() {
    ch := make(chan int, 1)  // ç¼“å†²channel
    ch <- 1
    fmt.Println(<-ch)
}

func fixed2() {
    ch := make(chan int)
    go func() {
        ch <- 1
    }()
    fmt.Println(<-ch)
}
```

#### é™·é˜±3ï¼šç«æ€æ¡ä»¶

```go
// âŒ ç«æ€æ¡ä»¶
var counter int
for i := 0; i < 1000; i++ {
    go func() {
        counter++  // â† æ•°æ®ç«äº‰
    }()
}

// âœ… ä¿®å¤ï¼šä½¿ç”¨atomicæˆ–mutex
var counter int64
for i := 0; i < 1000; i++ {
    go func() {
        atomic.AddInt64(&counter, 1)
    }()
}
```

---

## ğŸ¯ æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **Pipelineæ¨¡å¼**:
   - âœ… é€‚åˆæµå¼æ•°æ®å¤„ç†
   - âœ… å„é˜¶æ®µå¹¶è¡Œæ‰§è¡Œ
   - âš ï¸ å—æœ€æ…¢é˜¶æ®µé™åˆ¶

2. **Worker Poolæ¨¡å¼**:
   - âœ… æ§åˆ¶å¹¶å‘æ•°é‡
   - âœ… å¤ç”¨goroutine
   - âœ… é€‚åˆæ‰¹é‡ä»»åŠ¡

3. **Fan-Out/Fan-Inæ¨¡å¼**:
   - âœ… æœ€å¤§åŒ–å¹¶è¡Œåº¦
   - âœ… é€‚åˆCPUå¯†é›†å‹
   - âš ï¸ éœ€è¦ç®¡ç†å¤šä¸ªchannel

4. **Contextæ¨¡å¼**:
   - âœ… ç»Ÿä¸€çš„å–æ¶ˆæœºåˆ¶
   - âœ… è¶…æ—¶æ§åˆ¶
   - âœ… ä¼ é€’è¯·æ±‚çº§æ•°æ®

### é€‰æ‹©æŒ‡å—

| åœºæ™¯ | æ¨èæ¨¡å¼ | ç†ç”± |
|------|---------|------|
| æ—¥å¿—å¤„ç† | Pipeline | å¤šé˜¶æ®µå¤„ç† |
| å›¾ç‰‡æ‰¹å¤„ç† | Worker Pool | æ§åˆ¶å¹¶å‘æ•° |
| åˆ†å¸ƒå¼è®¡ç®— | Fan-Out/Fan-In | æœ€å¤§å¹¶è¡Œåº¦ |
| HTTPè¯·æ±‚ | Context | è¶…æ—¶æ§åˆ¶ |

### æ€§èƒ½æå‡é¢„æœŸ

```text
Pipeline:      2-4å€ï¼ˆå–å†³äºé˜¶æ®µæ•°ï¼‰
Worker Pool:   Nå€ï¼ˆN=workeræ•°ï¼Œå—é™äºCPUï¼‰
Fan-Out/Fan-In: Nå€ï¼ˆN=å¹¶å‘æ•°ï¼‰
```

---

## ğŸ“š å‚è€ƒèµ„æº

**å®˜æ–¹èµ„æº**:

- [Go Concurrency Patterns](https://go.dev/blog/pipelines)
- [Advanced Go Concurrency Patterns](https://go.dev/blog/io2013-talk-concurrency)

**æ¨èé˜…è¯»**:

- [Concurrency in Go](https://www.oreilly.com/library/view/concurrency-in-go/9781491941294/)
- [Go in Action](https://www.manning.com/books/go-in-action)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v2.0  
**æœ€åæ›´æ–°**: 2025-10-20  
**ç»´æŠ¤è€…**: Go Concurrency Team

<div align="center">

Made with â¤ï¸ for Go Developers

[â¬† å›åˆ°é¡¶éƒ¨](#goå¹¶å‘æ¨¡å¼å®æˆ˜æ·±åº¦æŒ‡å—)

</div>
