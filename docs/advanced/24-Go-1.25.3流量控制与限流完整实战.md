# Go 1.25.3 流量控制与限流完整实战

**版本**: v1.0  
**更新日期**: 2025-10-29  
**适用于**: Go 1.25.3

---


## 📋 目录


- [📖 文档说明](#文档说明)
- [目录](#目录)
- [1. 令牌桶限流](#1-令牌桶限流)
  - [1.1 基础令牌桶](#1-1-基础令牌桶)
  - [1.2 令牌桶中间件](#1-2-令牌桶中间件)
- [2. 漏桶限流](#2-漏桶限流)
  - [2.1 漏桶实现](#2-1-漏桶实现)
  - [2.2 漏桶中间件](#2-2-漏桶中间件)
- [3. 滑动窗口限流](#3-滑动窗口限流)
  - [3.1 固定窗口](#3-1-固定窗口)
  - [3.2 滑动窗口](#3-2-滑动窗口)
- [4. 分布式限流](#4-分布式限流)
  - [4.1 Redis限流](#4-1-redis限流)
  - [4.2 分布式滑动窗口](#4-2-分布式滑动窗口)
- [5. 熔断降级](#5-熔断降级)
  - [5.1 熔断器](#5-1-熔断器)
  - [5.2 熔断中间件](#5-2-熔断中间件)
- [6. 自适应限流](#6-自适应限流)
  - [6.1 基于系统负载](#6-1-基于系统负载)
  - [6.2 动态调整](#6-2-动态调整)
- [7. 流量整形](#7-流量整形)
  - [7.1 优先级队列](#7-1-优先级队列)
  - [7.2 流量调度](#7-2-流量调度)
- [8. 完整案例](#8-完整案例)
  - [8.1 多级限流系统](#8-1-多级限流系统)
- [📚 限流最佳实践](#限流最佳实践)
  - [算法选择](#算法选择)
  - [限流策略](#限流策略)
  - [熔断策略](#熔断策略)
  - [监控告警](#监控告警)
- [🎯 总结](#总结)

## 📖 文档说明

本文档展示Go 1.25.3的**流量控制与限流完整方案**，构建高可用系统：

- ✅ 令牌桶算法
- ✅ 漏桶算法
- ✅ 滑动窗口限流
- ✅ 分布式限流
- ✅ 熔断降级
- ✅ 流量整形
- ✅ 动态限流
- ✅ 过载保护

---

## 目录

- [Go 1.25.3 流量控制与限流完整实战](#go-1-25-3-流量控制与限流完整实战)
  - [📖 文档说明](#文档说明)
  - [目录](#目录)
  - [1. 令牌桶限流](#1-令牌桶限流)
    - [1.1 基础令牌桶](#1-1-基础令牌桶)
    - [1.2 令牌桶中间件](#1-2-令牌桶中间件)
  - [2. 漏桶限流](#2-漏桶限流)
    - [2.1 漏桶实现](#2-1-漏桶实现)
    - [2.2 漏桶中间件](#2-2-漏桶中间件)
  - [3. 滑动窗口限流](#3-滑动窗口限流)
    - [3.1 固定窗口](#3-1-固定窗口)
    - [3.2 滑动窗口](#3-2-滑动窗口)
  - [4. 分布式限流](#4-分布式限流)
    - [4.1 Redis限流](#4-1-redis限流)
    - [4.2 分布式滑动窗口](#4-2-分布式滑动窗口)
  - [5. 熔断降级](#5-熔断降级)
    - [5.1 熔断器](#5-1-熔断器)
    - [5.2 熔断中间件](#5-2-熔断中间件)
  - [6. 自适应限流](#6-自适应限流)
    - [6.1 基于系统负载](#6-1-基于系统负载)
    - [6.2 动态调整](#6-2-动态调整)
  - [7. 流量整形](#7-流量整形)
    - [7.1 优先级队列](#7-1-优先级队列)
    - [7.2 流量调度](#7-2-流量调度)
  - [8. 完整案例](#8-完整案例)
    - [8.1 多级限流系统](#8-1-多级限流系统)
  - [📚 限流最佳实践](#限流最佳实践)
    - [算法选择](#算法选择)
    - [限流策略](#限流策略)
    - [熔断策略](#熔断策略)
    - [监控告警](#监控告警)
  - [🎯 总结](#总结)

---

## 1. 令牌桶限流

### 1.1 基础令牌桶

```go
package ratelimit

import (
 "context"
 "sync"
 "time"
)

// TokenBucket 令牌桶
type TokenBucket struct {
 rate       float64       // 令牌生成速率（每秒）
 capacity   float64       // 桶容量
 tokens     float64       // 当前令牌数
 lastRefill time.Time     // 上次填充时间
 mu         sync.Mutex
}

// NewTokenBucket 创建令牌桶
func NewTokenBucket(rate, capacity float64) *TokenBucket {
 return &TokenBucket{
  rate:       rate,
  capacity:   capacity,
  tokens:     capacity,
  lastRefill: time.Now(),
 }
}

// Allow 尝试获取令牌
func (tb *TokenBucket) Allow() bool {
 tb.mu.Lock()
 defer tb.mu.Unlock()
 
 // 填充令牌
 now := time.Now()
 elapsed := now.Sub(tb.lastRefill).Seconds()
 tb.tokens += elapsed * tb.rate
 
 if tb.tokens > tb.capacity {
  tb.tokens = tb.capacity
 }
 
 tb.lastRefill = now
 
 // 消费令牌
 if tb.tokens >= 1.0 {
  tb.tokens -= 1.0
  return true
 }
 
 return false
}

// AllowN 尝试获取N个令牌
func (tb *TokenBucket) AllowN(n int) bool {
 tb.mu.Lock()
 defer tb.mu.Unlock()
 
 // 填充令牌
 now := time.Now()
 elapsed := now.Sub(tb.lastRefill).Seconds()
 tb.tokens += elapsed * tb.rate
 
 if tb.tokens > tb.capacity {
  tb.tokens = tb.capacity
 }
 
 tb.lastRefill = now
 
 // 消费令牌
 needed := float64(n)
 if tb.tokens >= needed {
  tb.tokens -= needed
  return true
 }
 
 return false
}

// Wait 等待获取令牌
func (tb *TokenBucket) Wait(ctx context.Context) error {
 for {
  if tb.Allow() {
   return nil
  }
  
  select {
  case <-ctx.Done():
   return ctx.Err()
  case <-time.After(time.Millisecond * 10):
   // 继续尝试
  }
 }
}

// Available 获取可用令牌数
func (tb *TokenBucket) Available() float64 {
 tb.mu.Lock()
 defer tb.mu.Unlock()
 
 // 填充令牌
 now := time.Now()
 elapsed := now.Sub(tb.lastRefill).Seconds()
 tokens := tb.tokens + elapsed*tb.rate
 
 if tokens > tb.capacity {
  tokens = tb.capacity
 }
 
 return tokens
}
```

---

### 1.2 令牌桶中间件

```go
package middleware

import (
 "net/http"
)

// RateLimitMiddleware 限流中间件
func RateLimitMiddleware(limiter *ratelimit.TokenBucket) func(http.Handler) http.Handler {
 return func(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
   if !limiter.Allow() {
    http.Error(w, "Rate limit exceeded", http.StatusTooManyRequests)
    return
   }
   
   next.ServeHTTP(w, r)
  })
 }
}

// PerIPRateLimitMiddleware 按IP限流
func PerIPRateLimitMiddleware(rate, capacity float64) func(http.Handler) http.Handler {
 limiters := &sync.Map{}
 
 return func(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
   ip := getClientIP(r)
   
   // 获取或创建限流器
   limiter, _ := limiters.LoadOrStore(ip, ratelimit.NewTokenBucket(rate, capacity))
   
   if !limiter.(*ratelimit.TokenBucket).Allow() {
    http.Error(w, "Rate limit exceeded", http.StatusTooManyRequests)
    return
   }
   
   next.ServeHTTP(w, r)
  })
 }
}

// getClientIP 获取客户端IP
func getClientIP(r *http.Request) string {
 // 尝试从X-Forwarded-For获取
 if xff := r.Header.Get("X-Forwarded-For"); xff != "" {
  return xff
 }
 
 // 尝试从X-Real-IP获取
 if xri := r.Header.Get("X-Real-IP"); xri != "" {
  return xri
 }
 
 // 使用RemoteAddr
 return r.RemoteAddr
}
```

---

## 2. 漏桶限流

### 2.1 漏桶实现

```go
package ratelimit

import (
 "sync"
 "time"
)

// LeakyBucket 漏桶
type LeakyBucket struct {
 rate       float64   // 漏出速率（每秒）
 capacity   int       // 桶容量
 queue      []time.Time // 请求队列
 mu         sync.Mutex
}

// NewLeakyBucket 创建漏桶
func NewLeakyBucket(rate float64, capacity int) *LeakyBucket {
 return &LeakyBucket{
  rate:     rate,
  capacity: capacity,
  queue:    make([]time.Time, 0, capacity),
 }
}

// Allow 尝试添加请求
func (lb *LeakyBucket) Allow() bool {
 lb.mu.Lock()
 defer lb.mu.Unlock()
 
 now := time.Now()
 
 // 移除已处理的请求
 lb.leak(now)
 
 // 检查容量
 if len(lb.queue) >= lb.capacity {
  return false
 }
 
 // 添加请求
 lb.queue = append(lb.queue, now)
 return true
}

// leak 漏出请求
func (lb *LeakyBucket) leak(now time.Time) {
 // 计算应该处理的请求数
 if len(lb.queue) == 0 {
  return
 }
 
 // 计算从第一个请求到现在可以处理的请求数
 firstReq := lb.queue[0]
 elapsed := now.Sub(firstReq).Seconds()
 processed := int(elapsed * lb.rate)
 
 if processed > 0 {
  if processed >= len(lb.queue) {
   lb.queue = lb.queue[:0]
  } else {
   lb.queue = lb.queue[processed:]
  }
 }
}

// Size 获取队列大小
func (lb *LeakyBucket) Size() int {
 lb.mu.Lock()
 defer lb.mu.Unlock()
 
 lb.leak(time.Now())
 return len(lb.queue)
}
```

---

### 2.2 漏桶中间件

```go
// LeakyBucketMiddleware 漏桶限流中间件
func LeakyBucketMiddleware(limiter *ratelimit.LeakyBucket) func(http.Handler) http.Handler {
 return func(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
   if !limiter.Allow() {
    http.Error(w, "Rate limit exceeded", http.StatusTooManyRequests)
    return
   }
   
   next.ServeHTTP(w, r)
  })
 }
}
```

---

## 3. 滑动窗口限流

### 3.1 固定窗口

```go
package ratelimit

import (
 "sync"
 "time"
)

// FixedWindow 固定窗口限流
type FixedWindow struct {
 limit    int           // 限流阈值
 window   time.Duration // 窗口大小
 count    int           // 当前计数
 reset    time.Time     // 重置时间
 mu       sync.Mutex
}

// NewFixedWindow 创建固定窗口
func NewFixedWindow(limit int, window time.Duration) *FixedWindow {
 return &FixedWindow{
  limit:  limit,
  window: window,
  reset:  time.Now().Add(window),
 }
}

// Allow 尝试通过
func (fw *FixedWindow) Allow() bool {
 fw.mu.Lock()
 defer fw.mu.Unlock()
 
 now := time.Now()
 
 // 检查是否需要重置
 if now.After(fw.reset) {
  fw.count = 0
  fw.reset = now.Add(fw.window)
 }
 
 // 检查限流
 if fw.count >= fw.limit {
  return false
 }
 
 fw.count++
 return true
}
```

---

### 3.2 滑动窗口

```go
// SlidingWindow 滑动窗口限流
type SlidingWindow struct {
 limit    int           // 限流阈值
 window   time.Duration // 窗口大小
 requests []time.Time   // 请求时间戳
 mu       sync.Mutex
}

// NewSlidingWindow 创建滑动窗口
func NewSlidingWindow(limit int, window time.Duration) *SlidingWindow {
 return &SlidingWindow{
  limit:    limit,
  window:   window,
  requests: make([]time.Time, 0, limit),
 }
}

// Allow 尝试通过
func (sw *SlidingWindow) Allow() bool {
 sw.mu.Lock()
 defer sw.mu.Unlock()
 
 now := time.Now()
 cutoff := now.Add(-sw.window)
 
 // 移除过期请求
 valid := 0
 for _, req := range sw.requests {
  if req.After(cutoff) {
   sw.requests[valid] = req
   valid++
  }
 }
 sw.requests = sw.requests[:valid]
 
 // 检查限流
 if len(sw.requests) >= sw.limit {
  return false
 }
 
 // 添加请求
 sw.requests = append(sw.requests, now)
 return true
}

// Count 获取当前请求数
func (sw *SlidingWindow) Count() int {
 sw.mu.Lock()
 defer sw.mu.Unlock()
 
 now := time.Now()
 cutoff := now.Add(-sw.window)
 
 count := 0
 for _, req := range sw.requests {
  if req.After(cutoff) {
   count++
  }
 }
 
 return count
}
```

---

## 4. 分布式限流

### 4.1 Redis限流

```go
package ratelimit

import (
 "context"
 "time"
 
 "github.com/redis/go-redis/v9"
)

// RedisRateLimiter Redis限流器
type RedisRateLimiter struct {
 client *redis.Client
 key    string
 limit  int
 window time.Duration
}

// NewRedisRateLimiter 创建Redis限流器
func NewRedisRateLimiter(client *redis.Client, key string, limit int, window time.Duration) *RedisRateLimiter {
 return &RedisRateLimiter{
  client: client,
  key:    key,
  limit:  limit,
  window: window,
 }
}

// Allow 尝试通过（使用Lua脚本保证原子性）
func (rrl *RedisRateLimiter) Allow(ctx context.Context) (bool, error) {
 // Lua脚本实现滑动窗口
 script := `
  local key = KEYS[1]
  local limit = tonumber(ARGV[1])
  local window = tonumber(ARGV[2])
  local now = tonumber(ARGV[3])
  local cutoff = now - window
  
  -- 移除过期记录
  redis.call('ZREMRANGEBYSCORE', key, 0, cutoff)
  
  -- 获取当前数量
  local count = redis.call('ZCARD', key)
  
  if count < limit then
   -- 添加当前请求
   redis.call('ZADD', key, now, now)
   redis.call('EXPIRE', key, window)
   return 1
  else
   return 0
  end
 `
 
 now := time.Now().UnixNano()
 result, err := rrl.client.Eval(ctx, script, []string{rrl.key}, 
  rrl.limit, rrl.window.Nanoseconds(), now).Int()
 
 if err != nil {
  return false, err
 }
 
 return result == 1, nil
}

// Count 获取当前请求数
func (rrl *RedisRateLimiter) Count(ctx context.Context) (int64, error) {
 now := time.Now().UnixNano()
 cutoff := now - rrl.window.Nanoseconds()
 
 // 移除过期记录
 rrl.client.ZRemRangeByScore(ctx, rrl.key, "0", fmt.Sprint(cutoff))
 
 // 获取当前数量
 return rrl.client.ZCard(ctx, rrl.key).Result()
}
```

---

### 4.2 分布式滑动窗口

```go
// RedisTokenBucket Redis令牌桶
type RedisTokenBucket struct {
 client   *redis.Client
 key      string
 rate     float64
 capacity float64
}

// NewRedisTokenBucket 创建Redis令牌桶
func NewRedisTokenBucket(client *redis.Client, key string, rate, capacity float64) *RedisTokenBucket {
 return &RedisTokenBucket{
  client:   client,
  key:      key,
  rate:     rate,
  capacity: capacity,
 }
}

// Allow 尝试获取令牌
func (rtb *RedisTokenBucket) Allow(ctx context.Context) (bool, error) {
 // Lua脚本实现令牌桶
 script := `
  local key = KEYS[1]
  local rate = tonumber(ARGV[1])
  local capacity = tonumber(ARGV[2])
  local now = tonumber(ARGV[3])
  
  -- 获取当前状态
  local tokens = tonumber(redis.call('HGET', key, 'tokens') or capacity)
  local last_refill = tonumber(redis.call('HGET', key, 'last_refill') or now)
  
  -- 计算新令牌
  local elapsed = (now - last_refill) / 1000000000
  tokens = tokens + elapsed * rate
  
  if tokens > capacity then
   tokens = capacity
  end
  
  -- 尝试消费令牌
  if tokens >= 1 then
   tokens = tokens - 1
   redis.call('HSET', key, 'tokens', tokens)
   redis.call('HSET', key, 'last_refill', now)
   redis.call('EXPIRE', key, 60)
   return 1
  else
   redis.call('HSET', key, 'tokens', tokens)
   redis.call('HSET', key, 'last_refill', now)
   return 0
  end
 `
 
 now := time.Now().UnixNano()
 result, err := rtb.client.Eval(ctx, script, []string{rtb.key}, 
  rtb.rate, rtb.capacity, now).Int()
 
 if err != nil {
  return false, err
 }
 
 return result == 1, nil
}
```

---

## 5. 熔断降级

### 5.1 熔断器

```go
package circuitbreaker

import (
 "errors"
 "sync"
 "time"
)

// State 熔断器状态
type State int

const (
 StateClosed State = iota // 关闭（正常）
 StateOpen                // 打开（熔断）
 StateHalfOpen            // 半开（尝试恢复）
)

// CircuitBreaker 熔断器
type CircuitBreaker struct {
 maxRequests  uint32        // 半开状态最大请求数
 interval     time.Duration // 统计周期
 timeout      time.Duration // 熔断超时时间
 readyToTrip  func(counts Counts) bool // 判断是否熔断
 onStateChange func(from, to State)    // 状态变化回调
 
 mu          sync.Mutex
 state       State
 generation  uint64
 counts      Counts
 expiry      time.Time
}

// Counts 统计数据
type Counts struct {
 Requests             uint32
 TotalSuccesses       uint32
 TotalFailures        uint32
 ConsecutiveSuccesses uint32
 ConsecutiveFailures  uint32
}

// NewCircuitBreaker 创建熔断器
func NewCircuitBreaker(settings Settings) *CircuitBreaker {
 cb := &CircuitBreaker{
  maxRequests: settings.MaxRequests,
  interval:    settings.Interval,
  timeout:     settings.Timeout,
  readyToTrip: settings.ReadyToTrip,
  onStateChange: settings.OnStateChange,
  state:       StateClosed,
 }
 
 if cb.maxRequests == 0 {
  cb.maxRequests = 1
 }
 
 if cb.interval == 0 {
  cb.interval = time.Minute
 }
 
 if cb.timeout == 0 {
  cb.timeout = time.Minute
 }
 
 if cb.readyToTrip == nil {
  cb.readyToTrip = defaultReadyToTrip
 }
 
 return cb
}

// Settings 熔断器配置
type Settings struct {
 MaxRequests   uint32
 Interval      time.Duration
 Timeout       time.Duration
 ReadyToTrip   func(counts Counts) bool
 OnStateChange func(from, to State)
}

// Execute 执行函数
func (cb *CircuitBreaker) Execute(req func() (interface{}, error)) (interface{}, error) {
 generation, err := cb.beforeRequest()
 if err != nil {
  return nil, err
 }
 
 defer func() {
  e := recover()
  if e != nil {
   cb.afterRequest(generation, false)
   panic(e)
  }
 }()
 
 result, err := req()
 cb.afterRequest(generation, err == nil)
 return result, err
}

// beforeRequest 请求前检查
func (cb *CircuitBreaker) beforeRequest() (uint64, error) {
 cb.mu.Lock()
 defer cb.mu.Unlock()
 
 now := time.Now()
 state, generation := cb.currentState(now)
 
 if state == StateOpen {
  return generation, errors.New("circuit breaker is open")
 } else if state == StateHalfOpen && cb.counts.Requests >= cb.maxRequests {
  return generation, errors.New("too many requests")
 }
 
 cb.counts.Requests++
 return generation, nil
}

// afterRequest 请求后处理
func (cb *CircuitBreaker) afterRequest(before uint64, success bool) {
 cb.mu.Lock()
 defer cb.mu.Unlock()
 
 now := time.Now()
 state, generation := cb.currentState(now)
 
 if generation != before {
  return
 }
 
 if success {
  cb.onSuccess(state, now)
 } else {
  cb.onFailure(state, now)
 }
}

// onSuccess 成功处理
func (cb *CircuitBreaker) onSuccess(state State, now time.Time) {
 cb.counts.TotalSuccesses++
 cb.counts.ConsecutiveSuccesses++
 cb.counts.ConsecutiveFailures = 0
 
 if state == StateHalfOpen {
  // 半开状态，尝试关闭
  cb.setState(StateClosed, now)
 }
}

// onFailure 失败处理
func (cb *CircuitBreaker) onFailure(state State, now time.Time) {
 cb.counts.TotalFailures++
 cb.counts.ConsecutiveFailures++
 cb.counts.ConsecutiveSuccesses = 0
 
 if cb.readyToTrip(cb.counts) {
  cb.setState(StateOpen, now)
 }
}

// currentState 获取当前状态
func (cb *CircuitBreaker) currentState(now time.Time) (State, uint64) {
 switch cb.state {
 case StateClosed:
  if !cb.expiry.IsZero() && cb.expiry.Before(now) {
   cb.toNewGeneration(now)
  }
 case StateOpen:
  if cb.expiry.Before(now) {
   cb.setState(StateHalfOpen, now)
  }
 }
 
 return cb.state, cb.generation
}

// setState 设置状态
func (cb *CircuitBreaker) setState(state State, now time.Time) {
 if cb.state == state {
  return
 }
 
 prev := cb.state
 cb.state = state
 
 cb.toNewGeneration(now)
 
 if cb.onStateChange != nil {
  cb.onStateChange(prev, state)
 }
}

// toNewGeneration 进入新周期
func (cb *CircuitBreaker) toNewGeneration(now time.Time) {
 cb.generation++
 cb.counts = Counts{}
 
 var zero time.Time
 switch cb.state {
 case StateClosed:
  if cb.interval == 0 {
   cb.expiry = zero
  } else {
   cb.expiry = now.Add(cb.interval)
  }
 case StateOpen:
  cb.expiry = now.Add(cb.timeout)
 default:
  cb.expiry = zero
 }
}

// defaultReadyToTrip 默认熔断判断
func defaultReadyToTrip(counts Counts) bool {
 return counts.ConsecutiveFailures > 5
}

// State 获取状态
func (cb *CircuitBreaker) State() State {
 cb.mu.Lock()
 defer cb.mu.Unlock()
 
 now := time.Now()
 state, _ := cb.currentState(now)
 return state
}
```

---

### 5.2 熔断中间件

```go
// CircuitBreakerMiddleware 熔断中间件
func CircuitBreakerMiddleware(cb *circuitbreaker.CircuitBreaker) func(http.Handler) http.Handler {
 return func(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
   _, err := cb.Execute(func() (interface{}, error) {
    recorder := &statusRecorder{
     ResponseWriter: w,
     statusCode:     http.StatusOK,
    }
    
    next.ServeHTTP(recorder, r)
    
    if recorder.statusCode >= 500 {
     return nil, errors.New("server error")
    }
    
    return nil, nil
   })
   
   if err != nil {
    http.Error(w, "Service unavailable", http.StatusServiceUnavailable)
    return
   }
  })
 }
}
```

---

## 6. 自适应限流

### 6.1 基于系统负载

```go
package adaptive

import (
 "runtime"
 "sync"
 "time"
)

// AdaptiveLimiter 自适应限流器
type AdaptiveLimiter struct {
 minRate      float64
 maxRate      float64
 currentRate  float64
 targetCPU    float64
 adjustPeriod time.Duration
 
 mu sync.RWMutex
 tb *ratelimit.TokenBucket
}

// NewAdaptiveLimiter 创建自适应限流器
func NewAdaptiveLimiter(minRate, maxRate, targetCPU float64) *AdaptiveLimiter {
 al := &AdaptiveLimiter{
  minRate:      minRate,
  maxRate:      maxRate,
  currentRate:  maxRate,
  targetCPU:    targetCPU,
  adjustPeriod: time.Second,
  tb:           ratelimit.NewTokenBucket(maxRate, maxRate),
 }
 
 go al.adjustRate()
 
 return al
}

// Allow 尝试通过
func (al *AdaptiveLimiter) Allow() bool {
 al.mu.RLock()
 defer al.mu.RUnlock()
 
 return al.tb.Allow()
}

// adjustRate 调整速率
func (al *AdaptiveLimiter) adjustRate() {
 ticker := time.NewTicker(al.adjustPeriod)
 defer ticker.Stop()
 
 for range ticker.C {
  cpuPercent := getCPUUsage()
  
  al.mu.Lock()
  
  if cpuPercent > al.targetCPU {
   // CPU使用率高，降低速率
   al.currentRate *= 0.9
   if al.currentRate < al.minRate {
    al.currentRate = al.minRate
   }
  } else if cpuPercent < al.targetCPU*0.8 {
   // CPU使用率低，提高速率
   al.currentRate *= 1.1
   if al.currentRate > al.maxRate {
    al.currentRate = al.maxRate
   }
  }
  
  // 更新令牌桶速率
  al.tb = ratelimit.NewTokenBucket(al.currentRate, al.currentRate)
  
  al.mu.Unlock()
 }
}

// getCPUUsage 获取CPU使用率
func getCPUUsage() float64 {
 var m runtime.MemStats
 runtime.ReadMemStats(&m)
 
 // 简化实现，实际应该使用更准确的CPU监控
 return float64(runtime.NumGoroutine()) / float64(runtime.NumCPU()) * 10
}

// CurrentRate 获取当前速率
func (al *AdaptiveLimiter) CurrentRate() float64 {
 al.mu.RLock()
 defer al.mu.RUnlock()
 
 return al.currentRate
}
```

---

### 6.2 动态调整

```go
// DynamicLimiter 动态限流器
type DynamicLimiter struct {
 rates       map[string]float64 // 不同级别的速率
 currentTier string
 
 mu sync.RWMutex
 tb *ratelimit.TokenBucket
}

// NewDynamicLimiter 创建动态限流器
func NewDynamicLimiter(rates map[string]float64, initialTier string) *DynamicLimiter {
 rate := rates[initialTier]
 
 return &DynamicLimiter{
  rates:       rates,
  currentTier: initialTier,
  tb:          ratelimit.NewTokenBucket(rate, rate),
 }
}

// Allow 尝试通过
func (dl *DynamicLimiter) Allow() bool {
 dl.mu.RLock()
 defer dl.mu.RUnlock()
 
 return dl.tb.Allow()
}

// SetTier 设置级别
func (dl *DynamicLimiter) SetTier(tier string) {
 dl.mu.Lock()
 defer dl.mu.Unlock()
 
 rate, ok := dl.rates[tier]
 if !ok {
  return
 }
 
 dl.currentTier = tier
 dl.tb = ratelimit.NewTokenBucket(rate, rate)
}

// CurrentTier 获取当前级别
func (dl *DynamicLimiter) CurrentTier() string {
 dl.mu.RLock()
 defer dl.mu.RUnlock()
 
 return dl.currentTier
}
```

---

## 7. 流量整形

### 7.1 优先级队列

```go
package trafficshaping

import (
 "container/heap"
 "sync"
 "time"
)

// Request 请求
type Request struct {
 ID        string
 Priority  int
 Timestamp time.Time
 Handler   func()
 index     int
}

// PriorityQueue 优先级队列
type PriorityQueue []*Request

func (pq PriorityQueue) Len() int { return len(pq) }

func (pq PriorityQueue) Less(i, j int) bool {
 // 优先级高的在前
 if pq[i].Priority != pq[j].Priority {
  return pq[i].Priority > pq[j].Priority
 }
 // 优先级相同，时间早的在前
 return pq[i].Timestamp.Before(pq[j].Timestamp)
}

func (pq PriorityQueue) Swap(i, j int) {
 pq[i], pq[j] = pq[j], pq[i]
 pq[i].index = i
 pq[j].index = j
}

func (pq *PriorityQueue) Push(x interface{}) {
 n := len(*pq)
 item := x.(*Request)
 item.index = n
 *pq = append(*pq, item)
}

func (pq *PriorityQueue) Pop() interface{} {
 old := *pq
 n := len(old)
 item := old[n-1]
 old[n-1] = nil
 item.index = -1
 *pq = old[0 : n-1]
 return item
}

// TrafficShaper 流量整形器
type TrafficShaper struct {
 concurrency int
 queue       PriorityQueue
 mu          sync.Mutex
 cond        *sync.Cond
 active      int
 closed      bool
}

// NewTrafficShaper 创建流量整形器
func NewTrafficShaper(concurrency int) *TrafficShaper {
 ts := &TrafficShaper{
  concurrency: concurrency,
  queue:       make(PriorityQueue, 0),
 }
 ts.cond = sync.NewCond(&ts.mu)
 
 heap.Init(&ts.queue)
 
 go ts.process()
 
 return ts
}

// Submit 提交请求
func (ts *TrafficShaper) Submit(req *Request) {
 ts.mu.Lock()
 defer ts.mu.Unlock()
 
 heap.Push(&ts.queue, req)
 ts.cond.Signal()
}

// process 处理请求
func (ts *TrafficShaper) process() {
 for {
  ts.mu.Lock()
  
  // 等待请求或槽位
  for len(ts.queue) == 0 || ts.active >= ts.concurrency {
   if ts.closed {
    ts.mu.Unlock()
    return
   }
   ts.cond.Wait()
  }
  
  // 获取请求
  req := heap.Pop(&ts.queue).(*Request)
  ts.active++
  ts.mu.Unlock()
  
  // 执行请求
  go func(r *Request) {
   defer func() {
    ts.mu.Lock()
    ts.active--
    ts.cond.Signal()
    ts.mu.Unlock()
   }()
   
   r.Handler()
  }(req)
 }
}

// Close 关闭
func (ts *TrafficShaper) Close() {
 ts.mu.Lock()
 defer ts.mu.Unlock()
 
 ts.closed = true
 ts.cond.Broadcast()
}
```

---

### 7.2 流量调度

```go
// Scheduler 流量调度器
type Scheduler struct {
 shapers map[string]*TrafficShaper
 mu      sync.RWMutex
}

// NewScheduler 创建调度器
func NewScheduler() *Scheduler {
 return &Scheduler{
  shapers: make(map[string]*TrafficShaper),
 }
}

// RegisterShaper 注册整形器
func (s *Scheduler) RegisterShaper(name string, concurrency int) {
 s.mu.Lock()
 defer s.mu.Unlock()
 
 s.shapers[name] = NewTrafficShaper(concurrency)
}

// Submit 提交请求
func (s *Scheduler) Submit(shaper string, req *Request) error {
 s.mu.RLock()
 ts, ok := s.shapers[shaper]
 s.mu.RUnlock()
 
 if !ok {
  return errors.New("shaper not found")
 }
 
 ts.Submit(req)
 return nil
}
```

---

## 8. 完整案例

### 8.1 多级限流系统

```go
package main

import (
 "context"
 "log"
 "net/http"
 "time"
)

// MultiLevelRateLimiter 多级限流系统
type MultiLevelRateLimiter struct {
 // 全局限流
 global *ratelimit.TokenBucket
 
 // IP限流
 perIP *sync.Map
 
 // 用户限流
 perUser *sync.Map
 
 // Redis分布式限流
 redis *ratelimit.RedisRateLimiter
 
 // 熔断器
 breaker *circuitbreaker.CircuitBreaker
 
 // 自适应限流
 adaptive *adaptive.AdaptiveLimiter
}

// NewMultiLevelRateLimiter 创建多级限流系统
func NewMultiLevelRateLimiter(redisClient *redis.Client) *MultiLevelRateLimiter {
 return &MultiLevelRateLimiter{
  global:   ratelimit.NewTokenBucket(10000, 10000), // 全局10000 QPS
  perIP:    &sync.Map{},
  perUser:  &sync.Map{},
  redis:    ratelimit.NewRedisRateLimiter(redisClient, "global", 50000, time.Minute),
  breaker:  circuitbreaker.NewCircuitBreaker(circuitbreaker.Settings{
   MaxRequests: 100,
   Interval:    time.Minute,
   Timeout:     time.Minute,
  }),
  adaptive: adaptive.NewAdaptiveLimiter(1000, 10000, 70.0), // 目标CPU 70%
 }
}

// Middleware 限流中间件
func (mlrl *MultiLevelRateLimiter) Middleware(next http.Handler) http.Handler {
 return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
  ctx := r.Context()
  
  // 1. 检查全局限流
  if !mlrl.global.Allow() {
   http.Error(w, "Global rate limit exceeded", http.StatusTooManyRequests)
   return
  }
  
  // 2. 检查分布式限流
  allowed, err := mlrl.redis.Allow(ctx)
  if err != nil || !allowed {
   http.Error(w, "Distributed rate limit exceeded", http.StatusTooManyRequests)
   return
  }
  
  // 3. 检查IP限流
  ip := getClientIP(r)
  ipLimiter, _ := mlrl.perIP.LoadOrStore(ip, ratelimit.NewTokenBucket(100, 100))
  if !ipLimiter.(*ratelimit.TokenBucket).Allow() {
   http.Error(w, "IP rate limit exceeded", http.StatusTooManyRequests)
   return
  }
  
  // 4. 检查用户限流
  userID := getUserID(r)
  if userID != "" {
   userLimiter, _ := mlrl.perUser.LoadOrStore(userID, ratelimit.NewTokenBucket(1000, 1000))
   if !userLimiter.(*ratelimit.TokenBucket).Allow() {
    http.Error(w, "User rate limit exceeded", http.StatusTooManyRequests)
    return
   }
  }
  
  // 5. 检查自适应限流
  if !mlrl.adaptive.Allow() {
   http.Error(w, "System overload", http.StatusServiceUnavailable)
   return
  }
  
  // 6. 熔断检查
  _, err = mlrl.breaker.Execute(func() (interface{}, error) {
   recorder := &statusRecorder{
    ResponseWriter: w,
    statusCode:     http.StatusOK,
   }
   
   next.ServeHTTP(recorder, r)
   
   if recorder.statusCode >= 500 {
    return nil, errors.New("server error")
   }
   
   return nil, nil
  })
  
  if err != nil {
   http.Error(w, "Service unavailable", http.StatusServiceUnavailable)
   return
  }
 })
}

func main() {
 // 1. 创建Redis客户端
 redisClient := redis.NewClient(&redis.Options{
  Addr: "localhost:6379",
 })
 
 // 2. 创建多级限流系统
 limiter := NewMultiLevelRateLimiter(redisClient)
 
 // 3. 创建HTTP服务器
 mux := http.NewServeMux()
 
 mux.HandleFunc("/api/users", func(w http.ResponseWriter, r *http.Request) {
  w.WriteHeader(http.StatusOK)
  w.Write([]byte(`{"status":"ok"}`))
 })
 
 // 应用限流中间件
 handler := limiter.Middleware(mux)
 
 // 4. 启动服务器
 server := &http.Server{
  Addr:    ":8080",
  Handler: handler,
 }
 
 log.Println("Server starting on :8080")
 log.Fatal(server.ListenAndServe())
}

func getUserID(r *http.Request) string {
 // 从请求中获取用户ID（例如从JWT中）
 // 简化实现
 return r.Header.Get("X-User-ID")
}

type statusRecorder struct {
 http.ResponseWriter
 statusCode int
}

func (sr *statusRecorder) WriteHeader(code int) {
 sr.statusCode = code
 sr.ResponseWriter.WriteHeader(code)
}
```

---

## 📚 限流最佳实践

### 算法选择

- ✅ **令牌桶**: 允许突发流量，适合API网关
- ✅ **漏桶**: 平滑输出，适合消息队列
- ✅ **滑动窗口**: 精确限流，适合高精度场景
- ✅ **分布式限流**: 集群环境必备

### 限流策略

- ✅ 全局限流 + IP限流 + 用户限流
- ✅ 区分读写操作
- ✅ 不同接口不同限制
- ✅ VIP用户特殊对待

### 熔断策略

- ✅ 错误率阈值
- ✅ 响应时间阈值
- ✅ 半开状态尝试
- ✅ 降级方案

### 监控告警

- ✅ 限流触发率
- ✅ 熔断器状态
- ✅ 系统负载
- ✅ 响应时间

---

## 🎯 总结

Go 1.25.3流量控制关键点：

1. **令牌桶**: 允许突发、平滑限流
2. **漏桶**: 平滑输出、队列处理
3. **滑动窗口**: 精确限流、实时统计
4. **分布式限流**: Redis、Lua脚本、原子性
5. **熔断降级**: 状态机、自动恢复、降级策略
6. **自适应限流**: 动态调整、负载感知
7. **流量整形**: 优先级队列、并发控制

**流量控制是高可用系统的第一道防线！**

---

<div align="center">

**构建稳定可靠的Go服务**:

[📚 返回目录](../README.md) | [📖 下一章](25-API网关完整实战.md)

Made with ❤️ for Go Developers

</div>

---

**文档版本**: v1.0  
**最后更新**: 2025-10-29  
**Go版本**: Go 1.25.3  
**生产就绪**: ✅
