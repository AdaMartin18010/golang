# 性能调优实战

## 📋 目录

- [性能调优实战](#性能调优实战)
  - [📋 目录](#-目录)
  - [1. 调优方法论](#1-调优方法论)
    - [性能调优流程](#性能调优流程)
    - [建立性能基准](#建立性能基准)
  - [2. 识别性能瓶颈](#2-识别性能瓶颈)
    - [使用pprof分析](#使用pprof分析)
  - [3. CPU优化实战](#3-cpu优化实战)
    - [案例1: 热点函数优化](#案例1-热点函数优化)
    - [案例2: 避免不必要的计算](#案例2-避免不必要的计算)
  - [4. 内存优化实战](#4-内存优化实战)
    - [案例1: 内存泄漏排查](#案例1-内存泄漏排查)
    - [案例2: Goroutine泄漏](#案例2-goroutine泄漏)
  - [5. I/O优化实战](#5-io优化实战)
    - [案例1: 文件I/O优化](#案例1-文件io优化)
    - [案例2: 网络I/O优化](#案例2-网络io优化)
  - [6. 并发优化实战](#6-并发优化实战)
    - [案例: 图片批处理服务](#案例-图片批处理服务)
  - [7. 数据库优化实战](#7-数据库优化实战)
    - [案例: 订单查询优化](#案例-订单查询优化)
  - [8. 网络优化实战](#8-网络优化实战)
    - [HTTP服务器优化](#http服务器优化)
  - [9. 完整优化案例](#9-完整优化案例)
    - [API服务端到端优化](#api服务端到端优化)
      - [第1轮: CPU优化](#第1轮-cpu优化)
      - [第2轮: 内存优化](#第2轮-内存优化)
      - [第3轮: 数据库优化](#第3轮-数据库优化)
      - [第4轮: 并发优化](#第4轮-并发优化)
  - [🔗 相关资源](#-相关资源)

## 1. 调优方法论

### 性能调优流程

```
1. 建立基准 (Baseline)
   ↓
2. 性能分析 (Profile)
   ↓
3. 识别瓶颈 (Identify Bottleneck)
   ↓
4. 优化实施 (Optimize)
   ↓
5. 验证效果 (Validate)
   ↓
6. 重复 2-5 (Iterate)
```

**核心原则**:

- ✅ 先测量，再优化
- ✅ 关注主要瓶颈（80/20法则）
- ✅ 一次优化一个点
- ✅ 每次优化后验证

---

### 建立性能基准

```go
// benchmark_test.go
package main

import (
    "testing"
)

func BenchmarkOriginal(b *testing.B) {
    for i := 0; i < b.N; i++ {
        processRequest()
    }
}

// 运行基准测试
// go test -bench=. -benchmem -cpuprofile=cpu.prof -memprofile=mem.prof
```

**关键指标**:

- **响应时间**: P50, P95, P99延迟
- **吞吐量**: QPS/TPS
- **资源使用**: CPU%, Memory, I/O
- **错误率**: Error rate

---

## 2. 识别性能瓶颈

### 使用pprof分析

```go
import (
    _ "net/http/pprof"
    "net/http"
)

func main() {
    // 启动pprof服务器
    go func() {
        http.ListenAndServe("localhost:6060", nil)
    }()

    // 应用主逻辑
    runApp()
}
```

**分析CPU热点**:

```bash
# 采集30秒CPU profile
curl http://localhost:6060/debug/pprof/profile?seconds=30 > cpu.prof

# 查看火焰图
go tool pprof -http=:8080 cpu.prof

# 查看top函数
go tool pprof cpu.prof
> top 20
```

**分析内存分配**:

```bash
# 采集堆快照
curl http://localhost:6060/debug/pprof/heap > heap.prof

# 分析内存分配
go tool pprof heap.prof
> top 20 -alloc_space
```

---

## 3. CPU优化实战

### 案例1: 热点函数优化

**问题**: CPU占用高，主要在字符串处理

```go
// ❌ 优化前 - CPU: 80%
func processLogs(logs []string) []string {
    var results []string
    for _, log := range logs {
        // 多次字符串拼接
        result := "[" + time.Now().Format("2006-01-02") + "] " +
                  strings.ToUpper(log) + " - processed"
        results = append(results, result)
    }
    return results
}

// 基准测试结果:
// BenchmarkProcessLogs-8    10000    120000 ns/op    50000 B/op    1500 allocs/op
```

**优化步骤**:

1. **使用pprof找到热点**:

```bash
go tool pprof cpu.prof
> top 10
# 输出显示: strings.ToUpper 占用 35%
#           time.Now().Format 占用 25%
#           string concatenation 占用 20%
```

2. **实施优化**:

```go
// ✅ 优化后 - CPU: 25%
func processLogsOptimized(logs []string) []string {
    // 预分配切片
    results := make([]string, 0, len(logs))

    // 预格式化日期（避免重复调用）
    dateStr := time.Now().Format("2006-01-02")

    // 使用strings.Builder减少分配
    var builder strings.Builder

    for _, log := range logs {
        builder.Reset()
        builder.Grow(len(log) + len(dateStr) + 20)

        builder.WriteByte('[')
        builder.WriteString(dateStr)
        builder.WriteString("] ")
        builder.WriteString(strings.ToUpper(log))
        builder.WriteString(" - processed")

        results = append(results, builder.String())
    }

    return results
}

// 优化后基准测试:
// BenchmarkProcessLogsOptimized-8    50000    25000 ns/op    10000 B/op    100 allocs/op
```

**优化效果**:

- CPU使用: 80% → 25% (3.2x改善)
- 执行时间: 120μs → 25μs (4.8x提升)
- 内存分配: 50KB → 10KB (5x减少)
- 分配次数: 1500 → 100 (15x减少)

---

### 案例2: 避免不必要的计算

```go
// ❌ 优化前
func calculateDiscount(orders []Order) float64 {
    var total float64
    for _, order := range orders {
        // 每次循环都重新计算
        if time.Now().Month() == 12 {
            total += order.Amount * 0.9
        } else {
            total += order.Amount
        }
    }
    return total
}

// ✅ 优化后
func calculateDiscountOptimized(orders []Order) float64 {
    // 提前计算条件
    isDecember := time.Now().Month() == 12
    var total float64

    if isDecember {
        for _, order := range orders {
            total += order.Amount * 0.9
        }
    } else {
        for _, order := range orders {
            total += order.Amount
        }
    }

    return total
}
```

---

## 4. 内存优化实战

### 案例1: 内存泄漏排查

**问题**: 服务运行一段时间后内存持续增长

```go
// ❌ 问题代码 - 内存泄漏
type Cache struct {
    data map[string][]byte
    mu   sync.RWMutex
}

func (c *Cache) Set(key string, value []byte) {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.data[key] = value  // 无限增长
}
```

**排查步骤**:

1. **对比两个时间点的堆快照**:

```bash
# 采集第一个快照
curl http://localhost:6060/debug/pprof/heap > heap1.prof

# 等待10分钟
sleep 600

# 采集第二个快照
curl http://localhost:6060/debug/pprof/heap > heap2.prof

# 对比差异
go tool pprof -base=heap1.prof heap2.prof
> top 20
```

2. **发现问题**: `Cache.data` map持续增长

3. **修复**:

```go
// ✅ 修复后 - 使用LRU缓存
import "github.com/hashicorp/golang-lru"

type Cache struct {
    data *lru.Cache
    mu   sync.RWMutex
}

func NewCache(size int) *Cache {
    cache, _ := lru.New(size)
    return &Cache{
        data: cache,
    }
}

func (c *Cache) Set(key string, value []byte) {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.data.Add(key, value)  // 自动淘汰旧数据
}
```

**修复效果**:

- 内存使用: 持续增长 → 稳定在500MB
- OOM崩溃: 每天1次 → 0次

---

### 案例2: Goroutine泄漏

**问题**: Goroutine数量持续增长

```go
// ❌ 问题代码
func handleRequest(req Request) {
    go func() {
        // 没有退出机制
        for {
            data := fetchData()
            process(data)
            time.Sleep(time.Second)
        }
    }()
}
```

**排查**:

```bash
curl http://localhost:6060/debug/pprof/goroutine?debug=1 > goroutines.txt
# 查看goroutine数量和堆栈
```

**修复**:

```go
// ✅ 修复后
func handleRequest(ctx context.Context, req Request) {
    go func() {
        ticker := time.NewTicker(time.Second)
        defer ticker.Stop()

        for {
            select {
            case <-ctx.Done():
                return  // 正常退出
            case <-ticker.C:
                data := fetchData()
                process(data)
            }
        }
    }()
}
```

---

## 5. I/O优化实战

### 案例1: 文件I/O优化

```go
// ❌ 优化前 - 逐行写入
func writeLogsUnoptimized(logs []string) error {
    file, _ := os.OpenFile("logs.txt", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
    defer file.Close()

    for _, log := range logs {
        file.WriteString(log + "\n")  // 每次都触发系统调用
    }

    return nil
}

// BenchmarkWriteLogsUnoptimized-8    100    12000000 ns/op

// ✅ 优化后 - 使用缓冲
func writeLogsOptimized(logs []string) error {
    file, _ := os.OpenFile("logs.txt", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
    defer file.Close()

    // 使用带缓冲的writer
    writer := bufio.NewWriterSize(file, 64*1024)  // 64KB buffer
    defer writer.Flush()

    for _, log := range logs {
        writer.WriteString(log)
        writer.WriteByte('\n')
    }

    return nil
}

// BenchmarkWriteLogsOptimized-8    5000    250000 ns/op
```

**优化效果**: 48x性能提升

---

### 案例2: 网络I/O优化

```go
// ❌ 优化前 - 串行HTTP请求
func fetchDataUnoptimized(urls []string) ([][]byte, error) {
    var results [][]byte

    for _, url := range urls {
        resp, err := http.Get(url)
        if err != nil {
            return nil, err
        }
        defer resp.Body.Close()

        data, _ := io.ReadAll(resp.Body)
        results = append(results, data)
    }

    return results, nil
}

// 耗时: 10个URL = 5秒

// ✅ 优化后 - 并发请求
func fetchDataOptimized(urls []string) ([][]byte, error) {
    results := make([][]byte, len(urls))
    var wg sync.WaitGroup
    var mu sync.Mutex

    // 使用worker pool限制并发
    semaphore := make(chan struct{}, 10)

    for i, url := range urls {
        wg.Add(1)
        go func(index int, u string) {
            defer wg.Done()

            semaphore <- struct{}{}
            defer func() { <-semaphore }()

            resp, err := http.Get(u)
            if err != nil {
                return
            }
            defer resp.Body.Close()

            data, _ := io.ReadAll(resp.Body)

            mu.Lock()
            results[index] = data
            mu.Unlock()
        }(i, url)
    }

    wg.Wait()
    return results, nil
}

// 耗时: 10个URL = 0.5秒
```

**优化效果**: 10x性能提升

---

## 6. 并发优化实战

### 案例: 图片批处理服务

**初始版本** - 串行处理:

```go
// ❌ V1: 串行处理
func processImages(images []Image) []ProcessedImage {
    results := make([]ProcessedImage, len(images))

    for i, img := range images {
        results[i] = processImage(img)
    }

    return results
}

// 性能: 100张图片 = 100秒
// CPU使用: 12% (单核)
```

**优化V2** - 基本并发:

```go
// ⚠️ V2: 无限并发
func processImagesV2(images []Image) []ProcessedImage {
    results := make([]ProcessedImage, len(images))
    var wg sync.WaitGroup

    for i, img := range images {
        wg.Add(1)
        go func(index int, image Image) {
            defer wg.Done()
            results[index] = processImage(image)
        }(i, img)
    }

    wg.Wait()
    return results
}

// 性能: 100张图片 = 15秒
// CPU使用: 95%
// 问题: 创建100个goroutine，内存占用高
```

**优化V3** - Worker Pool:

```go
// ✅ V3: Worker Pool
func processImagesV3(images []Image) []ProcessedImage {
    numWorkers := runtime.NumCPU()
    jobs := make(chan Job, len(images))
    results := make([]ProcessedImage, len(images))
    var wg sync.WaitGroup

    // 启动workers
    for w := 0; w < numWorkers; w++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for job := range jobs {
                results[job.Index] = processImage(job.Image)
            }
        }()
    }

    // 发送任务
    for i, img := range images {
        jobs <- Job{Index: i, Image: img}
    }
    close(jobs)

    wg.Wait()
    return results
}

// 性能: 100张图片 = 13秒
// CPU使用: 95%
// Goroutine: 8个 (稳定)
```

**最终优化V4** - 批处理 + 对象池:

```go
// ✅ V4: 批处理 + 对象池
var processorPool = sync.Pool{
    New: func() interface{} {
        return &ImageProcessor{}
    },
}

func processImagesV4(images []Image) []ProcessedImage {
    numWorkers := runtime.NumCPU()
    batchSize := 10
    results := make([]ProcessedImage, len(images))
    var wg sync.WaitGroup

    jobs := make(chan []Job, (len(images)+batchSize-1)/batchSize)

    // Workers
    for w := 0; w < numWorkers; w++ {
        wg.Add(1)
        go func() {
            defer wg.Done()

            // 从池中获取processor
            processor := processorPool.Get().(*ImageProcessor)
            defer processorPool.Put(processor)

            for batch := range jobs {
                for _, job := range batch {
                    results[job.Index] = processor.Process(job.Image)
                }
            }
        }()
    }

    // 批量发送任务
    for i := 0; i < len(images); i += batchSize {
        end := i + batchSize
        if end > len(images) {
            end = len(images)
        }

        batch := make([]Job, end-i)
        for j := i; j < end; j++ {
            batch[j-i] = Job{Index: j, Image: images[j]}
        }
        jobs <- batch
    }
    close(jobs)

    wg.Wait()
    return results
}

// 性能: 100张图片 = 10秒
// CPU使用: 95%
// 内存: 减少30%
```

**优化总结**:

| 版本 | 耗时 | CPU | 内存 | Goroutine |
|------|------|-----|------|-----------|
| V1 (串行) | 100s | 12% | 100MB | 1 |
| V2 (无限并发) | 15s | 95% | 500MB | 100 |
| V3 (Worker Pool) | 13s | 95% | 200MB | 8 |
| V4 (批处理+池) | 10s | 95% | 140MB | 8 |

---

## 7. 数据库优化实战

### 案例: 订单查询优化

**问题**: 订单列表查询慢（P99 > 2秒）

```go
// ❌ 优化前
func GetOrders(userID string) ([]Order, error) {
    var orders []Order

    // N+1查询问题
    rows, _ := db.Query("SELECT * FROM orders WHERE user_id = ?", userID)
    defer rows.Close()

    for rows.Next() {
        var order Order
        rows.Scan(&order.ID, &order.UserID, &order.TotalAmount)

        // 为每个订单查询商品
        items, _ := db.Query("SELECT * FROM order_items WHERE order_id = ?", order.ID)
        // ... 扫描items
        order.Items = items

        orders = append(orders, order)
    }

    return orders, nil
}

// 性能: 100个订单 = 2.5秒 (101次数据库查询)
```

**优化步骤**:

1. **使用JOIN避免N+1查询**:

```go
// ✅ 优化V1: JOIN查询
func GetOrdersV1(userID string) ([]Order, error) {
    query := `
        SELECT o.id, o.user_id, o.total_amount,
               oi.product_id, oi.quantity, oi.price
        FROM orders o
        LEFT JOIN order_items oi ON o.id = oi.order_id
        WHERE o.user_id = ?
    `

    rows, _ := db.Query(query, userID)
    defer rows.Close()

    // 组装数据
    ordersMap := make(map[string]*Order)
    for rows.Next() {
        var orderID, userID, productID string
        var totalAmount, price float64
        var quantity int

        rows.Scan(&orderID, &userID, &totalAmount, &productID, &quantity, &price)

        if order, exists := ordersMap[orderID]; !exists {
            ordersMap[orderID] = &Order{
                ID:          orderID,
                UserID:      userID,
                TotalAmount: totalAmount,
                Items:       []OrderItem{},
            }
        }

        ordersMap[orderID].Items = append(ordersMap[orderID].Items, OrderItem{
            ProductID: productID,
            Quantity:  quantity,
            Price:     price,
        })
    }

    orders := make([]Order, 0, len(ordersMap))
    for _, order := range ordersMap {
        orders = append(orders, *order)
    }

    return orders, nil
}

// 性能: 100个订单 = 0.5秒 (1次数据库查询)
```

2. **添加缓存**:

```go
// ✅ 优化V2: 添加缓存
func GetOrdersV2(userID string) ([]Order, error) {
    // 尝试从缓存获取
    cacheKey := "orders:" + userID
    if cached, err := redis.Get(cacheKey).Result(); err == nil {
        var orders []Order
        json.Unmarshal([]byte(cached), &orders)
        return orders, nil
    }

    // 从数据库查询
    orders, err := GetOrdersV1(userID)
    if err != nil {
        return nil, err
    }

    // 写入缓存
    if data, err := json.Marshal(orders); err == nil {
        redis.Set(cacheKey, data, 5*time.Minute)
    }

    return orders, nil
}

// 性能: 缓存命中 = 5ms，未命中 = 0.5秒
```

**优化效果**:

| 版本 | 查询时间 | DB查询次数 | 缓存命中率 |
|------|----------|------------|------------|
| V0 (原始) | 2.5s | 101 | 0% |
| V1 (JOIN) | 0.5s | 1 | 0% |
| V2 (缓存) | 5ms | 0 (命中) | 95% |

---

## 8. 网络优化实战

### HTTP服务器优化

```go
// ❌ 优化前 - 默认配置
func main() {
    http.HandleFunc("/", handler)
    http.ListenAndServe(":8080", nil)
}

// ✅ 优化后 - 自定义配置
func main() {
    server := &http.Server{
        Addr:         ":8080",
        Handler:      handler,
        ReadTimeout:  10 * time.Second,
        WriteTimeout: 10 * time.Second,
        IdleTimeout:  120 * time.Second,
        MaxHeaderBytes: 1 << 20,  // 1MB
    }

    // 调整操作系统参数
    // Linux: ulimit -n 65535

    server.ListenAndServe()
}

// 性能提升:
// - 并发连接: 1000 → 10000
// - QPS: 5000 → 15000
```

---

## 9. 完整优化案例

### API服务端到端优化

**初始状态**:

- QPS: 500
- P99延迟: 800ms
- CPU: 70%
- 内存: 2GB
- 错误率: 1%

**优化流程**:

#### 第1轮: CPU优化

**发现**: pprof显示JSON序列化占用40% CPU

```go
// 优化: 使用jsoniter替代标准库
import jsoniter "github.com/json-iterator/go"

var json = jsoniter.ConfigCompatibleWithStandardLibrary

// 效果: CPU 70% → 50%
```

#### 第2轮: 内存优化

**发现**: 大量临时对象分配

```go
// 优化: 使用对象池
var responsePool = sync.Pool{
    New: func() interface{} {
        return &Response{}
    },
}

// 效果: 内存 2GB → 1.2GB, GC暂停 50ms → 10ms
```

#### 第3轮: 数据库优化

**发现**: 慢查询日志显示多个查询 > 100ms

```go
// 优化:
// 1. 添加索引
// 2. 使用预编译语句
// 3. 引入Redis缓存

// 效果: P99延迟 800ms → 200ms
```

#### 第4轮: 并发优化

**发现**: 单线程处理限制了吞吐量

```go
// 优化: 使用worker pool处理请求

// 效果: QPS 500 → 2000
```

**最终结果**:

| 指标 | 优化前 | 优化后 | 提升 |
|------|--------|--------|------|
| QPS | 500 | 2000 | 4x |
| P99延迟 | 800ms | 50ms | 16x |
| CPU | 70% | 40% | 1.75x |
| 内存 | 2GB | 800MB | 2.5x |
| 错误率 | 1% | 0.01% | 100x |

---

## 🔗 相关资源

- [性能分析工具](./01-性能分析工具.md)
- [内存优化](./02-内存优化.md)
- [并发优化](./03-并发优化.md)
- [GC调优](./05-GC调优.md)

---

**最后更新**: 2025-10-29
**Go版本**: 1.25.3
**文档类型**: 实战指南 ✨
