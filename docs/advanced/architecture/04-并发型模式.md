# Go并发型设计模式

**版本**: v1.0  
**更新日期**: 2025-10-29  
**适用于**: Go 1.23+

---

## 📋 目录


- [理论基础与分类](#理论基础与分类)
  - [并发模式的重要性](#并发模式的重要性)
  - [模式分类](#模式分类)
- [Future/Promise模式](#futurepromise模式)
  - [定义](#定义)
  - [实现](#实现)
  - [批量Future](#批量future)
- [Worker Pool模式](#worker-pool模式)
  - [定义](#定义)
  - [基础实现](#基础实现)
  - [带Context的Worker Pool](#带context的worker-pool)
- [Pipeline模式](#pipeline模式)
  - [定义](#定义)
  - [实现](#实现)
  - [可取消的Pipeline](#可取消的pipeline)
- [Fan-Out/Fan-In模式](#fan-outfan-in模式)
  - [定义](#定义)
  - [实现](#实现)
- [生产者-消费者模式](#生产者-消费者模式)
  - [定义](#定义)
  - [实现](#实现)
- [Semaphore模式](#semaphore模式)
  - [定义](#定义)
  - [实现](#实现)
- [Context传播模式](#context传播模式)
  - [定义](#定义)
  - [实现](#实现)
- [最佳实践与常见陷阱](#最佳实践与常见陷阱)
  - [最佳实践](#最佳实践)
  - [常见陷阱](#常见陷阱)
  - [性能考量](#性能考量)

## 理论基础与分类

### 并发模式的重要性

在现代软件系统中，并发是提升性能的关键手段。Go语言以其轻量级goroutine和channel为核心，提供了强大的并发支持。

### 模式分类

| 模式 | 核心思想 | 适用场景 |
|------|---------|----------|
| **Future/Promise** | 异步计算结果 | 异步任务、结果收集 |
| **Worker Pool** | 固定数量worker | 限流、资源复用 |
| **Pipeline** | 数据流水线 | 数据转换、流式处理 |
| **Fan-Out/Fan-In** | 并发分发/汇总 | 并行计算、结果聚合 |
| **Producer-Consumer** | 生产消费解耦 | 速率不匹配 |
| **Semaphore** | 资源限制 | 并发控制 |
| **Context** | 上下文传播 | 取消、超时、元数据 |

---

## Future/Promise模式

### 定义

**Future/Promise** 表示一个尚未完成但将来可用的结果，允许异步执行任务。

### 实现

```go
package main

import (
    "errors"
    "time"
)

// Future 代表未来的计算结果
type Future struct {
    result chan interface{}
    err    chan error
}

// NewFuture 创建并异步执行任务
func NewFuture(task func() (interface{}, error)) *Future {
    f := &Future{
        result: make(chan interface{}, 1),
        err:    make(chan error, 1),
    }
    
    go func() {
        result, err := task()
        if err != nil {
            f.err <- err
        } else {
            f.result <- result
        }
    }()
    
    return f
}

// Get 阻塞获取结果
func (f *Future) Get() (interface{}, error) {
    select {
    case result := <-f.result:
        return result, nil
    case err := <-f.err:
        return nil, err
    }
}

// GetWithTimeout 带超时获取结果
func (f *Future) GetWithTimeout(timeout time.Duration) (interface{}, error) {
    select {
    case result := <-f.result:
        return result, nil
    case err := <-f.err:
        return nil, err
    case <-time.After(timeout):
        return nil, errors.New("timeout")
    }
}

// 使用示例
func main() {
    future := NewFuture(func() (interface{}, error) {
        time.Sleep(2 * time.Second)
        return "result", nil
    })
    
    result, err := future.Get()
    if err != nil {
        panic(err)
    }
    println(result.(string))
}
```

### 批量Future

```go
// FutureAll 等待所有future完成
func FutureAll(futures ...*Future) ([]interface{}, error) {
    results := make([]interface{}, len(futures))
    
    for i, f := range futures {
        result, err := f.Get()
        if err != nil {
            return nil, err
        }
        results[i] = result
    }
    
    return results, nil
}

// 使用
func main() {
    f1 := NewFuture(func() (interface{}, error) { return 1, nil })
    f2 := NewFuture(func() (interface{}, error) { return 2, nil })
    f3 := NewFuture(func() (interface{}, error) { return 3, nil })
    
    results, _ := FutureAll(f1, f2, f3)
    println(results)  // [1, 2, 3]
}
```

---

## Worker Pool模式

### 定义

通过固定数量的worker并发处理任务，控制资源消耗，提升吞吐量。

### 基础实现

```go
package main

import (
    "fmt"
    "sync"
)

type Job struct {
    ID   int
    Data string
}

type Result struct {
    Job    Job
    Output string
}

// WorkerPool 工作池
type WorkerPool struct {
    jobs    chan Job
    results chan Result
    workers int
    wg      sync.WaitGroup
}

// NewWorkerPool 创建工作池
func NewWorkerPool(workers, jobBuffer int) *WorkerPool {
    return &WorkerPool{
        jobs:    make(chan Job, jobBuffer),
        results: make(chan Result, jobBuffer),
        workers: workers,
    }
}

// Start 启动worker
func (wp *WorkerPool) Start() {
    for i := 0; i < wp.workers; i++ {
        wp.wg.Add(1)
        go wp.worker(i)
    }
}

// worker 执行任务
func (wp *WorkerPool) worker(id int) {
    defer wp.wg.Done()
    
    for job := range wp.jobs {
        // 处理任务
        output := fmt.Sprintf("Worker %d processed job %d: %s", 
            id, job.ID, job.Data)
        
        wp.results <- Result{
            Job:    job,
            Output: output,
        }
    }
}

// Submit 提交任务
func (wp *WorkerPool) Submit(job Job) {
    wp.jobs <- job
}

// Wait 等待所有任务完成
func (wp *WorkerPool) Wait() {
    close(wp.jobs)
    wp.wg.Wait()
    close(wp.results)
}

// Results 获取结果channel
func (wp *WorkerPool) Results() <-chan Result {
    return wp.results
}

// 使用示例
func main() {
    pool := NewWorkerPool(5, 100)
    pool.Start()
    
    // 提交任务
    go func() {
        for i := 0; i < 10; i++ {
            pool.Submit(Job{ID: i, Data: fmt.Sprintf("data-%d", i)})
        }
        pool.Wait()
    }()
    
    // 收集结果
    for result := range pool.Results() {
        fmt.Println(result.Output)
    }
}
```

### 带Context的Worker Pool

```go
type WorkerPoolWithContext struct {
    jobs    chan Job
    results chan Result
    workers int
    ctx     context.Context
    cancel  context.CancelFunc
}

func (wp *WorkerPoolWithContext) worker(id int, wg *sync.WaitGroup) {
    defer wg.Done()
    
    for {
        select {
        case <-wp.ctx.Done():
            return  // 取消信号
        case job, ok := <-wp.jobs:
            if !ok {
                return
            }
            // 处理job
            wp.results <- process(job)
        }
    }
}
```

---

## Pipeline模式

### 定义

将数据处理分解为多个阶段，每个阶段并发执行，形成数据流水线。

### 实现

```go
// 阶段1：生成数据
func generate(nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for _, n := range nums {
            out <- n
        }
    }()
    return out
}

// 阶段2：平方
func square(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            out <- n * n
        }
    }()
    return out
}

// 阶段3：过滤
func filter(in <-chan int, predicate func(int) bool) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            if predicate(n) {
                out <- n
            }
        }
    }()
    return out
}

// 阶段4：求和
func sum(in <-chan int) int {
    total := 0
    for n := range in {
        total += n
    }
    return total
}

// 组装Pipeline
func main() {
    // 生成 -> 平方 -> 过滤(>10) -> 求和
    c := generate(1, 2, 3, 4, 5)
    c = square(c)
    c = filter(c, func(n int) bool { return n > 10 })
    
    result := sum(c)
    fmt.Println(result)  // 25 + 16 = 41
}
```

### 可取消的Pipeline

```go
func squareWithContext(ctx context.Context, in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for {
            select {
            case <-ctx.Done():
                return
            case n, ok := <-in:
                if !ok {
                    return
                }
                select {
                case out <- n * n:
                case <-ctx.Done():
                    return
                }
            }
        }
    }()
    return out
}
```

---

## Fan-Out/Fan-In模式

### 定义

**Fan-Out**: 将任务分发到多个worker并发处理  
**Fan-In**: 将多个worker的结果汇总到一个channel

### 实现

```go
// Fan-Out: 启动多个worker
func fanOut(in <-chan int, workers int) []<-chan int {
    channels := make([]<-chan int, workers)
    for i := 0; i < workers; i++ {
        channels[i] = worker(in)
    }
    return channels
}

func worker(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            // 模拟耗时操作
            time.Sleep(time.Millisecond)
            out <- n * n
        }
    }()
    return out
}

// Fan-In: 合并多个channel
func fanIn(channels ...<-chan int) <-chan int {
    out := make(chan int)
    var wg sync.WaitGroup
    
    for _, ch := range channels {
        wg.Add(1)
        go func(c <-chan int) {
            defer wg.Done()
            for n := range c {
                out <- n
            }
        }(ch)
    }
    
    go func() {
        wg.Wait()
        close(out)
    }()
    
    return out
}

// 使用
func main() {
    in := generate(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
    
    // Fan-Out: 3个worker并发处理
    workers := fanOut(in, 3)
    
    // Fan-In: 合并结果
    results := fanIn(workers...)
    
    for result := range results {
        fmt.Println(result)
    }
}
```

---

## 生产者-消费者模式

### 定义

生产者生成数据，消费者处理数据，通过缓冲channel解耦，适应不同速率。

### 实现

```go
type Queue struct {
    items chan interface{}
}

// 生产者
func producer(q *Queue, count int) {
    for i := 0; i < count; i++ {
        q.items <- i
        fmt.Printf("Produced: %d\n", i)
        time.Sleep(time.Millisecond * 100)
    }
    close(q.items)
}

// 消费者
func consumer(id int, q *Queue, wg *sync.WaitGroup) {
    defer wg.Done()
    for item := range q.items {
        fmt.Printf("Consumer %d consumed: %v\n", id, item)
        time.Sleep(time.Millisecond * 200)  // 消费更慢
    }
}

func main() {
    q := &Queue{items: make(chan interface{}, 10)}
    
    go producer(q, 20)
    
    var wg sync.WaitGroup
    for i := 0; i < 3; i++ {
        wg.Add(1)
        go consumer(i, q, &wg)
    }
    
    wg.Wait()
}
```

---

## Semaphore模式

### 定义

使用channel实现信号量，限制并发访问数量。

### 实现

```go
type Semaphore chan struct{}

// NewSemaphore 创建信号量
func NewSemaphore(n int) Semaphore {
    return make(Semaphore, n)
}

// Acquire 获取资源
func (s Semaphore) Acquire() {
    s <- struct{}{}
}

// Release 释放资源
func (s Semaphore) Release() {
    <-s
}

// 使用示例
func main() {
    sem := NewSemaphore(3)  // 最多3个并发
    
    var wg sync.WaitGroup
    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            
            sem.Acquire()
            defer sem.Release()
            
            fmt.Printf("Task %d running\n", id)
            time.Sleep(time.Second)
        }(i)
    }
    
    wg.Wait()
}
```

---

## Context传播模式

### 定义

使用context传递取消信号、超时、截止时间和请求范围的值。

### 实现

```go
func worker(ctx context.Context, id int) {
    for {
        select {
        case <-ctx.Done():
            fmt.Printf("Worker %d stopped: %v\n", id, ctx.Err())
            return
        default:
            fmt.Printf("Worker %d working...\n", id)
            time.Sleep(time.Millisecond * 500)
        }
    }
}

func main() {
    // 带超时的context
    ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)
    defer cancel()
    
    // 启动多个worker
    var wg sync.WaitGroup
    for i := 0; i < 3; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            worker(ctx, id)
        }(i)
    }
    
    wg.Wait()
    fmt.Println("All workers stopped")
}
```

---

## 最佳实践与常见陷阱

### 最佳实践

1. **合理设置缓冲区**
   - 缓冲过小：频繁阻塞
   - 缓冲过大：浪费内存
   - 建议：根据生产/消费速率估算

2. **使用Context控制生命周期**
   ```go
   ctx, cancel := context.WithCancel(context.Background())
   defer cancel()  // 确保取消
   ```

3. **避免Goroutine泄漏**
   - 确保每个goroutine都有退出路径
   - 使用context或done channel

4. **Worker数量调优**
   - CPU密集型：workers = CPU核数
   - I/O密集型：workers > CPU核数
   - 通过benchmark确定最佳值

5. **Channel关闭原则**
   - 只由生产者关闭channel
   - 消费者检测关闭：`val, ok := <-ch`

### 常见陷阱

**1. Goroutine泄漏**

```go
// ❌ 泄漏：channel永远阻塞
func leak() {
    ch := make(chan int)
    go func() {
        ch <- 42  // 永远阻塞
    }()
}

// ✅ 正确：使用缓冲或确保接收
func noLeak() {
    ch := make(chan int, 1)
    go func() {
        ch <- 42
    }()
}
```

**2. 死锁**

```go
// ❌ 死锁：循环依赖
ch1 := make(chan int)
ch2 := make(chan int)

go func() {
    ch1 <- <-ch2
}()

go func() {
    ch2 <- <-ch1
}()
```

**3. 竞态条件**

```go
// ❌ 竞态
count := 0
for i := 0; i < 10; i++ {
    go func() {
        count++  // 竞态！
    }()
}

// ✅ 使用atomic或channel
var count int64
for i := 0; i < 10; i++ {
    go func() {
        atomic.AddInt64(&count, 1)
    }()
}
```

### 性能考量

| 模式 | 开销 | 吞吐量 | 适用场景 |
|------|------|--------|----------|
| Worker Pool | 低 | 高 | 批量任务 |
| Pipeline | 中 | 中 | 流式处理 |
| Fan-Out/Fan-In | 中 | 高 | 并行计算 |
| Future/Promise | 低 | 中 | 异步任务 |

---

**文档维护者**: Go Documentation Team  
**最后更新**: 2025-10-29  
**文档状态**: 已优化  
**适用版本**: Go 1.25.3+
