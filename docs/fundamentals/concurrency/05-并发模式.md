# 并发模式

**难度**: 高级  
**预计阅读时间**: 30分钟  
**前置知识**: Goroutine、Channel、select、Context

---

## 📋 目录

- [1. 📖 概念介绍](#1--概念介绍)
- [2. 🎯 核心知识点](#2--核心知识点)
  - [1. Pipeline模式](#1-pipeline模式)
    - [基础实现](#基础实现)
    - [支持取消的Pipeline](#支持取消的pipeline)
  - [2. Fan-out/Fan-in模式](#2-fan-outfan-in模式)
    - [Fan-out实现](#fan-out实现)
    - [Fan-in实现](#fan-in实现)
  - [3. Worker Pool模式](#3-worker-pool模式)
  - [4. Or-Channel模式](#4-or-channel模式)
  - [5. Tee-Channel模式](#5-tee-channel模式)
  - [6. Bridge-Channel模式](#6-bridge-channel模式)
- [🏗️ 实战案例：并发Web爬虫](#-实战案例并发web爬虫)
- [⚠️ 常见问题](#-常见问题)
  - [Q1: 什么时候使用Worker Pool？](#q1-什么时候使用worker-pool)
  - [Q2: Pipeline的优势是什么？](#q2-pipeline的优势是什么)
  - [Q3: 如何选择合适的并发模式？](#q3-如何选择合适的并发模式)
  - [Q4: 并发模式的性能开销？](#q4-并发模式的性能开销)
- [📚 相关资源](#-相关资源)
  - [推荐阅读](#推荐阅读)
  - [相关章节](#相关章节)

## 1. 📖 概念介绍

并发模式是解决常见并发问题的经过验证的方案。掌握这些模式可以帮助你构建健壮、可维护的并发程序。本文介绍Go中最常用的6种并发模式。

---

## 2. 🎯 核心知识点

### 1. Pipeline模式

**定义**: 将数据处理分成多个阶段，每个阶段由独立的Goroutine处理，通过Channel连接。

#### 基础实现

```go
package main

import "fmt"

// 阶段1：生成数字
func generator(nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        for _, n := range nums {
            out <- n
        }
        close(out)
    }()
    return out
}

// 阶段2：平方
func square(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        for n := range in {
            out <- n * n
        }
        close(out)
    }()
    return out
}

// 阶段3：过滤偶数
func filterEven(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        for n := range in {
            if n%2 == 0 {
                out <- n
            }
        }
        close(out)
    }()
    return out
}

func pipelineBasic() {
    // 构建pipeline
    ch := generator(1, 2, 3, 4, 5, 6)
    ch = square(ch)
    ch = filterEven(ch)
    
    // 消费结果
    for n := range ch {
        fmt.Println(n) // 输出: 4, 16, 36
    }
}

func main() {
    pipelineBasic()
}
```

#### 支持取消的Pipeline

```go
package main

import (
    "context"
    "fmt"
    "time"
)

func generatorWithContext(ctx context.Context, nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for _, n := range nums {
            select {
            case out <- n:
            case <-ctx.Done():
                return
            }
        }
    }()
    return out
}

func squareWithContext(ctx context.Context, in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            select {
            case out <- n * n:
            case <-ctx.Done():
                return
            }
        }
    }()
    return out
}

func pipelineWithCancel() {
    ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
    defer cancel()
    
    ch := generatorWithContext(ctx, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
    ch = squareWithContext(ctx, ch)
    
    for n := range ch {
        fmt.Println(n)
        time.Sleep(500 * time.Millisecond) // 模拟慢消费
    }
}

func main() {
    pipelineWithCancel()
}
```

---

### 2. Fan-out/Fan-in模式

**定义**: Fan-out将工作分发给多个worker并行处理；Fan-in将多个结果合并到一个Channel。

#### Fan-out实现

```go
package main

import (
    "fmt"
    "sync"
    "time"
)

func worker(id int, jobs <-chan int, results chan<- int) {
    for j := range jobs {
        fmt.Printf("Worker %d processing job %d\n", id, j)
        time.Sleep(time.Second) // 模拟工作
        results <- j * 2
    }
}

func fanOut() {
    jobs := make(chan int, 10)
    results := make(chan int, 10)
    
    // 启动3个worker（Fan-out）
    for w := 1; w <= 3; w++ {
        go worker(w, jobs, results)
    }
    
    // 发送5个任务
    for j := 1; j <= 5; j++ {
        jobs <- j
    }
    close(jobs)
    
    // 收集结果
    for a := 1; a <= 5; a++ {
        fmt.Printf("Result: %d\n", <-results)
    }
}

func main() {
    fanOut()
}
```

#### Fan-in实现

```go
package main

import (
    "fmt"
    "sync"
)

func producer(id int, ch chan<- int) {
    for i := 0; i < 3; i++ {
        ch <- id*10 + i
    }
}

func fanIn(channels ...<-chan int) <-chan int {
    var wg sync.WaitGroup
    out := make(chan int)
    
    // 为每个输入channel启动一个Goroutine
    multiplex := func(ch <-chan int) {
        defer wg.Done()
        for val := range ch {
            out <- val
        }
    }
    
    wg.Add(len(channels))
    for _, ch := range channels {
        go multiplex(ch)
    }
    
    // 等待所有输入完成后关闭输出channel
    go func() {
        wg.Wait()
        close(out)
    }()
    
    return out
}

func fanInDemo() {
    ch1 := make(chan int)
    ch2 := make(chan int)
    ch3 := make(chan int)
    
    go producer(1, ch1)
    go producer(2, ch2)
    go producer(3, ch3)
    
    // 合并3个channel
    for val := range fanIn(ch1, ch2, ch3) {
        fmt.Println(val)
    }
}

// 取消注释以运行
// func main() {
//     fanInDemo()
// }
```

---

### 3. Worker Pool模式

**定义**: 维护固定数量的worker goroutine，从任务队列中获取并处理任务。

```go
package main

import (
    "fmt"
    "sync"
    "time"
)

type Job struct {
    ID      int
    Payload string
}

type Result struct {
    Job    Job
    Result string
}

func workerPool(numWorkers int, jobs <-chan Job, results chan<- Result) {
    var wg sync.WaitGroup
    
    // 启动固定数量的worker
    for i := 1; i <= numWorkers; i++ {
        wg.Add(1)
        go func(workerID int) {
            defer wg.Done()
            
            for job := range jobs {
                fmt.Printf("Worker %d processing job %d\n", workerID, job.ID)
                time.Sleep(time.Second) // 模拟处理时间
                
                results <- Result{
                    Job:    job,
                    Result: fmt.Sprintf("Processed by worker %d", workerID),
                }
            }
        }(i)
    }
    
    // 等待所有worker完成
    wg.Wait()
    close(results)
}

func workerPoolDemo() {
    const numJobs = 10
    const numWorkers = 3
    
    jobs := make(chan Job, numJobs)
    results := make(chan Result, numJobs)
    
    // 启动worker pool
    go workerPool(numWorkers, jobs, results)
    
    // 发送任务
    for i := 1; i <= numJobs; i++ {
        jobs <- Job{
            ID:      i,
            Payload: fmt.Sprintf("Task-%d", i),
        }
    }
    close(jobs)
    
    // 收集结果
    for r := range results {
        fmt.Printf("Job %d: %s\n", r.Job.ID, r.Result)
    }
}

func main() {
    workerPoolDemo()
}
```

---

### 4. Or-Channel模式

**定义**: 监听多个done channel，任意一个触发即返回。

```go
package main

import (
    "fmt"
    "time"
)

// or函数：合并多个done channel
func or(channels ...<-chan interface{}) <-chan interface{} {
    switch len(channels) {
    case 0:
        return nil
    case 1:
        return channels[0]
    }
    
    orDone := make(chan interface{})
    go func() {
        defer close(orDone)
        
        switch len(channels) {
        case 2:
            select {
            case <-channels[0]:
            case <-channels[1]:
            }
        default:
            select {
            case <-channels[0]:
            case <-channels[1]:
            case <-channels[2]:
            case <-or(append(channels[3:], orDone)...):
            }
        }
    }()
    return orDone
}

func sig(after time.Duration) <-chan interface{} {
    c := make(chan interface{})
    go func() {
        defer close(c)
        time.Sleep(after)
    }()
    return c
}

func orChannelDemo() {
    start := time.Now()
    
    // 任意一个channel关闭即返回
    <-or(
        sig(2*time.Hour),
        sig(5*time.Minute),
        sig(1*time.Second),    // 这个会最先触发
        sig(1*time.Hour),
        sig(1*time.Minute),
    )
    
    fmt.Printf("Done after %v\n", time.Since(start))
}

func main() {
    orChannelDemo()
}
```

---

### 5. Tee-Channel模式

**定义**: 将一个输入channel的数据复制到两个输出channel。

```go
package main

import "fmt"

func tee(in <-chan int) (<-chan int, <-chan int) {
    out1 := make(chan int)
    out2 := make(chan int)
    
    go func() {
        defer close(out1)
        defer close(out2)
        
        for val := range in {
            // 复制到两个channel
            var out1, out2 = out1, out2
            for i := 0; i < 2; i++ {
                select {
                case out1 <- val:
                    out1 = nil // 防止重复发送
                case out2 <- val:
                    out2 = nil
                }
            }
        }
    }()
    
    return out1, out2
}

func teeDemo() {
    in := make(chan int)
    
    // 生成数据
    go func() {
        defer close(in)
        for i := 1; i <= 5; i++ {
            in <- i
        }
    }()
    
    // 分流到两个channel
    out1, out2 := tee(in)
    
    // 两个消费者
    done := make(chan bool, 2)
    
    go func() {
        for val := range out1 {
            fmt.Printf("Consumer 1: %d\n", val)
        }
        done <- true
    }()
    
    go func() {
        for val := range out2 {
            fmt.Printf("Consumer 2: %d\n", val)
        }
        done <- true
    }()
    
    <-done
    <-done
}

func main() {
    teeDemo()
}
```

---

### 6. Bridge-Channel模式

**定义**: 将channel of channels展平为单个channel。

```go
package main

import "fmt"

func bridge(chanStream <-chan <-chan int) <-chan int {
    out := make(chan int)
    
    go func() {
        defer close(out)
        
        for ch := range chanStream {
            for val := range ch {
                out <- val
            }
        }
    }()
    
    return out
}

func bridgeDemo() {
    chanStream := make(chan (<-chan int))
    
    // 生成channel stream
    go func() {
        defer close(chanStream)
        
        for i := 0; i < 3; i++ {
            ch := make(chan int)
            chanStream <- ch
            
            go func(ch chan int, i int) {
                defer close(ch)
                for j := 0; j < 3; j++ {
                    ch <- i*10 + j
                }
            }(ch, i)
        }
    }()
    
    // 展平并消费
    for val := range bridge(chanStream) {
        fmt.Println(val)
    }
}

func main() {
    bridgeDemo()
}
```

---

## 🏗️ 实战案例：并发Web爬虫

```go
package main

import (
    "fmt"
    "sync"
    "time"
)

type URL string
type Page struct {
    URL   URL
    Links []URL
}

// 模拟爬取页面
func fetch(url URL) Page {
    time.Sleep(500 * time.Millisecond)
    return Page{
        URL: url,
        Links: []URL{
            URL(string(url) + "/link1"),
            URL(string(url) + "/link2"),
        },
    }
}

// 并发爬虫
func crawler(start URL, maxDepth int) {
    type crawlState struct {
        url   URL
        depth int
    }
    
    visited := make(map[URL]bool)
    var mu sync.Mutex
    
    queue := make(chan crawlState, 100)
    var wg sync.WaitGroup
    
    // Worker pool
    for i := 0; i < 5; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            
            for state := range queue {
                // 检查是否已访问
                mu.Lock()
                if visited[state.url] {
                    mu.Unlock()
                    continue
                }
                visited[state.url] = true
                mu.Unlock()
                
                // 爬取页面
                fmt.Printf("Crawling: %s (depth %d)\n", state.url, state.depth)
                page := fetch(state.url)
                
                // 添加新链接到队列
                if state.depth < maxDepth {
                    for _, link := range page.Links {
                        queue <- crawlState{link, state.depth + 1}
                    }
                }
            }
        }()
    }
    
    // 启动爬虫
    queue <- crawlState{start, 0}
    
    // 等待完成
    time.Sleep(3 * time.Second) // 简化版：实际应该用更好的完成检测
    close(queue)
    wg.Wait()
}

func main() {
    crawler("https://example.com", 2)
}
```

---

## ⚠️ 常见问题

### Q1: 什么时候使用Worker Pool？
- 任务数量远大于worker数量
- 需要控制并发度
- 任务处理时间相对均匀

### Q2: Pipeline的优势是什么？
- 清晰的数据流
- 易于测试和维护
- 可以独立优化每个阶段
- 支持背压（backpressure）

### Q3: 如何选择合适的并发模式？
- 数据处理：Pipeline
- 并行计算：Fan-out/Fan-in
- 任务队列：Worker Pool
- 超时/取消：Or-Channel
- 数据复制：Tee-Channel

### Q4: 并发模式的性能开销？
- Goroutine创建：极低
- Channel通信：纳秒级
- Context传递：几乎无开销
- 关键是避免不必要的同步

---

## 📚 相关资源

### 推荐阅读
- [Go Concurrency Patterns](https://go.dev/blog/pipelines)
- [Advanced Go Concurrency Patterns](https://go.dev/blog/io2013-talk-concurrency)
- 《Concurrency in Go》by Katherine Cox-Buday

### 相关章节
- [并发型模式](../../advanced/architecture/04-并发型模式.md)
- [并发优化](../../advanced/performance/03-并发优化.md)

---

**最后更新**: 2025-10-27  
**作者**: Documentation Team

