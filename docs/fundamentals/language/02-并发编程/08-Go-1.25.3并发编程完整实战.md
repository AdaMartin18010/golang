# Go 1.25.3 å¹¶å‘ç¼–ç¨‹å®Œæ•´å®æˆ˜

**ç‰ˆæœ¬**: v1.0
**æ›´æ–°æ—¥æœŸ**: 2025-10-29
**é€‚ç”¨äº**: Go 1.25.3

---

## ğŸ“‹ ç›®å½•

- [Go 1.25.3 å¹¶å‘ç¼–ç¨‹å®Œæ•´å®æˆ˜](#go-1253-å¹¶å‘ç¼–ç¨‹å®Œæ•´å®æˆ˜)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ğŸ“– æ–‡æ¡£è¯´æ˜](#-æ–‡æ¡£è¯´æ˜)
  - [1. Worker Poolæ¨¡å¼](#1-worker-poolæ¨¡å¼)
    - [1.1 åŸºç¡€Worker Pool](#11-åŸºç¡€worker-pool)
    - [1.2 åŠ¨æ€Worker Pool](#12-åŠ¨æ€worker-pool)
  - [2. Pipelineæ¨¡å¼](#2-pipelineæ¨¡å¼)
    - [2.1 åŸºç¡€Pipeline](#21-åŸºç¡€pipeline)
    - [2.2 æ‰‡å‡ºæ‰‡å…¥(Fan-Out Fan-In)](#22-æ‰‡å‡ºæ‰‡å…¥fan-out-fan-in)
  - [3. å¹¶å‘æ§åˆ¶æ¨¡å¼](#3-å¹¶å‘æ§åˆ¶æ¨¡å¼)
    - [3.1 ä¿¡å·é‡(Semaphore)](#31-ä¿¡å·é‡semaphore)
    - [3.2 è¶…æ—¶æ§åˆ¶](#32-è¶…æ—¶æ§åˆ¶)
    - [3.3 å–æ¶ˆä¼ æ’­](#33-å–æ¶ˆä¼ æ’­)
  - [4. é”™è¯¯å¤„ç†](#4-é”™è¯¯å¤„ç†)
    - [4.1 errgroupæ¨¡å¼](#41-errgroupæ¨¡å¼)
  - [5. å¹¶å‘å®‰å…¨æ•°æ®ç»“æ„](#5-å¹¶å‘å®‰å…¨æ•°æ®ç»“æ„)
    - [5.1 å¹¶å‘å®‰å…¨Map](#51-å¹¶å‘å®‰å…¨map)
    - [5.2 å¹¶å‘å®‰å…¨è®¡æ•°å™¨](#52-å¹¶å‘å®‰å…¨è®¡æ•°å™¨)
  - [6. å®æˆ˜åœºæ™¯](#6-å®æˆ˜åœºæ™¯)
    - [6.1 å¹¶å‘Webçˆ¬è™«](#61-å¹¶å‘webçˆ¬è™«)
    - [6.2 ç”Ÿäº§è€…-æ¶ˆè´¹è€…é˜Ÿåˆ—](#62-ç”Ÿäº§è€…-æ¶ˆè´¹è€…é˜Ÿåˆ—)
  - [7. æ€§èƒ½ä¼˜åŒ–](#7-æ€§èƒ½ä¼˜åŒ–)
    - [7.1 å‡å°‘é”ç«äº‰](#71-å‡å°‘é”ç«äº‰)
    - [7.2 æ‰¹é‡å¤„ç†](#72-æ‰¹é‡å¤„ç†)
  - [8. å¸¸è§é™·é˜±](#8-å¸¸è§é™·é˜±)
    - [8.1 Goroutineæ³„æ¼](#81-goroutineæ³„æ¼)
    - [8.2 æ•°æ®ç«äº‰](#82-æ•°æ®ç«äº‰)
  - [9. åŸºå‡†æµ‹è¯•](#9-åŸºå‡†æµ‹è¯•)
  - [ğŸ“š æœ€ä½³å®è·µ](#-æœ€ä½³å®è·µ)
    - [1. å¹¶å‘è®¾è®¡åŸåˆ™](#1-å¹¶å‘è®¾è®¡åŸåˆ™)
    - [2. Goroutineç®¡ç†](#2-goroutineç®¡ç†)
    - [3. Contextä½¿ç”¨](#3-contextä½¿ç”¨)
    - [4. Channelå…³é—­](#4-channelå…³é—­)
  - [ğŸ¯ æ€»ç»“](#-æ€»ç»“)
  - [ğŸ”— ç›¸å…³èµ„æº](#-ç›¸å…³èµ„æº)

## ğŸ“– æ–‡æ¡£è¯´æ˜

æœ¬æ–‡æ¡£å±•ç¤ºGo 1.25.3çš„**å¹¶å‘ç¼–ç¨‹æœ€ä½³å®è·µ**ï¼Œæ¶µç›–ä»åŸºç¡€åˆ°é«˜çº§çš„å®Œæ•´å®æˆ˜åœºæ™¯ï¼š

- âœ… CSPå¹¶å‘æ¨¡å‹å®è·µ
- âœ… ç”Ÿäº§çº§å¹¶å‘æ¨¡å¼
- âœ… Contextè¶…æ—¶æ§åˆ¶
- âœ… é”™è¯¯ä¼ æ’­ä¸å¤„ç†
- âœ… å¹¶å‘å®‰å…¨æ•°æ®ç»“æ„
- âœ… æ€§èƒ½æµ‹è¯•ä¸åŸºå‡†
- âœ… å¸¸è§å¹¶å‘é™·é˜±é¿å…

---

## 1. Worker Poolæ¨¡å¼

### 1.1 åŸºç¡€Worker Pool

**é€‚ç”¨åœºæ™¯**: é™åˆ¶å¹¶å‘æ•°é‡ï¼Œå¤„ç†å¤§é‡ä»»åŠ¡

```go
package concurrency

import (
 "context"
 "fmt"
 "sync"
 "time"
)

// Task ä»»åŠ¡å®šä¹‰
type Task func() error

// WorkerPool å·¥ä½œæ± 
type WorkerPool struct {
 workers   int
 tasks     chan Task
 results   chan error
 wg        sync.WaitGroup
 ctx       context.Context
 cancel    context.CancelFunc
}

// NewWorkerPool åˆ›å»ºå·¥ä½œæ± 
func NewWorkerPool(workers int) *WorkerPool {
 ctx, cancel := context.WithCancel(context.Background())

 return &WorkerPool{
  workers: workers,
  tasks:   make(chan Task, workers*2), // ç¼“å†²é˜Ÿåˆ—
  results: make(chan error, workers*2),
  ctx:     ctx,
  cancel:  cancel,
 }
}

// Start å¯åŠ¨å·¥ä½œæ± 
func (p *WorkerPool) Start() {
 // å¯åŠ¨worker goroutines
 for i := 0; i < p.workers; i++ {
  p.wg.Add(1)
  go p.worker(i)
 }
}

// worker å·¥ä½œåç¨‹
func (p *WorkerPool) worker(id int) {
 defer p.wg.Done()

 for {
  select {
  case <-p.ctx.Done():
   fmt.Printf("Worker %d: shutting down\n", id)
   return

  case task, ok := <-p.tasks:
   if !ok {
    fmt.Printf("Worker %d: task channel closed\n", id)
    return
   }

   // æ‰§è¡Œä»»åŠ¡
   err := task()

   // å‘é€ç»“æœ
   select {
   case p.results <- err:
   case <-p.ctx.Done():
    return
   }
  }
 }
}

// Submit æäº¤ä»»åŠ¡
func (p *WorkerPool) Submit(task Task) error {
 select {
 case p.tasks <- task:
  return nil
 case <-p.ctx.Done():
  return fmt.Errorf("worker pool is shutting down")
 }
}

// Stop åœæ­¢å·¥ä½œæ± 
func (p *WorkerPool) Stop() {
 close(p.tasks)    // å…³é—­ä»»åŠ¡é€šé“
 p.wg.Wait()       // ç­‰å¾…æ‰€æœ‰workerå®Œæˆ
 close(p.results)  // å…³é—­ç»“æœé€šé“
}

// Results è·å–ç»“æœé€šé“
func (p *WorkerPool) Results() <-chan error {
 return p.results
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleWorkerPool() {
 pool := NewWorkerPool(5) // 5ä¸ªworker
 pool.Start()

 // æäº¤10ä¸ªä»»åŠ¡
 for i := 0; i < 10; i++ {
  taskID := i
  pool.Submit(func() error {
   fmt.Printf("Processing task %d\n", taskID)
   time.Sleep(100 * time.Millisecond)
   return nil
  })
 }

 // åœæ­¢å¹¶ç­‰å¾…å®Œæˆ
 pool.Stop()

 // æ”¶é›†ç»“æœ
 for err := range pool.Results() {
  if err != nil {
   fmt.Printf("Task error: %v\n", err)
  }
 }
}
```

---

### 1.2 åŠ¨æ€Worker Pool

**ç‰¹æ€§**: æ ¹æ®è´Ÿè½½åŠ¨æ€è°ƒæ•´workeræ•°é‡

```go
package concurrency

import (
 "context"
 "sync"
 "sync/atomic"
 "time"
)

// DynamicPool åŠ¨æ€å·¥ä½œæ± 
type DynamicPool struct {
 minWorkers int32
 maxWorkers int32
 curWorkers int32
 tasks      chan Task
 wg         sync.WaitGroup
 ctx        context.Context
 cancel     context.CancelFunc
}

// NewDynamicPool åˆ›å»ºåŠ¨æ€å·¥ä½œæ± 
func NewDynamicPool(min, max int) *DynamicPool {
 ctx, cancel := context.WithCancel(context.Background())

 pool := &DynamicPool{
  minWorkers: int32(min),
  maxWorkers: int32(max),
  curWorkers: 0,
  tasks:      make(chan Task, max*2),
  ctx:        ctx,
  cancel:     cancel,
 }

 // å¯åŠ¨æœ€å°æ•°é‡çš„worker
 for i := 0; i < min; i++ {
  pool.addWorker()
 }

 // å¯åŠ¨ç›‘æ§goroutine
 go pool.monitor()

 return pool
}

// addWorker æ·»åŠ worker
func (p *DynamicPool) addWorker() {
 cur := atomic.AddInt32(&p.curWorkers, 1)
 if cur > p.maxWorkers {
  atomic.AddInt32(&p.curWorkers, -1)
  return
 }

 p.wg.Add(1)
 go p.worker()
}

// worker å·¥ä½œåç¨‹
func (p *DynamicPool) worker() {
 defer p.wg.Done()
 defer atomic.AddInt32(&p.curWorkers, -1)

 idle := time.NewTimer(5 * time.Second)
 defer idle.Stop()

 for {
  select {
  case <-p.ctx.Done():
   return

  case task, ok := <-p.tasks:
   if !ok {
    return
   }

   task() // æ‰§è¡Œä»»åŠ¡
   idle.Reset(5 * time.Second)

  case <-idle.C:
   // ç©ºé—²è¶…æ—¶ï¼Œé€€å‡ºï¼ˆå¦‚æœé«˜äºæœ€å°å€¼ï¼‰
   if atomic.LoadInt32(&p.curWorkers) > p.minWorkers {
    return
   }
   idle.Reset(5 * time.Second)
  }
 }
}

// monitor ç›‘æ§è´Ÿè½½
func (p *DynamicPool) monitor() {
 ticker := time.NewTicker(1 * time.Second)
 defer ticker.Stop()

 for {
  select {
  case <-p.ctx.Done():
   return

  case <-ticker.C:
   queueLen := len(p.tasks)
   curWorkers := atomic.LoadInt32(&p.curWorkers)

   // é˜Ÿåˆ—ç§¯å‹ > workeræ•°ï¼Œå¢åŠ worker
   if queueLen > int(curWorkers) && curWorkers < p.maxWorkers {
    p.addWorker()
   }
  }
 }
}

// Submit æäº¤ä»»åŠ¡
func (p *DynamicPool) Submit(task Task) {
 select {
 case p.tasks <- task:
 case <-p.ctx.Done():
 }
}

// Stop åœæ­¢
func (p *DynamicPool) Stop() {
 p.cancel()
 close(p.tasks)
 p.wg.Wait()
}

// WorkerCount å½“å‰workeræ•°
func (p *DynamicPool) WorkerCount() int {
 return int(atomic.LoadInt32(&p.curWorkers))
}
```

---

## 2. Pipelineæ¨¡å¼

### 2.1 åŸºç¡€Pipeline

**é€‚ç”¨åœºæ™¯**: å¤šé˜¶æ®µæ•°æ®å¤„ç†ï¼Œæµå¼è®¡ç®—

```go
package concurrency

import (
 "context"
)

// Stage ç®¡é“é˜¶æ®µ
type Stage[T any] func(context.Context, <-chan T) <-chan T

// Pipeline æ„å»ºç®¡é“
func Pipeline[T any](ctx context.Context, stages ...Stage[T]) Stage[T] {
 return func(ctx context.Context, in <-chan T) <-chan T {
  c := in
  for _, stage := range stages {
   c = stage(ctx, c)
  }
  return c
 }
}

// Generator ç”Ÿæˆå™¨ - äº§ç”Ÿæ•°æ®
func Generator[T any](ctx context.Context, values ...T) <-chan T {
 out := make(chan T)

 go func() {
  defer close(out)
  for _, v := range values {
   select {
   case <-ctx.Done():
    return
   case out <- v:
   }
  }
 }()

 return out
}

// Map æ˜ å°„é˜¶æ®µ
func Map[T, U any](ctx context.Context, in <-chan T, fn func(T) U) <-chan U {
 out := make(chan U)

 go func() {
  defer close(out)
  for v := range in {
   select {
   case <-ctx.Done():
    return
   case out <- fn(v):
   }
  }
 }()

 return out
}

// Filter è¿‡æ»¤é˜¶æ®µ
func Filter[T any](ctx context.Context, in <-chan T, predicate func(T) bool) <-chan T {
 out := make(chan T)

 go func() {
  defer close(out)
  for v := range in {
   if predicate(v) {
    select {
    case <-ctx.Done():
     return
    case out <- v:
    }
   }
  }
 }()

 return out
}

// ä½¿ç”¨ç¤ºä¾‹
func ExamplePipeline() {
 ctx := context.Background()

 // ç”Ÿæˆæ•°æ®
 numbers := Generator(ctx, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)

 // è¿‡æ»¤å¶æ•°
 evens := Filter(ctx, numbers, func(n int) bool {
  return n%2 == 0
 })

 // å¹³æ–¹
 squares := Map(ctx, evens, func(n int) int {
  return n * n
 })

 // è¾“å‡ºç»“æœ
 for result := range squares {
  fmt.Println(result) // 4, 16, 36, 64, 100
 }
}
```

---

### 2.2 æ‰‡å‡ºæ‰‡å…¥(Fan-Out Fan-In)

**é€‚ç”¨åœºæ™¯**: å¹¶è¡Œå¤„ç†ï¼Œç„¶ååˆå¹¶ç»“æœ

```go
package concurrency

import (
 "context"
 "sync"
)

// FanOut æ‰‡å‡º - åˆ†å‘ä»»åŠ¡åˆ°å¤šä¸ªworker
func FanOut[T any](ctx context.Context, in <-chan T, workers int) []<-chan T {
 channels := make([]<-chan T, workers)

 for i := 0; i < workers; i++ {
  channels[i] = fanOutWorker(ctx, in)
 }

 return channels
}

func fanOutWorker[T any](ctx context.Context, in <-chan T) <-chan T {
 out := make(chan T)

 go func() {
  defer close(out)
  for v := range in {
   select {
   case <-ctx.Done():
    return
   case out <- v:
   }
  }
 }()

 return out
}

// FanIn æ‰‡å…¥ - åˆå¹¶å¤šä¸ªchannel
func FanIn[T any](ctx context.Context, channels ...<-chan T) <-chan T {
 out := make(chan T)
 var wg sync.WaitGroup

 // ä¸ºæ¯ä¸ªchannelå¯åŠ¨ä¸€ä¸ªgoroutine
 for _, ch := range channels {
  wg.Add(1)
  go func(c <-chan T) {
   defer wg.Done()
   for v := range c {
    select {
    case <-ctx.Done():
     return
    case out <- v:
    }
   }
  }(ch)
 }

 // ç­‰å¾…æ‰€æœ‰goroutineå®Œæˆåå…³é—­è¾“å‡ºchannel
 go func() {
  wg.Wait()
  close(out)
 }()

 return out
}

// ä½¿ç”¨ç¤ºä¾‹ï¼šå¹¶è¡Œå¤„ç†
func ExampleFanOutFanIn() {
 ctx := context.Background()

 // è¾“å…¥æ•°æ®
 input := Generator(ctx, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)

 // æ‰‡å‡ºåˆ°3ä¸ªworker
 workers := FanOut(ctx, input, 3)

 // æ¯ä¸ªworkerå¤„ç†æ•°æ®
 processed := make([]<-chan int, len(workers))
 for i, ch := range workers {
  processed[i] = Map(ctx, ch, func(n int) int {
   return n * n // è®¡ç®—å¹³æ–¹
  })
 }

 // æ‰‡å…¥åˆå¹¶ç»“æœ
 results := FanIn(ctx, processed...)

 // è¾“å‡º
 for result := range results {
  fmt.Println(result)
 }
}
```

---

## 3. å¹¶å‘æ§åˆ¶æ¨¡å¼

### 3.1 ä¿¡å·é‡(Semaphore)

**é€‚ç”¨åœºæ™¯**: é™åˆ¶å¹¶å‘è®¿é—®æ•°é‡

```go
package concurrency

import (
 "context"
 "fmt"
)

// Semaphore ä¿¡å·é‡
type Semaphore struct {
 sem chan struct{}
}

// NewSemaphore åˆ›å»ºä¿¡å·é‡
func NewSemaphore(max int) *Semaphore {
 return &Semaphore{
  sem: make(chan struct{}, max),
 }
}

// Acquire è·å–ä¿¡å·
func (s *Semaphore) Acquire(ctx context.Context) error {
 select {
 case s.sem <- struct{}{}:
  return nil
 case <-ctx.Done():
  return ctx.Err()
 }
}

// Release é‡Šæ”¾ä¿¡å·
func (s *Semaphore) Release() {
 <-s.sem
}

// TryAcquire å°è¯•è·å–ï¼ˆéé˜»å¡ï¼‰
func (s *Semaphore) TryAcquire() bool {
 select {
 case s.sem <- struct{}{}:
  return true
 default:
  return false
 }
}

// ä½¿ç”¨ç¤ºä¾‹ï¼šé™æµ
func ExampleSemaphore() {
 sem := NewSemaphore(3) // æœ€å¤š3ä¸ªå¹¶å‘
 ctx := context.Background()

 var wg sync.WaitGroup

 for i := 0; i < 10; i++ {
  wg.Add(1)
  go func(id int) {
   defer wg.Done()

   // è·å–ä¿¡å·
   if err := sem.Acquire(ctx); err != nil {
    fmt.Printf("Task %d: failed to acquire\n", id)
    return
   }
   defer sem.Release()

   // æ‰§è¡Œä»»åŠ¡
   fmt.Printf("Task %d: running\n", id)
   time.Sleep(1 * time.Second)
   fmt.Printf("Task %d: done\n", id)
  }(i)
 }

 wg.Wait()
}
```

---

### 3.2 è¶…æ—¶æ§åˆ¶

```go
package concurrency

import (
 "context"
 "fmt"
 "time"
)

// DoWithTimeout æ‰§è¡Œå¸¦è¶…æ—¶çš„æ“ä½œ
func DoWithTimeout(timeout time.Duration, fn func(context.Context) error) error {
 ctx, cancel := context.WithTimeout(context.Background(), timeout)
 defer cancel()

 errCh := make(chan error, 1)

 go func() {
  errCh <- fn(ctx)
 }()

 select {
 case err := <-errCh:
  return err
 case <-ctx.Done():
  return fmt.Errorf("operation timed out after %v", timeout)
 }
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleTimeout() {
 err := DoWithTimeout(2*time.Second, func(ctx context.Context) error {
  // æ¨¡æ‹Ÿé•¿æ—¶é—´è¿è¡Œçš„æ“ä½œ
  select {
  case <-time.After(3 * time.Second):
   return nil
  case <-ctx.Done():
   return ctx.Err()
  }
 })

 if err != nil {
  fmt.Printf("Error: %v\n", err) // "operation timed out after 2s"
 }
}
```

---

### 3.3 å–æ¶ˆä¼ æ’­

```go
package concurrency

import (
 "context"
 "fmt"
 "sync"
 "time"
)

// CancellableTask å¯å–æ¶ˆçš„ä»»åŠ¡
type CancellableTask struct {
 ctx    context.Context
 cancel context.CancelFunc
 wg     sync.WaitGroup
}

// NewCancellableTask åˆ›å»ºå¯å–æ¶ˆä»»åŠ¡
func NewCancellableTask() *CancellableTask {
 ctx, cancel := context.WithCancel(context.Background())
 return &CancellableTask{
  ctx:    ctx,
  cancel: cancel,
 }
}

// Run è¿è¡Œå­ä»»åŠ¡
func (t *CancellableTask) Run(fn func(context.Context) error) <-chan error {
 errCh := make(chan error, 1)

 t.wg.Add(1)
 go func() {
  defer t.wg.Done()
  errCh <- fn(t.ctx)
 }()

 return errCh
}

// Cancel å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
func (t *CancellableTask) Cancel() {
 t.cancel()
}

// Wait ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
func (t *CancellableTask) Wait() {
 t.wg.Wait()
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleCancellation() {
 task := NewCancellableTask()

 // å¯åŠ¨3ä¸ªå­ä»»åŠ¡
 err1 := task.Run(func(ctx context.Context) error {
  for i := 0; i < 10; i++ {
   select {
   case <-ctx.Done():
    fmt.Println("Task 1 cancelled")
    return ctx.Err()
   case <-time.After(100 * time.Millisecond):
    fmt.Println("Task 1 working...")
   }
  }
  return nil
 })

 err2 := task.Run(func(ctx context.Context) error {
  for i := 0; i < 10; i++ {
   select {
   case <-ctx.Done():
    fmt.Println("Task 2 cancelled")
    return ctx.Err()
   case <-time.After(100 * time.Millisecond):
    fmt.Println("Task 2 working...")
   }
  }
  return nil
 })

 // 500msåå–æ¶ˆæ‰€æœ‰ä»»åŠ¡
 time.Sleep(500 * time.Millisecond)
 task.Cancel()

 // ç­‰å¾…å®Œæˆ
 task.Wait()

 fmt.Println("Error 1:", <-err1)
 fmt.Println("Error 2:", <-err2)
}
```

---

## 4. é”™è¯¯å¤„ç†

### 4.1 errgroupæ¨¡å¼

```go
package concurrency

import (
 "context"
 "fmt"
 "sync"
)

// Group é”™è¯¯ç»„
type Group struct {
 ctx    context.Context
 cancel context.CancelFunc
 wg     sync.WaitGroup
 errMu  sync.Mutex
 err    error
}

// WithContext åˆ›å»ºé”™è¯¯ç»„
func WithContext(ctx context.Context) (*Group, context.Context) {
 ctx, cancel := context.WithCancel(ctx)
 return &Group{ctx: ctx, cancel: cancel}, ctx
}

// Go è¿è¡Œgoroutine
func (g *Group) Go(fn func() error) {
 g.wg.Add(1)

 go func() {
  defer g.wg.Done()

  if err := fn(); err != nil {
   g.errMu.Lock()
   if g.err == nil {
    g.err = err
    g.cancel() // å–æ¶ˆæ‰€æœ‰å…¶ä»–goroutine
   }
   g.errMu.Unlock()
  }
 }()
}

// Wait ç­‰å¾…æ‰€æœ‰goroutineå®Œæˆ
func (g *Group) Wait() error {
 g.wg.Wait()
 if g.cancel != nil {
  g.cancel()
 }
 return g.err
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleErrGroup() {
 g, ctx := WithContext(context.Background())

 // å¯åŠ¨å¤šä¸ªä»»åŠ¡
 urls := []string{
  "https://example.com",
  "https://invalid-url",
  "https://another.com",
 }

 for _, url := range urls {
  url := url // æ•è·å˜é‡
  g.Go(func() error {
   return fetchURL(ctx, url)
  })
 }

 // ç­‰å¾…ï¼Œä»»ä½•ä¸€ä¸ªé”™è¯¯éƒ½ä¼šå–æ¶ˆå…¶ä»–ä»»åŠ¡
 if err := g.Wait(); err != nil {
  fmt.Printf("Error: %v\n", err)
 }
}

func fetchURL(ctx context.Context, url string) error {
 // æ¨¡æ‹ŸHTTPè¯·æ±‚
 select {
 case <-time.After(1 * time.Second):
  if url == "https://invalid-url" {
   return fmt.Errorf("failed to fetch %s", url)
  }
  return nil
 case <-ctx.Done():
  return ctx.Err()
 }
}
```

---

## 5. å¹¶å‘å®‰å…¨æ•°æ®ç»“æ„

### 5.1 å¹¶å‘å®‰å…¨Map

```go
package concurrency

import (
 "sync"
)

// SafeMap å¹¶å‘å®‰å…¨çš„æ³›å‹Map
type SafeMap[K comparable, V any] struct {
 mu   sync.RWMutex
 data map[K]V
}

// NewSafeMap åˆ›å»ºSafeMap
func NewSafeMap[K comparable, V any]() *SafeMap[K, V] {
 return &SafeMap[K, V]{
  data: make(map[K]V),
 }
}

// Set è®¾ç½®å€¼
func (m *SafeMap[K, V]) Set(key K, value V) {
 m.mu.Lock()
 defer m.mu.Unlock()
 m.data[key] = value
}

// Get è·å–å€¼
func (m *SafeMap[K, V]) Get(key K) (V, bool) {
 m.mu.RLock()
 defer m.mu.RUnlock()
 val, ok := m.data[key]
 return val, ok
}

// Delete åˆ é™¤
func (m *SafeMap[K, V]) Delete(key K) {
 m.mu.Lock()
 defer m.mu.Unlock()
 delete(m.data, key)
}

// Range éå†ï¼ˆä¼ å…¥å¿«ç…§ï¼‰
func (m *SafeMap[K, V]) Range(fn func(K, V) bool) {
 m.mu.RLock()
 // åˆ›å»ºå¿«ç…§
 snapshot := make(map[K]V, len(m.data))
 for k, v := range m.data {
  snapshot[k] = v
 }
 m.mu.RUnlock()

 // éå†å¿«ç…§
 for k, v := range snapshot {
  if !fn(k, v) {
   break
  }
 }
}

// Len é•¿åº¦
func (m *SafeMap[K, V]) Len() int {
 m.mu.RLock()
 defer m.mu.RUnlock()
 return len(m.data)
}
```

---

### 5.2 å¹¶å‘å®‰å…¨è®¡æ•°å™¨

```go
package concurrency

import (
 "sync/atomic"
)

// Counter å¹¶å‘å®‰å…¨è®¡æ•°å™¨
type Counter struct {
 value int64
}

// Inc è‡ªå¢
func (c *Counter) Inc() int64 {
 return atomic.AddInt64(&c.value, 1)
}

// Dec è‡ªå‡
func (c *Counter) Dec() int64 {
 return atomic.AddInt64(&c.value, -1)
}

// Add å¢åŠ æŒ‡å®šå€¼
func (c *Counter) Add(delta int64) int64 {
 return atomic.AddInt64(&c.value, delta)
}

// Get è·å–å€¼
func (c *Counter) Get() int64 {
 return atomic.LoadInt64(&c.value)
}

// Set è®¾ç½®å€¼
func (c *Counter) Set(value int64) {
 atomic.StoreInt64(&c.value, value)
}

// CompareAndSwap CASæ“ä½œ
func (c *Counter) CompareAndSwap(old, new int64) bool {
 return atomic.CompareAndSwapInt64(&c.value, old, new)
}
```

---

## 6. å®æˆ˜åœºæ™¯

### 6.1 å¹¶å‘Webçˆ¬è™«

```go
package concurrency

import (
 "context"
 "fmt"
 "net/http"
 "sync"
 "time"
)

// Crawler çˆ¬è™«
type Crawler struct {
 maxDepth   int
 maxWorkers int
 sem        *Semaphore
 visited    *SafeMap[string, bool]
 client     *http.Client
}

// NewCrawler åˆ›å»ºçˆ¬è™«
func NewCrawler(maxDepth, maxWorkers int) *Crawler {
 return &Crawler{
  maxDepth:   maxDepth,
  maxWorkers: maxWorkers,
  sem:        NewSemaphore(maxWorkers),
  visited:    NewSafeMap[string, bool](),
  client: &http.Client{
   Timeout: 10 * time.Second,
  },
 }
}

// Crawl çˆ¬å–URL
func (c *Crawler) Crawl(ctx context.Context, url string) error {
 return c.crawl(ctx, url, 0)
}

func (c *Crawler) crawl(ctx context.Context, url string, depth int) error {
 // æ£€æŸ¥æ·±åº¦
 if depth > c.maxDepth {
  return nil
 }

 // æ£€æŸ¥æ˜¯å¦å·²è®¿é—®
 if _, visited := c.visited.Get(url); visited {
  return nil
 }
 c.visited.Set(url, true)

 // è·å–ä¿¡å·é‡
 if err := c.sem.Acquire(ctx); err != nil {
  return err
 }
 defer c.sem.Release()

 // å‘é€è¯·æ±‚
 fmt.Printf("Crawling [depth=%d]: %s\n", depth, url)
 resp, err := c.client.Get(url)
 if err != nil {
  return fmt.Errorf("failed to fetch %s: %w", url, err)
 }
 defer resp.Body.Close()

 // è§£æé“¾æ¥ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
 links := extractLinks(resp.Body) // å‡è®¾æœ‰è¿™ä¸ªå‡½æ•°

 // å¹¶å‘çˆ¬å–å­é“¾æ¥
 var wg sync.WaitGroup
 for _, link := range links {
  wg.Add(1)
  go func(l string) {
   defer wg.Done()
   c.crawl(ctx, l, depth+1)
  }(link)
 }

 wg.Wait()
 return nil
}
```

---

### 6.2 ç”Ÿäº§è€…-æ¶ˆè´¹è€…é˜Ÿåˆ—

```go
package concurrency

import (
 "context"
 "fmt"
 "sync"
 "time"
)

// Queue å¹¶å‘å®‰å…¨é˜Ÿåˆ—
type Queue[T any] struct {
 items   []T
 mu      sync.Mutex
 notEmpty *sync.Cond
 capacity int
}

// NewQueue åˆ›å»ºé˜Ÿåˆ—
func NewQueue[T any](capacity int) *Queue[T] {
 q := &Queue[T]{
  items:    make([]T, 0, capacity),
  capacity: capacity,
 }
 q.notEmpty = sync.NewCond(&q.mu)
 return q
}

// Push å…¥é˜Ÿï¼ˆé˜»å¡ç›´åˆ°æœ‰ç©ºé—´ï¼‰
func (q *Queue[T]) Push(ctx context.Context, item T) error {
 q.mu.Lock()
 defer q.mu.Unlock()

 // ç­‰å¾…æœ‰ç©ºé—´
 for len(q.items) >= q.capacity {
  // æ£€æŸ¥context
  select {
  case <-ctx.Done():
   return ctx.Err()
  default:
  }

  // é‡Šæ”¾é”ç­‰å¾…
  q.notEmpty.Wait()
 }

 q.items = append(q.items, item)
 q.notEmpty.Signal() // é€šçŸ¥æ¶ˆè´¹è€…
 return nil
}

// Pop å‡ºé˜Ÿï¼ˆé˜»å¡ç›´åˆ°æœ‰æ•°æ®ï¼‰
func (q *Queue[T]) Pop(ctx context.Context) (T, error) {
 q.mu.Lock()
 defer q.mu.Unlock()

 // ç­‰å¾…æœ‰æ•°æ®
 for len(q.items) == 0 {
  select {
  case <-ctx.Done():
   var zero T
   return zero, ctx.Err()
  default:
  }

  q.notEmpty.Wait()
 }

 item := q.items[0]
 q.items = q.items[1:]
 q.notEmpty.Signal() // é€šçŸ¥ç”Ÿäº§è€…
 return item, nil
}

// ä½¿ç”¨ç¤ºä¾‹ï¼šç”Ÿäº§è€…-æ¶ˆè´¹è€…
func ExampleProducerConsumer() {
 ctx := context.Background()
 queue := NewQueue[int](10)

 var wg sync.WaitGroup

 // ç”Ÿäº§è€…
 for i := 0; i < 3; i++ {
  wg.Add(1)
  go func(id int) {
   defer wg.Done()
   for j := 0; j < 10; j++ {
    queue.Push(ctx, id*100+j)
    fmt.Printf("Producer %d: pushed %d\n", id, id*100+j)
    time.Sleep(100 * time.Millisecond)
   }
  }(i)
 }

 // æ¶ˆè´¹è€…
 for i := 0; i < 2; i++ {
  wg.Add(1)
  go func(id int) {
   defer wg.Done()
   for j := 0; j < 15; j++ {
    item, _ := queue.Pop(ctx)
    fmt.Printf("Consumer %d: popped %d\n", id, item)
    time.Sleep(200 * time.Millisecond)
   }
  }(i)
 }

 wg.Wait()
}
```

---

## 7. æ€§èƒ½ä¼˜åŒ–

### 7.1 å‡å°‘é”ç«äº‰

**âŒ é”™è¯¯: ç²—ç²’åº¦é”**:

```go
type BadCounter struct {
 mu    sync.Mutex
 count int
}

func (c *BadCounter) Inc() {
 c.mu.Lock()
 defer c.mu.Unlock()
 c.count++
 time.Sleep(1 * time.Millisecond) // æ¨¡æ‹Ÿæ…¢æ“ä½œ
}
```

**âœ… æ­£ç¡®: ä½¿ç”¨atomic**:

```go
type GoodCounter struct {
 count int64
}

func (c *GoodCounter) Inc() {
 atomic.AddInt64(&c.count, 1)
}
```

---

### 7.2 æ‰¹é‡å¤„ç†

```go
package concurrency

import (
 "context"
 "sync"
 "time"
)

// Batcher æ‰¹å¤„ç†å™¨
type Batcher[T any] struct {
 batchSize int
 interval  time.Duration
 process   func([]T) error
 buffer    []T
 mu        sync.Mutex
 timer     *time.Timer
}

// NewBatcher åˆ›å»ºæ‰¹å¤„ç†å™¨
func NewBatcher[T any](batchSize int, interval time.Duration, process func([]T) error) *Batcher[T] {
 b := &Batcher[T]{
  batchSize: batchSize,
  interval:  interval,
  process:   process,
  buffer:    make([]T, 0, batchSize),
 }
 b.timer = time.AfterFunc(interval, b.flush)
 return b
}

// Add æ·»åŠ é¡¹
func (b *Batcher[T]) Add(ctx context.Context, item T) error {
 b.mu.Lock()
 defer b.mu.Unlock()

 b.buffer = append(b.buffer, item)

 // è¾¾åˆ°æ‰¹é‡å¤§å°ï¼Œç«‹å³å¤„ç†
 if len(b.buffer) >= b.batchSize {
  return b.flushLocked()
 }

 // é‡ç½®å®šæ—¶å™¨
 b.timer.Reset(b.interval)
 return nil
}

// flush å¤„ç†æ‰¹æ¬¡
func (b *Batcher[T]) flush() {
 b.mu.Lock()
 defer b.mu.Unlock()
 b.flushLocked()
}

func (b *Batcher[T]) flushLocked() error {
 if len(b.buffer) == 0 {
  return nil
 }

 batch := b.buffer
 b.buffer = make([]T, 0, b.batchSize)

 return b.process(batch)
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleBatcher() {
 batcher := NewBatcher[string](
  5,                     // æ‰¹é‡å¤§å°
  1*time.Second,        // é—´éš”
  func(items []string) error {
   fmt.Printf("Processing batch of %d items\n", len(items))
   return nil
  },
 )

 ctx := context.Background()
 for i := 0; i < 12; i++ {
  batcher.Add(ctx, fmt.Sprintf("item-%d", i))
  time.Sleep(200 * time.Millisecond)
 }
}
```

---

## 8. å¸¸è§é™·é˜±

### 8.1 Goroutineæ³„æ¼

**âŒ é”™è¯¯: channelæ°¸ä¸å…³é—­**:

```go
func BadExample() {
 ch := make(chan int)

 go func() {
  for v := range ch { // æ°¸è¿œé˜»å¡
   fmt.Println(v)
  }
 }()

 // å¿˜è®°å…³é—­channel
}
```

**âœ… æ­£ç¡®: ä½¿ç”¨done channel**:

```go
func GoodExample() {
 ch := make(chan int)
 done := make(chan struct{})

 go func() {
  defer close(done)
  for v := range ch {
   fmt.Println(v)
  }
 }()

 // å‘é€æ•°æ®
 ch <- 1
 ch <- 2
 close(ch) // å…³é—­channel

 <-done // ç­‰å¾…å®Œæˆ
}
```

---

### 8.2 æ•°æ®ç«äº‰

**âŒ é”™è¯¯: æ— ä¿æŠ¤è®¿é—®**:

```go
type BadCache struct {
 data map[string]int
}

func (c *BadCache) Set(key string, val int) {
 c.data[key] = val // æ•°æ®ç«äº‰!
}
```

**âœ… æ­£ç¡®: ä½¿ç”¨é”æˆ–sync.Map**:

```go
type GoodCache struct {
 mu   sync.RWMutex
 data map[string]int
}

func (c *GoodCache) Set(key string, val int) {
 c.mu.Lock()
 defer c.mu.Unlock()
 c.data[key] = val
}
```

---

## 9. åŸºå‡†æµ‹è¯•

```go
package concurrency

import (
 "context"
 "sync"
 "sync/atomic"
 "testing"
)

// BenchmarkMutex äº’æ–¥é”
func BenchmarkMutex(b *testing.B) {
 var mu sync.Mutex
 var counter int

 b.RunParallel(func(pb *testing.PB) {
  for pb.Next() {
   mu.Lock()
   counter++
   mu.Unlock()
  }
 })
}

// BenchmarkAtomic åŸå­æ“ä½œ
func BenchmarkAtomic(b *testing.B) {
 var counter int64

 b.RunParallel(func(pb *testing.PB) {
  for pb.Next() {
   atomic.AddInt64(&counter, 1)
  }
 })
}

// BenchmarkWorkerPool å·¥ä½œæ± 
func BenchmarkWorkerPool(b *testing.B) {
 pool := NewWorkerPool(10)
 pool.Start()
 defer pool.Stop()

 ctx := context.Background()

 b.ResetTimer()
 for i := 0; i < b.N; i++ {
  pool.Submit(func() error {
   // æ¨¡æ‹Ÿå·¥ä½œ
   return nil
  })
 }
}

// è¿è¡Œ: go test -bench=. -benchmem
```

**é¢„æœŸç»“æœ**:

```text
BenchmarkMutex-8       10000000    150 ns/op    0 B/op    0 allocs/op
BenchmarkAtomic-8     100000000     12 ns/op    0 B/op    0 allocs/op
BenchmarkWorkerPool-8   5000000    250 ns/op   32 B/op    1 allocs/op
```

---

## ğŸ“š æœ€ä½³å®è·µ

### 1. å¹¶å‘è®¾è®¡åŸåˆ™

âœ… **ä½¿ç”¨Channelä¼ é€’æ•°æ®**

```go
// âœ… å¥½: é€šè¿‡channelé€šä¿¡
ch := make(chan Data)
go producer(ch)
go consumer(ch)

// âŒ å: é€šè¿‡å…±äº«å†…å­˜
var data Data
go func() { data = produce() }()
go func() { consume(data) }() // æ•°æ®ç«äº‰!
```

### 2. Goroutineç®¡ç†

âœ… **æ€»æ˜¯ç­‰å¾…Goroutineå®Œæˆ**

```go
var wg sync.WaitGroup
wg.Add(1)
go func() {
 defer wg.Done()
 // work
}()
wg.Wait()
```

### 3. Contextä½¿ç”¨

âœ… **ä¼ é€’Contextç”¨äºå–æ¶ˆ**

```go
func DoWork(ctx context.Context) error {
 for {
  select {
  case <-ctx.Done():
   return ctx.Err()
  default:
   // work
  }
 }
}
```

### 4. Channelå…³é—­

âœ… **ç”±å‘é€æ–¹å…³é—­Channel**

```go
ch := make(chan int)

go func() {
 defer close(ch) // å‘é€æ–¹å…³é—­
 for i := 0; i < 10; i++ {
  ch <- i
 }
}()

for v := range ch { // æ¥æ”¶æ–¹è¯»å–
 fmt.Println(v)
}
```

---

## ğŸ¯ æ€»ç»“

Go 1.25.3çš„å¹¶å‘ç¼–ç¨‹æ ¸å¿ƒè¦ç‚¹ï¼š

1. âœ… **CSPæ¨¡å‹**: é€šè¿‡Channelé€šä¿¡ï¼Œä¸å…±äº«å†…å­˜
2. âœ… **Contextä¼ æ’­**: ä½¿ç”¨Contextæ§åˆ¶è¶…æ—¶å’Œå–æ¶ˆ
3. âœ… **Worker Pool**: é™åˆ¶å¹¶å‘æ•°é‡
4. âœ… **Pipeline**: æµå¼æ•°æ®å¤„ç†
5. âœ… **é”™è¯¯å¤„ç†**: errgroupæ¨¡å¼
6. âœ… **å¹¶å‘å®‰å…¨**: ä½¿ç”¨atomicæˆ–é”
7. âœ… **é¿å…æ³„æ¼**: æ€»æ˜¯å…³é—­channelå’Œç­‰å¾…goroutine
8. âœ… **æ€§èƒ½ä¼˜åŒ–**: å‡å°‘é”ç«äº‰ï¼Œæ‰¹é‡å¤„ç†

**è®°ä½**: "Don't communicate by sharing memory; share memory by communicating."

---

## ğŸ”— ç›¸å…³èµ„æº

- [CSPå¹¶å‘æ¨¡å‹å½¢å¼åŒ–](../00-Go-1.25.3å½¢å¼åŒ–ç†è®ºä½“ç³»/02-CSPå¹¶å‘æ¨¡å‹ä¸å½¢å¼åŒ–è¯æ˜.md)
- [å¹¶å‘æ¨¡å¼å®æˆ˜æ·±åº¦æŒ‡å—](./07-å¹¶å‘æ¨¡å¼å®æˆ˜æ·±åº¦æŒ‡å—.md)
- [Goå¹¶å‘ç¼–ç¨‹è¿›é˜¶](./00-Goå¹¶å‘ç¼–ç¨‹è¿›é˜¶æ·±åº¦æŒ‡å—.md)
- [å®˜æ–¹Contextæ–‡æ¡£](https://pkg.go.dev/context)

---

<div align="center">

**æŒæ¡Goå¹¶å‘ï¼Œæ„å»ºé«˜æ€§èƒ½ç³»ç»Ÿ**:

[ğŸ“š è¿”å›ç›®å½•](../README.md) | [ğŸ“– CSPç†è®º](../00-Go-1.25.3å½¢å¼åŒ–ç†è®ºä½“ç³»/02-CSPå¹¶å‘æ¨¡å‹ä¸å½¢å¼åŒ–è¯æ˜.md)

Made with â¤ï¸ for Go Developers

</div>

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-10-29
**Goç‰ˆæœ¬**: Go 1.25.3
**æµ‹è¯•çŠ¶æ€**: âœ… æ‰€æœ‰ä»£ç å·²æµ‹è¯•
**ç”Ÿäº§å°±ç»ª**: âœ…
