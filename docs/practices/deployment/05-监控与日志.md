# 监控与日志

**版本**: v1.0
**更新日期**: 2025-11-11
**适用于**: Go 1.25.3

---

## 📋 目录

- [监控与日志](#监控与日志)
  - [📋 目录](#-目录)
  - [1. 📖 概念介绍](#1--概念介绍)
  - [2. 🎯 监控系统](#2--监控系统)
    - [2.1 Prometheus监控](#21-prometheus监控)
    - [2.2 Grafana仪表板](#22-grafana仪表板)
  - [3. 📝 日志系统](#3--日志系统)
    - [3.1 结构化日志](#31-结构化日志)
    - [3.2 日志级别](#32-日志级别)
    - [3.3 日志轮转](#33-日志轮转)
  - [4. 📊 ELK Stack](#4--elk-stack)
    - [4.1 Filebeat配置](#41-filebeat配置)
    - [4.2 完整监控栈](#42-完整监控栈)
  - [5. 💡 最佳实践](#5--最佳实践)
    - [5.1 监控最佳实践](#51-监控最佳实践)
    - [5.2 日志最佳实践](#52-日志最佳实践)
    - [5.3 告警最佳实践](#53-告警最佳实践)
    - [5.4 性能优化最佳实践](#54-性能优化最佳实践)
  - [6. 📚 相关资源](#6--相关资源)

---

## 1. 📖 概念介绍

监控和日志是生产环境运维的核心，帮助快速发现和定位问题。根据生产环境的实际经验，完善的监控和日志系统可以将故障发现时间从数小时缩短到数分钟，将故障定位时间从数小时缩短到数十分钟，将系统可用性提升 99%+。

**监控和日志性能对比**:

| 操作类型 | 无监控/日志 | 基础监控/日志 | 完善监控/日志 | 提升比例 |
|---------|-----------|-------------|-------------|---------|
| **故障发现时间** | 2-4 小时 | 30-60 分钟 | 2-5 分钟 | -95%+ |
| **故障定位时间** | 4-8 小时 | 1-2 小时 | 10-30 分钟 | -90%+ |
| **系统可用性** | 95% | 99% | 99.9%+ | +4.2% |
| **MTTR (平均修复时间)** | 4-8 小时 | 1-2 小时 | 20-40 分钟 | -90%+ |
| **告警准确率** | 30-40% | 60-70% | 90%+ | +150%+ |

**监控和日志核心价值**:

1. **快速发现问题**: 实时监控关键指标，快速发现异常（减少发现时间 95%+）
2. **快速定位问题**: 结构化日志和分布式追踪，快速定位根因（减少定位时间 90%+）
3. **预防性维护**: 趋势分析和预测性告警，预防故障发生（提升可用性 4%+）
4. **性能优化**: 性能指标分析，识别性能瓶颈（提升性能 20-30%）

---

## 2. 🎯 监控系统

### 2.1 Prometheus监控

**完整的生产环境 Prometheus 监控实现**:

```go
// internal/infrastructure/observability/metrics.go
package observability

import (
    "net/http"
    "time"

    "github.com/go-chi/chi/v5"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
    "github.com/prometheus/client_golang/prometheus/promhttp"
    "log/slog"
)

// Metrics 指标集合
type Metrics struct {
    // Golden Signals: Latency, Traffic, Errors, Saturation

    // Traffic: HTTP 请求总数
    HTTPRequestsTotal *prometheus.CounterVec

    // Errors: HTTP 错误总数
    HTTPErrorsTotal *prometheus.CounterVec

    // Latency: HTTP 请求延迟（直方图）
    HTTPRequestDuration *prometheus.HistogramVec

    // Saturation: 活跃连接数
    ActiveConnections prometheus.Gauge

    // 业务指标
    UserRegistrationsTotal prometheus.Counter
    UserLoginFailuresTotal prometheus.Counter

    // 系统指标
    GoGoroutines prometheus.Gauge
    GoMemoryAllocBytes prometheus.Gauge
    GoMemorySysBytes prometheus.Gauge
}

// NewMetrics 创建指标集合
func NewMetrics() *Metrics {
    return &Metrics{
        HTTPRequestsTotal: promauto.NewCounterVec(
            prometheus.CounterOpts{
                Name: "http_requests_total",
                Help: "Total number of HTTP requests by method, path, and status code",
            },
            []string{"method", "path", "status"},
        ),

        HTTPErrorsTotal: promauto.NewCounterVec(
            prometheus.CounterOpts{
                Name: "http_errors_total",
                Help: "Total number of HTTP errors by method, path, and status code",
            },
            []string{"method", "path", "status"},
        ),

        HTTPRequestDuration: promauto.NewHistogramVec(
            prometheus.HistogramOpts{
                Name:    "http_request_duration_seconds",
                Help:    "HTTP request latencies in seconds",
                Buckets: []float64{0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10},
            },
            []string{"method", "path", "status"},
        ),

        ActiveConnections: promauto.NewGauge(
            prometheus.GaugeOpts{
                Name: "http_active_connections",
                Help: "Number of currently active HTTP connections",
            },
        ),

        UserRegistrationsTotal: promauto.NewCounter(
            prometheus.CounterOpts{
                Name: "app_user_registrations_total",
                Help: "Total number of user registrations",
            },
        ),

        UserLoginFailuresTotal: promauto.NewCounter(
            prometheus.CounterOpts{
                Name: "app_user_login_failures_total",
                Help: "Total number of user login failures",
            },
        ),

        GoGoroutines: promauto.NewGauge(
            prometheus.GaugeOpts{
                Name: "go_goroutines",
                Help: "Number of goroutines",
            },
        ),

        GoMemoryAllocBytes: promauto.NewGauge(
            prometheus.GaugeOpts{
                Name: "go_memstats_alloc_bytes",
                Help: "Number of bytes allocated",
            },
        ),

        GoMemorySysBytes: promauto.NewGauge(
            prometheus.GaugeOpts{
                Name: "go_memstats_sys_bytes",
                Help: "Number of bytes obtained from system",
            },
        ),
    }
}

// MetricsMiddleware HTTP 中间件
func (m *Metrics) MetricsMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()

        // 增加活跃连接数
        m.ActiveConnections.Inc()
        defer m.ActiveConnections.Dec()

        // 包装 ResponseWriter 以捕获状态码
        rw := &responseWriter{ResponseWriter: w, statusCode: http.StatusOK}

        // 调用下一个处理器
        next.ServeHTTP(rw, r)

        // 记录请求指标
        duration := time.Since(start).Seconds()
        statusCode := http.StatusText(rw.statusCode)

        m.HTTPRequestsTotal.WithLabelValues(r.Method, r.URL.Path, statusCode).Inc()
        m.HTTPRequestDuration.WithLabelValues(r.Method, r.URL.Path, statusCode).Observe(duration)

        // 记录错误
        if rw.statusCode >= 400 {
            m.HTTPErrorsTotal.WithLabelValues(r.Method, r.URL.Path, statusCode).Inc()
        }
    })
}

// RegisterMetrics 注册指标路由
func (m *Metrics) RegisterMetrics(router *chi.Mux) {
    router.Handle("/metrics", promhttp.Handler())
}

// StartSystemMetrics 启动系统指标收集
func (m *Metrics) StartSystemMetrics() {
    go func() {
        ticker := time.NewTicker(10 * time.Second)
        defer ticker.Stop()

        for range ticker.C {
            var memStats runtime.MemStats
            runtime.ReadMemStats(&memStats)

            m.GoGoroutines.Set(float64(runtime.NumGoroutine()))
            m.GoMemoryAllocBytes.Set(float64(memStats.Alloc))
            m.GoMemorySysBytes.Set(float64(memStats.Sys))
        }
    }()
}

// responseWriter 包装 ResponseWriter 以捕获状态码
type responseWriter struct {
    http.ResponseWriter
    statusCode int
}

func (rw *responseWriter) WriteHeader(code int) {
    rw.statusCode = code
    rw.ResponseWriter.WriteHeader(code)
}
```

**Prometheus 配置优化**:

```yaml
# prometheus.yml
global:
  scrape_interval: 15s      # 抓取间隔
  evaluation_interval: 15s  # 评估间隔
  external_labels:
    cluster: 'production'
    environment: 'prod'

# 告警管理器配置
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - 'alertmanager:9093'

# 告警规则
rule_files:
  - '/etc/prometheus/alerts/*.yml'

# 抓取配置
scrape_configs:
  # 应用指标
  - job_name: 'myapp'
    static_configs:
      - targets: ['myapp:8080']
    scrape_interval: 10s
    metrics_path: '/metrics'
    scrape_timeout: 5s

  # Kubernetes 服务发现
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
```

**Prometheus 告警规则**:

```yaml
# alerts/app.yml
groups:
  - name: application
    interval: 30s
    rules:
      # 高错误率告警
      - alert: HighErrorRate
        expr: |
          rate(http_errors_total[5m]) / rate(http_requests_total[5m]) > 0.01
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} (threshold: 1%)"

      # 高延迟告警
      - alert: HighLatency
        expr: |
          histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High latency detected"
          description: "P99 latency is {{ $value }}s (threshold: 1s)"

      # 低请求率告警
      - alert: LowRequestRate
        expr: |
          rate(http_requests_total[5m]) < 10
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Low request rate detected"
          description: "Request rate is {{ $value }} req/s (threshold: 10 req/s)"

      # 高活跃连接数告警
      - alert: HighActiveConnections
        expr: |
          http_active_connections > 1000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High active connections"
          description: "Active connections: {{ $value }} (threshold: 1000)"
```

**Prometheus 性能优化对比**:

| 优化项 | 未优化 | 优化后 | 提升比例 |
|--------|--------|--------|---------|
| **抓取延迟** | 100-200ms | 10-20ms | -90% |
| **存储空间** | 100GB | 20-30GB | -70-80% |
| **查询延迟** | 500-1000ms | 50-100ms | -90% |
| **告警延迟** | 1-2 分钟 | 5-10 秒 | -90%+ |
| **资源占用** | 4GB RAM | 1-2GB RAM | -50-75% |

---

### 2.2 Grafana仪表板

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'myapp'
    static_configs:
      - targets: ['localhost:8080']
    scrape_interval: 15s
```

---

## 3. 📝 日志系统

### 3.1 结构化日志

**完整的生产环境结构化日志实现（使用 Go 1.21+ slog）**:

```go
// internal/infrastructure/logging/logger.go
package logging

import (
    "context"
    "io"
    "log/slog"
    "os"
    "time"

    "github.com/go-chi/chi/v5/middleware"
)

// Logger 日志记录器
type Logger struct {
    logger *slog.Logger
    level  slog.Level
}

// NewLogger 创建日志记录器
func NewLogger(level string, output io.Writer) *Logger {
    var logLevel slog.Level
    switch level {
    case "debug":
        logLevel = slog.LevelDebug
    case "info":
        logLevel = slog.LevelInfo
    case "warn":
        logLevel = slog.LevelWarn
    case "error":
        logLevel = slog.LevelError
    default:
        logLevel = slog.LevelInfo
    }

    opts := &slog.HandlerOptions{
        Level:     logLevel,
        AddSource: true, // 添加源代码位置
    }

    handler := slog.NewJSONHandler(output, opts)
    logger := slog.New(handler)

    slog.SetDefault(logger)

    return &Logger{
        logger: logger,
        level:  logLevel,
    }
}

// WithContext 从上下文获取请求ID和追踪信息
func (l *Logger) WithContext(ctx context.Context) *slog.Logger {
    attrs := []slog.Attr{}

    // 从上下文获取请求ID
    if requestID := middleware.GetReqID(ctx); requestID != "" {
        attrs = append(attrs, slog.String("request_id", requestID))
    }

    // 从上下文获取追踪信息
    if traceID := ctx.Value("trace_id"); traceID != nil {
        attrs = append(attrs, slog.String("trace_id", traceID.(string)))
    }

    if spanID := ctx.Value("span_id"); spanID != nil {
        attrs = append(attrs, slog.String("span_id", spanID.(string)))
    }

    return l.logger.With(attrs...)
}

// LoggingMiddleware HTTP 日志中间件
func (l *Logger) LoggingMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()

        // 包装 ResponseWriter 以捕获状态码和响应大小
        rw := &loggingResponseWriter{
            ResponseWriter: w,
            statusCode:     http.StatusOK,
        }

        // 调用下一个处理器
        next.ServeHTTP(rw, r)

        // 记录请求日志
        duration := time.Since(start)
        logger := l.WithContext(r.Context())

        attrs := []slog.Attr{
            slog.String("method", r.Method),
            slog.String("path", r.URL.Path),
            slog.String("query", r.URL.RawQuery),
            slog.Int("status", rw.statusCode),
            slog.Duration("duration", duration),
            slog.Int("size", rw.size),
            slog.String("ip", r.RemoteAddr),
            slog.String("user_agent", r.UserAgent()),
        }

        // 根据状态码选择日志级别
        if rw.statusCode >= 500 {
            logger.Error("HTTP request failed", attrs...)
        } else if rw.statusCode >= 400 {
            logger.Warn("HTTP request error", attrs...)
        } else {
            logger.Info("HTTP request", attrs...)
        }
    })
}

// loggingResponseWriter 包装 ResponseWriter
type loggingResponseWriter struct {
    http.ResponseWriter
    statusCode int
    size       int
}

func (rw *loggingResponseWriter) WriteHeader(code int) {
    rw.statusCode = code
    rw.ResponseWriter.WriteHeader(code)
}

func (rw *loggingResponseWriter) Write(b []byte) (int, error) {
    size, err := rw.ResponseWriter.Write(b)
    rw.size += size
    return size, err
}

// 使用示例
func ExampleUsage() {
    logger := NewLogger("info", os.Stdout)

    // 基础日志
    logger.logger.Info("Server started",
        slog.String("port", "8080"),
        slog.String("env", "production"),
    )

    // 带上下文的日志
    ctx := context.WithValue(context.Background(), "trace_id", "trace-123")
    logger.WithContext(ctx).Info("Processing request",
        slog.String("user_id", "user-123"),
        slog.String("action", "create_user"),
    )

    // 错误日志
    err := errors.New("database connection failed")
    logger.logger.Error("Operation failed",
        slog.String("operation", "create_user"),
        slog.Any("error", err),
    )
}
```

**日志轮转配置（使用 lumberjack）**:

```go
// internal/infrastructure/logging/rotation.go
package logging

import (
    "gopkg.in/natefinch/lumberjack.v2"
    "log/slog"
)

// NewRotatingLogger 创建轮转日志记录器
func NewRotatingLogger(level string, logFile string) *Logger {
    writer := &lumberjack.Logger{
        Filename:   logFile,
        MaxSize:    100, // MB
        MaxBackups: 10,  // 保留10个备份
        MaxAge:     30,  // 保留30天
        Compress:   true, // 压缩旧日志
        LocalTime:  true,
    }

    return NewLogger(level, writer)
}
```

**日志性能优化对比**:

| 优化项 | 未优化 | 优化后 | 提升比例 |
|--------|--------|--------|---------|
| **日志写入延迟** | 5-10ms | 0.5-1ms | -90% |
| **磁盘空间占用** | 100GB | 20-30GB | -70-80% |
| **日志查询速度** | 10-30秒 | 1-3秒 | -90% |
| **内存占用** | 500MB | 50-100MB | -80-90% |
| **日志丢失率** | 5-10% | <0.1% | -98%+ |

---

### 3.2 日志级别

```go
// 不同级别的日志
Log.Debug("Debug message", zap.Any("data", data))
Log.Info("Info message")
Log.Warn("Warning message")
Log.Error("Error message", zap.Error(err))
Log.Fatal("Fatal message") // 会退出程序
```

---

### 3.3 日志轮转

```yaml
# docker-compose.yml
services:
  app:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
```

---

## 4. 📊 ELK Stack

### 4.1 Filebeat配置

```yaml
# filebeat.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/myapp/*.log
  json.keys_under_root: true
  json.add_error_key: true

output.elasticsearch:
  hosts: ["elasticsearch:9200"]

setup.kibana:
  host: "kibana:5601"
```

---

### 4.2 完整监控栈

```yaml
# docker-compose.monitoring.yml
version: '3'

services:
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus

  elasticsearch:
    image: elasticsearch:8.10.0
    environment:
      - discovery.type=single-node
    ports:
      - "9200:9200"

  kibana:
    image: kibana:8.10.0
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
```

---

## 5. 💡 最佳实践

### 5.1 监控最佳实践

**Golden Signals（黄金信号）**:

| 信号 | 指标 | 告警阈值 | 说明 |
|------|------|---------|------|
| **Latency（延迟）** | P50, P95, P99 | P99 > 1s | 请求延迟 |
| **Traffic（流量）** | RPS | < 10 req/s (异常) | 请求速率 |
| **Errors（错误）** | 错误率 | > 1% | 错误率 |
| **Saturation（饱和度）** | CPU, Memory | CPU > 80%, Memory > 90% | 资源使用 |

**监控指标设计原则**:

1. **高基数标签**: 避免使用高基数标签（如用户ID），使用低基数标签（如用户类型）
2. **指标命名**: 遵循 Prometheus 命名规范（`metric_name_unit`）
3. **采样率**: 对高频指标进行采样，减少存储压力
4. **保留策略**: 根据指标重要性设置不同的保留时间

### 5.2 日志最佳实践

**日志级别使用指南**:

| 级别 | 使用场景 | 示例 |
|------|---------|------|
| **DEBUG** | 详细调试信息 | 函数调用、变量值 |
| **INFO** | 关键业务事件 | 用户注册、订单创建 |
| **WARN** | 警告信息 | 配置缺失、性能下降 |
| **ERROR** | 错误信息 | 数据库连接失败、API调用失败 |
| **FATAL** | 致命错误 | 应用无法继续运行 |

**日志字段设计**:

```go
// 标准日志字段
logger.Info("User created",
    slog.String("request_id", requestID),      // 请求ID（必须）
    slog.String("user_id", userID),           // 用户ID
    slog.String("action", "create_user"),     // 操作类型
    slog.String("ip", clientIP),              // 客户端IP
    slog.Duration("duration", duration),      // 操作耗时
    slog.Int("status_code", 201),             // HTTP状态码
)
```

**日志采样策略**:

```go
// 对高频日志进行采样
type Sampler struct {
    rate float64 // 采样率（0.0-1.0）
}

func (s *Sampler) ShouldLog(level slog.Level) bool {
    if level >= slog.LevelError {
        return true // 错误日志总是记录
    }
    return rand.Float64() < s.rate
}
```

### 5.3 告警最佳实践

**告警规则设计原则**:

1. **避免告警疲劳**: 设置合理的阈值和持续时间
2. **分级告警**: 根据严重程度设置不同的告警级别
3. **告警聚合**: 对相同类型的告警进行聚合
4. **告警抑制**: 设置告警抑制规则，避免重复告警

**告警路由配置**:

```yaml
# alertmanager.yml
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'
  routes:
    - match:
        severity: critical
      receiver: 'oncall'
    - match:
        severity: warning
      receiver: 'slack'
```

### 5.4 性能优化最佳实践

**监控性能优化**:

1. **指标采样**: 对高频指标进行采样（采样率 10-20%）
2. **指标聚合**: 在应用层进行指标聚合，减少指标数量
3. **存储优化**: 使用 Prometheus 的保留策略和压缩
4. **查询优化**: 使用 Recording Rules 预计算常用查询

**日志性能优化**:

1. **异步写入**: 使用异步日志写入，避免阻塞业务逻辑
2. **批量写入**: 批量写入日志，减少 I/O 操作
3. **日志采样**: 对高频日志进行采样
4. **日志过滤**: 在生产环境过滤 DEBUG 级别日志

**监控和日志性能优化对比**:

| 优化项 | 未优化 | 优化后 | 提升比例 |
|--------|--------|--------|---------|
| **监控开销** | 5-10% CPU | 1-2% CPU | -80% |
| **日志开销** | 3-5% CPU | 0.5-1% CPU | -80-90% |
| **存储成本** | 100% | 20-30% | -70-80% |
| **查询性能** | 100% | 200-300% | +100-200% |

---

## 6. 📚 相关资源
