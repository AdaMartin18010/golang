# 监控与可观测性

**版本**: v1.0
**更新日期**: 2025-11-11
**适用于**: Go 1.25.3

---

## 📋 目录

- [监控与可观测性](#监控与可观测性)
  - [📋 目录](#-目录)
  - [第一部分：可观测性核心理论](#第一部分可观测性核心理论)
    - [可观测性三大支柱](#可观测性三大支柱)
    - [监控 vs 可观测性](#监控-vs-可观测性)
  - [第二部分：Prometheus监控](#第二部分prometheus监控)
    - [实战案例1：Prometheus基础使用](#实战案例1prometheus基础使用)
    - [实战案例2：自定义Collector](#实战案例2自定义collector)
  - [第三部分：Grafana可视化](#第三部分grafana可视化)
    - [实战案例3：Grafana Dashboard配置](#实战案例3grafana-dashboard配置)
  - [第四部分：OpenTelemetry追踪](#第四部分opentelemetry追踪)
    - [实战案例4：分布式追踪](#实战案例4分布式追踪)
  - [第五部分：结构化日志](#第五部分结构化日志)
    - [实战案例5：Zap结构化日志](#实战案例5zap结构化日志)
  - [🎯 总结](#-总结)
    - [可观测性核心要点](#可观测性核心要点)
    - [最佳实践清单](#最佳实践清单)
  - [第六部分：性能优化与最佳实践](#第六部分性能优化与最佳实践)
    - [6.1 性能优化对比](#61-性能优化对比)
    - [6.2 Prometheus 性能优化](#62-prometheus-性能优化)
    - [6.3 OpenTelemetry 性能优化](#63-opentelemetry-性能优化)
    - [6.4 日志性能优化](#64-日志性能优化)
    - [6.5 监控告警最佳实践](#65-监控告警最佳实践)
    - [6.6 性能监控最佳实践](#66-性能监控最佳实践)
    - [6.7 故障排查最佳实践](#67-故障排查最佳实践)
    - [6.8 可观测性最佳实践总结](#68-可观测性最佳实践总结)

---

## 第一部分：可观测性核心理论

### 可观测性三大支柱

```text
┌─────────────────────────────────────────────────┐
│              可观测性三大支柱                     │
└─────────────────────────────────────────────────┘

                Application
                     │
        ┌────────────┼────────────┐
        │            │            │
        ▼            ▼            ▼
    ┌───────┐   ┌───────┐   ┌───────┐
    │Metrics│   │ Traces│   │  Logs │
    │ 指标  │   │ 追踪   │   │ 日志  │
    └───────┘   └───────┘   └───────┘
        │            │            │
        ▼            ▼            ▼

1️⃣ Metrics（指标）
   - 数值型数据（CPU、内存、QPS）
   - 时间序列
   - 聚合统计
   工具：Prometheus、InfluxDB

2️⃣ Traces（追踪）
   - 请求链路
   - 跨服务调用
   - 性能分析
   工具：Jaeger、Zipkin、OpenTelemetry

3️⃣ Logs（日志）
   - 事件记录
   - 错误信息
   - 业务日志
   工具：ELK、Loki、Fluentd

                ↓
    ┌──────────────────────────┐
    │  Observability Platform  │
    │  (可观测性平台)           │
    │  - Grafana               │
    │  - Kibana                │
    │  - Datadog               │
    └──────────────────────────┘
```

---

### 监控 vs 可观测性

```text
监控（Monitoring）:
- 已知问题的检测
- 预定义的指标
- 阈值告警
例如：CPU > 80% → 告警

可观测性（Observability）:
- 未知问题的探索
- 任意维度查询
- 根因分析
例如：为什么第95百分位延迟突然上升？

                监控
                 ↓
    我知道会出现什么问题
    （已知的已知）

            可观测性
                 ↓
    我不知道会出现什么问题
    （已知的未知 + 未知的未知）
```

---

## 第二部分：Prometheus监控

### 实战案例1：Prometheus基础使用

```go
package main

import (
 "net/http"
 "time"

 "github.com/prometheus/client_golang/prometheus"
 "github.com/prometheus/client_golang/prometheus/promauto"
 "github.com/prometheus/client_golang/prometheus/promhttp"
)

// ===== 四种指标类型 =====

// 1. Counter（计数器）- 只增不减
var (
 httpRequestsTotal = promauto.NewCounterVec(
  prometheus.CounterOpts{
   Name: "http_requests_total",
   Help: "Total number of HTTP requests",
  },
  []string{"method", "endpoint", "status"},
 )

 httpRequestErrors = promauto.NewCounter(
  prometheus.CounterOpts{
   Name: "http_request_errors_total",
   Help: "Total number of HTTP request errors",
  },
 )
)

// 2. Gauge（仪表盘）- 可增可减
var (
 activeConnections = promauto.NewGauge(
  prometheus.GaugeOpts{
   Name: "active_connections",
   Help: "Number of active connections",
  },
 )

 cpuUsage = promauto.NewGauge(
  prometheus.GaugeOpts{
   Name: "cpu_usage_percent",
   Help: "Current CPU usage in percent",
  },
 )

 memoryUsage = promauto.NewGaugeVec(
  prometheus.GaugeOpts{
   Name: "memory_usage_bytes",
   Help: "Memory usage in bytes",
  },
  []string{"type"}, // heap, stack, etc.
 )
)

// 3. Histogram（直方图）- 分布统计
var (
 httpRequestDuration = promauto.NewHistogramVec(
  prometheus.HistogramOpts{
   Name:    "http_request_duration_seconds",
   Help:    "HTTP request latency in seconds",
   Buckets: prometheus.DefBuckets, // [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]
  },
  []string{"method", "endpoint"},
 )

 // 自定义buckets
 dbQueryDuration = promauto.NewHistogram(
  prometheus.HistogramOpts{
   Name:    "db_query_duration_seconds",
   Help:    "Database query latency",
   Buckets: []float64{0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2},
  },
 )
)

// 4. Summary（摘要）- 百分位统计
var (
 requestSize = promauto.NewSummaryVec(
  prometheus.SummaryOpts{
   Name:       "http_request_size_bytes",
   Help:       "HTTP request size in bytes",
   Objectives: map[float64]float64{0.5: 0.05, 0.9: 0.01, 0.99: 0.001}, // 分位数
  },
  []string{"method"},
 )
)

// ===== 使用示例 =====

// MetricsMiddleware HTTP中间件
func MetricsMiddleware(next http.Handler) http.Handler {
 return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
  start := time.Now()

  // 增加活跃连接数
  activeConnections.Inc()
  defer activeConnections.Dec()

  // 记录请求大小
  requestSize.WithLabelValues(r.Method).Observe(float64(r.ContentLength))

  // 包装ResponseWriter以捕获状态码
  rw := &responseWriter{ResponseWriter: w, statusCode: 200}

  // 调用下一个处理器
  next.ServeHTTP(rw, r)

  // 记录请求指标
  duration := time.Since(start).Seconds()
  httpRequestDuration.WithLabelValues(r.Method, r.URL.Path).Observe(duration)
  httpRequestsTotal.WithLabelValues(r.Method, r.URL.Path, http.StatusText(rw.statusCode)).Inc()

  // 记录错误
  if rw.statusCode >= 400 {
   httpRequestErrors.Inc()
  }
 })
}

type responseWriter struct {
 http.ResponseWriter
 statusCode int
}

func (rw *responseWriter) WriteHeader(code int) {
 rw.statusCode = code
 rw.ResponseWriter.WriteHeader(code)
}

// ===== 业务指标示例 =====

var (
 // 订单指标
 ordersTotal = promauto.NewCounterVec(
  prometheus.CounterOpts{
   Name: "orders_total",
   Help: "Total number of orders",
  },
  []string{"status"}, // pending, completed, failed
 )

 orderAmount = promauto.NewHistogramVec(
  prometheus.HistogramOpts{
   Name:    "order_amount_dollars",
   Help:    "Order amount in dollars",
   Buckets: []float64{10, 50, 100, 200, 500, 1000, 5000},
  },
  []string{"product_category"},
 )

 // 用户指标
 activeUsers = promauto.NewGauge(
  prometheus.GaugeOpts{
   Name: "active_users",
   Help: "Number of currently active users",
  },
 )

 userRegistrations = promauto.NewCounter(
  prometheus.CounterOpts{
   Name: "user_registrations_total",
   Help: "Total number of user registrations",
  },
 )
)

// RecordOrder 记录订单
func RecordOrder(status string, amount float64, category string) {
 ordersTotal.WithLabelValues(status).Inc()
 orderAmount.WithLabelValues(category).Observe(amount)
}

// UpdateActiveUsers 更新活跃用户数
func UpdateActiveUsers(count int) {
 activeUsers.Set(float64(count))
}

// ===== 主程序 =====

func main() {
 // 注册/metrics端点
 http.Handle("/metrics", promhttp.Handler())

 // 业务路由（带监控中间件）
 mux := http.NewServeMux()
 mux.HandleFunc("/api/users", func(w http.ResponseWriter, r *http.Request) {
  w.Write([]byte("Users API"))
 })
 mux.HandleFunc("/api/orders", func(w http.ResponseWriter, r *http.Request) {
  // 模拟业务逻辑
  RecordOrder("completed", 99.99, "electronics")
  w.Write([]byte("Orders API"))
 })

 // 应用中间件
 handler := MetricsMiddleware(mux)
 http.Handle("/", handler)

 // 启动服务器
 http.ListenAndServe(":8080", nil)
}
```

---

### 实战案例2：自定义Collector

```go
package main

import (
 "log"
 "runtime"
 "time"

 "github.com/prometheus/client_golang/prometheus"
)

// ===== 自定义Collector（高级用法）=====

// SystemStatsCollector 系统统计收集器
type SystemStatsCollector struct {
 goroutines *prometheus.Desc
 threads    *prometheus.Desc
 gcPauses   *prometheus.Desc
 heapAlloc  *prometheus.Desc
 heapSys    *prometheus.Desc
}

// NewSystemStatsCollector 创建收集器
func NewSystemStatsCollector() *SystemStatsCollector {
 return &SystemStatsCollector{
  goroutines: prometheus.NewDesc(
   "go_goroutines_count",
   "Number of goroutines",
   nil, nil,
  ),
  threads: prometheus.NewDesc(
   "go_threads_count",
   "Number of OS threads",
   nil, nil,
  ),
  gcPauses: prometheus.NewDesc(
   "go_gc_pause_seconds",
   "GC pause duration in seconds",
   nil, nil,
  ),
  heapAlloc: prometheus.NewDesc(
   "go_heap_alloc_bytes",
   "Heap allocated bytes",
   nil, nil,
  ),
  heapSys: prometheus.NewDesc(
   "go_heap_sys_bytes",
   "Heap system bytes",
   nil, nil,
  ),
 }
}

// Describe 实现Collector接口
func (c *SystemStatsCollector) Describe(ch Channel<- *prometheus.Desc) {
 ch <- c.goroutines
 ch <- c.threads
 ch <- c.gcPauses
 ch <- c.heapAlloc
 ch <- c.heapSys
}

// Collect 实现Collector接口
func (c *SystemStatsCollector) Collect(ch Channel<- prometheus.Metric) {
 var m runtime.MemStats
 runtime.ReadMemStats(&m)

 ch <- prometheus.MustNewConstMetric(
  c.goroutines,
  prometheus.GaugeValue,
  float64(runtime.NumGoroutine()),
 )

 ch <- prometheus.MustNewConstMetric(
  c.threads,
  prometheus.GaugeValue,
  float64(runtime.GOMAXPROCS(0)),
 )

 ch <- prometheus.MustNewConstMetric(
  c.gcPauses,
  prometheus.GaugeValue,
  float64(m.PauseNs[(m.NumGC+255)%256])/1e9,
 )

 ch <- prometheus.MustNewConstMetric(
  c.heapAlloc,
  prometheus.GaugeValue,
  float64(m.HeapAlloc),
 )

 ch <- prometheus.MustNewConstMetric(
  c.heapSys,
  prometheus.GaugeValue,
  float64(m.HeapSys),
 )
}

// ===== 使用示例 =====

func main() {
 // 注册自定义收集器
 collector := NewSystemStatsCollector()
 prometheus.MustRegister(collector)

 log.Println("Custom collector registered")
}
```

---

## 第三部分：Grafana可视化

### 实战案例3：Grafana Dashboard配置

```json
{
  "dashboard": {
    "title": "Go Application Monitoring",
    "panels": [
      {
        "title": "HTTP Request Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "HTTP Request Duration P95",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "p95"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Error Rate",
        "targets": [
          {
            "expr": "rate(http_request_errors_total[5m])",
            "legendFormat": "errors/s"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Active Connections",
        "targets": [
          {
            "expr": "active_connections"
          }
        ],
        "type": "stat"
      }
    ]
  }
}
```

---

## 第四部分：OpenTelemetry追踪

### 实战案例4：分布式追踪

```go
package main

import (
 "context"
 "log"
 "time"

 "go.opentelemetry.io/otel"
 "go.opentelemetry.io/otel/attribute"
 "go.opentelemetry.io/otel/exporters/jaeger"
 "go.opentelemetry.io/otel/sdk/resource"
 tracesdk "go.opentelemetry.io/otel/sdk/trace"
 semconv "go.opentelemetry.io/otel/semconv/v1.4.0"
 "go.opentelemetry.io/otel/trace"
)

// ===== OpenTelemetry初始化 =====

func InitTracer(serviceName string) (*tracesdk.TracerProvider, error) {
 // 创建Jaeger导出器
 exporter, err := jaeger.New(jaeger.WithCollectorEndpoint(
  jaeger.WithEndpoint("http://localhost:14268/api/traces"),
 ))
 if err != nil {
  return nil, err
 }

 // 创建TracerProvider
 tp := tracesdk.NewTracerProvider(
  tracesdk.WithBatcher(exporter),
  tracesdk.WithResource(resource.NewWithAttributes(
   semconv.SchemaURL,
   semconv.ServiceNameKey.String(serviceName),
  )),
  tracesdk.WithSampler(tracesdk.AlwaysSample()),
 )

 // 设置全局TracerProvider
 otel.SetTracerProvider(tp)

 return tp, nil
}

// ===== 业务代码示例 =====

type OrderService struct {
 tracer trace.Tracer
}

func NewOrderService() *OrderService {
 return &OrderService{
  tracer: otel.Tracer("order-service"),
 }
}

// CreateOrder 创建订单（带追踪）
func (s *OrderService) CreateOrder(ctx Context.Context, userID, productID string, amount float64) (string, error) {
 // 创建Span
 ctx, span := s.tracer.Start(ctx, "CreateOrder",
  trace.WithAttributes(
   attribute.String("user.id", userID),
   attribute.String("product.id", productID),
   attribute.Float64("order.amount", amount),
  ),
 )
 defer span.End()

 // 1. 验证用户
 if err := s.validateUser(ctx, userID); err != nil {
  span.RecordError(err)
  return "", err
 }

 // 2. 检查库存
 if err := s.checkInventory(ctx, productID); err != nil {
  span.RecordError(err)
  return "", err
 }

 // 3. 创建订单
 orderID := s.createOrderInDB(ctx, userID, productID, amount)
 span.SetAttributes(attribute.String("order.id", orderID))

 // 4. 发送通知
 s.sendNotification(ctx, userID, orderID)

 return orderID, nil
}

func (s *OrderService) validateUser(ctx Context.Context, userID string) error {
 ctx, span := s.tracer.Start(ctx, "ValidateUser")
 defer span.End()

 // 模拟验证逻辑
 time.Sleep(50 * time.Millisecond)
 span.SetAttributes(attribute.Bool("user.valid", true))

 return nil
}

func (s *OrderService) checkInventory(ctx Context.Context, productID string) error {
 ctx, span := s.tracer.Start(ctx, "CheckInventory")
 defer span.End()

 // 模拟库存检查
 time.Sleep(100 * time.Millisecond)
 span.SetAttributes(attribute.Int("inventory.count", 10))

 return nil
}

func (s *OrderService) createOrderInDB(ctx Context.Context, userID, productID string, amount float64) string {
 ctx, span := s.tracer.Start(ctx, "CreateOrderInDB")
 defer span.End()

 // 模拟数据库操作
 time.Sleep(200 * time.Millisecond)
 orderID := "order-123"
 span.SetAttributes(attribute.String("db.operation", "INSERT"))

 return orderID
}

func (s *OrderService) sendNotification(ctx Context.Context, userID, orderID string) {
 ctx, span := s.tracer.Start(ctx, "SendNotification")
 defer span.End()

 // 模拟发送通知
 time.Sleep(50 * time.Millisecond)
 span.SetAttributes(attribute.String("notification.type", "email"))
}

// ===== 主程序 =====

func main() {
 // 初始化追踪
 tp, err := InitTracer("order-service")
 if err != nil {
  log.Fatal(err)
 }
 defer func() {
  if err := tp.Shutdown(context.Background()); err != nil {
   log.Printf("Error shutting down tracer provider: %v", err)
  }
 }()

 // 创建服务
 orderService := NewOrderService()

 // 模拟请求
 ctx := context.Background()
 orderID, err := orderService.CreateOrder(ctx, "user-001", "product-123", 99.99)
 if err != nil {
  log.Printf("Create order failed: %v", err)
 } else {
  log.Printf("Order created: %s", orderID)
 }
}
```

---

## 第五部分：结构化日志

### 实战案例5：Zap结构化日志

```go
package main

import (
 "context"
 "fmt"
 "time"

 "go.uber.org/zap"
 "go.uber.org/zap/zapcore"
)

// ===== Zap日志初始化 =====

func InitLogger(env string) (*zap.Logger, error) {
 var config zap.Config

 if env == "production" {
  config = zap.NewProductionConfig()
  config.EncoderConfig.TimeKey = "timestamp"
  config.EncoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder
 } else {
  config = zap.NewDevelopmentConfig()
  config.EncoderConfig.EncodeLevel = zapcore.CapitalColorLevelEncoder
 }

 // 设置日志级别
 config.Level = zap.NewAtomicLevelAt(zap.InfoLevel)

 // 输出到文件和控制台
 config.OutputPaths = []string{"stdout", "app.log"}
 config.ErrorOutputPaths = []string{"stderr", "error.log"}

 logger, err := config.Build(
  zap.AddCaller(),      // 添加调用者信息
  zap.AddStacktrace(zapcore.ErrorLevel), // 错误级别添加堆栈
 )
 if err != nil {
  return nil, err
 }

 return logger, nil
}

// ===== 日志封装 =====

type Logger struct {
 logger *zap.Logger
}

func NewLogger(logger *zap.Logger) *Logger {
 return &Logger{logger: logger}
}

// WithContext 从context提取trace信息
func (l *Logger) WithContext(ctx Context.Context) *zap.Logger {
 // 从context提取trace_id、span_id等
 // 这里简化处理
 return l.logger.With(
  zap.String("request_id", getRequestID(ctx)),
  zap.String("user_id", getUserID(ctx)),
 )
}

func getRequestID(ctx Context.Context) string {
 if id, ok := ctx.Value("request_id").(string); ok {
  return id
 }
 return "unknown"
}

func getUserID(ctx Context.Context) string {
 if id, ok := ctx.Value("user_id").(string); ok {
  return id
 }
 return "anonymous"
}

// ===== 业务日志示例 =====

type UserService struct {
 logger *Logger
}

func NewUserService(logger *Logger) *UserService {
 return &UserService{logger: logger}
}

// Login 用户登录（带结构化日志）
func (s *UserService) Login(ctx Context.Context, username, password string) error {
 logger := s.logger.WithContext(ctx)

 logger.Info("User login attempt",
  zap.String("username", username),
  zap.Time("timestamp", time.Now()),
 )

 // 模拟登录逻辑
 if username == "" {
  logger.Warn("Login failed: empty username",
   zap.String("username", username),
  )
  return fmt.Errorf("empty username")
 }

 // 模拟数据库查询
 time.Sleep(50 * time.Millisecond)

 logger.Info("User login successful",
  zap.String("username", username),
  zap.Duration("duration", 50*time.Millisecond),
 )

 return nil
}

// ProcessOrder 处理订单（带详细日志）
func (s *UserService) ProcessOrder(ctx Context.Context, orderID string, amount float64) error {
 logger := s.logger.WithContext(ctx)

 logger.Info("Processing order",
  zap.String("order_id", orderID),
  zap.Float64("amount", amount),
 )

 // 模拟业务逻辑
 if amount <= 0 {
  logger.Error("Invalid order amount",
   zap.String("order_id", orderID),
   zap.Float64("amount", amount),
   zap.String("error", "amount must be positive"),
  )
  return fmt.Errorf("invalid amount")
 }

 // 模拟处理时间
 start := time.Now()
 time.Sleep(200 * time.Millisecond)
 duration := time.Since(start)

 logger.Info("Order processed successfully",
  zap.String("order_id", orderID),
  zap.Duration("duration", duration),
  zap.String("status", "completed"),
 )

 return nil
}

// ===== 主程序 =====

func main() {
 // 初始化日志
 zapLogger, err := InitLogger("development")
 if err != nil {
  panic(err)
 }
 defer zapLogger.Sync()

 logger := NewLogger(zapLogger)

 // 创建服务
 userService := NewUserService(logger)

 // 模拟请求
 ctx := context.WithValue(context.Background(), "request_id", "req-001")
 ctx = context.WithValue(ctx, "user_id", "user-123")

 // 用户登录
 userService.Login(ctx, "alice", "password123")

 // 处理订单
 userService.ProcessOrder(ctx, "order-001", 99.99)
}
```

---

## 🎯 总结

### 可观测性核心要点

1. **三大支柱** - Metrics/Traces/Logs
2. **Prometheus** - 指标收集、PromQL查询、告警规则
3. **Grafana** - 可视化Dashboard、告警通知
4. **OpenTelemetry** - 分布式追踪、上下文传播
5. **结构化日志** - Zap/Logrus、日志聚合
6. **指标类型** - Counter/Gauge/Histogram/Summary
7. **SLI/SLO/SLA** - 服务质量指标
8. **告警系统** - AlertManager、告警路由
9. **性能分析** - pprof集成、火焰图
10. **故障排查** - 日志关联、追踪分析

### 最佳实践清单

---

## 第六部分：性能优化与最佳实践

### 6.1 性能优化对比

**可观测性工具性能对比**:

| 工具类型 | 内存占用 | CPU占用 | 延迟影响 | 适用场景 |
|---------|---------|---------|---------|---------|
| **Prometheus** | 中等 | 低 | < 1ms | 指标收集，适合高频率指标 |
| **OpenTelemetry** | 低 | 低 | 1-5ms | 分布式追踪，适合请求链路追踪 |
| **Zap日志** | 极低 | 极低 | < 0.1ms | 结构化日志，适合高频日志 |
| **Jaeger** | 高 | 中 | 5-10ms | 追踪存储，适合追踪数据持久化 |

**性能优化效果对比**:

| 优化项 | 未优化 | 优化后 | 提升比例 |
|--------|--------|--------|---------|
| **指标收集延迟** | 5ms | < 1ms | +80% |
| **追踪采样率** | 100% | 10% | +90% |
| **日志写入延迟** | 2ms | < 0.1ms | +95% |
| **内存占用** | 500MB | 200MB | -60% |

### 6.2 Prometheus 性能优化

**指标收集优化**:

```go
// 性能优化的指标收集器
type OptimizedCollector struct {
    mu        sync.RWMutex
    metrics   map[string]float64
    lastUpdate time.Time
    updateInterval time.Duration
}

func NewOptimizedCollector(interval time.Duration) *OptimizedCollector {
    return &OptimizedCollector{
        metrics:        make(map[string]float64),
        updateInterval: interval,
    }
}

// 批量更新指标（减少锁竞争）
func (c *OptimizedCollector) BatchUpdate(updates map[string]float64) {
    c.mu.Lock()
    defer c.mu.Unlock()

    now := time.Now()
    if now.Sub(c.lastUpdate) < c.updateInterval {
        return  // 跳过频繁更新
    }

    for k, v := range updates {
        c.metrics[k] = v
    }
    c.lastUpdate = now
}

// 异步指标收集（不阻塞主流程）
func (c *OptimizedCollector) CollectAsync(ch chan<- prometheus.Metric) {
    go func() {
        c.mu.RLock()
        defer c.mu.RUnlock()

        for name, value := range c.metrics {
            desc := prometheus.NewDesc(
                name,
                "Metric "+name,
                nil, nil,
            )
            ch <- prometheus.MustNewConstMetric(desc, prometheus.GaugeValue, value)
        }
    }()
}
```

**指标采样优化**:

```go
// 采样率控制（减少指标数量）
type SampledCounter struct {
    counter prometheus.Counter
    sampler *rate.Limiter
}

func NewSampledCounter(counter prometheus.Counter, sampleRate float64) *SampledCounter {
    return &SampledCounter{
        counter: counter,
        sampler: rate.NewLimiter(rate.Limit(sampleRate), 1),
    }
}

func (s *SampledCounter) Inc() {
    if s.sampler.Allow() {
        s.counter.Inc()
    }
}
```

### 6.3 OpenTelemetry 性能优化

**追踪采样策略**:

```go
// 智能采样策略（减少追踪开销）
type SmartSampler struct {
    baseRate    float64
    errorRate   float64
    slowRate    float64
    slowThreshold time.Duration
}

func NewSmartSampler(baseRate, errorRate, slowRate float64, slowThreshold time.Duration) *SmartSampler {
    return &SmartSampler{
        baseRate:      baseRate,
        errorRate:     errorRate,
        slowRate:      slowRate,
        slowThreshold: slowThreshold,
    }
}

func (s *SmartSampler) ShouldSample(params tracesdk.SamplingParameters) tracesdk.SamplingResult {
    // 错误请求：高采样率
    if params.Attributes != nil {
        for _, attr := range params.Attributes {
            if attr.Key == "error" && attr.Value.AsBool() {
                return tracesdk.SamplingResult{
                    Decision: tracesdk.RecordAndSample,
                }
            }
        }
    }

    // 慢请求：中等采样率
    if params.Duration > s.slowThreshold {
        if rand.Float64() < s.slowRate {
            return tracesdk.SamplingResult{
                Decision: tracesdk.RecordAndSample,
            }
        }
    }

    // 普通请求：低采样率
    if rand.Float64() < s.baseRate {
        return tracesdk.SamplingResult{
            Decision: tracesdk.RecordAndSample,
        }
    }

    return tracesdk.SamplingResult{
        Decision: tracesdk.Drop,
    }
}

// 使用智能采样
func InitOptimizedTracer(serviceName string) (*tracesdk.TracerProvider, error) {
    sampler := NewSmartSampler(0.1, 1.0, 0.5, 100*time.Millisecond)

    tp := tracesdk.NewTracerProvider(
        tracesdk.WithSampler(sampler),
        // ... 其他配置
    )

    return tp, nil
}
```

**批量导出优化**:

```go
// 批量导出追踪数据（减少网络开销）
func NewBatchExporter(exporter tracesdk.SpanExporter, batchSize int, timeout time.Duration) tracesdk.SpanExporter {
    return &batchExporter{
        exporter:  exporter,
        batchSize: batchSize,
        timeout:   timeout,
        spans:     make([]tracesdk.ReadWriteSpan, 0, batchSize),
        mu:        sync.Mutex{},
    }
}

type batchExporter struct {
    exporter  tracesdk.SpanExporter
    batchSize int
    timeout   time.Duration
    spans     []tracesdk.ReadWriteSpan
    mu        sync.Mutex
}

func (b *batchExporter) ExportSpans(ctx context.Context, spans []tracesdk.ReadWriteSpan) error {
    b.mu.Lock()
    b.spans = append(b.spans, spans...)
    shouldFlush := len(b.spans) >= b.batchSize
    b.mu.Unlock()

    if shouldFlush {
        return b.flush(ctx)
    }

    // 定时刷新
    go func() {
        time.Sleep(b.timeout)
        b.flush(ctx)
    }()

    return nil
}

func (b *batchExporter) flush(ctx context.Context) error {
    b.mu.Lock()
    spans := make([]tracesdk.ReadWriteSpan, len(b.spans))
    copy(spans, b.spans)
    b.spans = b.spans[:0]
    b.mu.Unlock()

    if len(spans) > 0 {
        return b.exporter.ExportSpans(ctx, spans)
    }
    return nil
}
```

### 6.4 日志性能优化

**异步日志写入**:

```go
// 异步日志写入（不阻塞主流程）
type AsyncLogger struct {
    logger *zap.Logger
    queue  chan *LogEntry
    wg     sync.WaitGroup
}

type LogEntry struct {
    level  zapcore.Level
    msg    string
    fields []zap.Field
}

func NewAsyncLogger(logger *zap.Logger, queueSize int) *AsyncLogger {
    al := &AsyncLogger{
        logger: logger,
        queue:  make(chan *LogEntry, queueSize),
    }

    // 启动后台写入goroutine
    al.wg.Add(1)
    go al.writeLoop()

    return al
}

func (al *AsyncLogger) writeLoop() {
    defer al.wg.Done()

    for entry := range al.queue {
        switch entry.level {
        case zapcore.DebugLevel:
            al.logger.Debug(entry.msg, entry.fields...)
        case zapcore.InfoLevel:
            al.logger.Info(entry.msg, entry.fields...)
        case zapcore.WarnLevel:
            al.logger.Warn(entry.msg, entry.fields...)
        case zapcore.ErrorLevel:
            al.logger.Error(entry.msg, entry.fields...)
        }
    }
}

func (al *AsyncLogger) Info(msg string, fields ...zap.Field) {
    select {
    case al.queue <- &LogEntry{level: zapcore.InfoLevel, msg: msg, fields: fields}:
    default:
        // 队列满，丢弃日志或同步写入
        al.logger.Info(msg, fields...)
    }
}

func (al *AsyncLogger) Close() {
    close(al.queue)
    al.wg.Wait()
}
```

**日志采样**:

```go
// 日志采样（减少日志量）
type SampledLogger struct {
    logger    *zap.Logger
    sampler   *rate.Limiter
    errorRate *rate.Limiter
}

func NewSampledLogger(logger *zap.Logger, infoRate, errorRate float64) *SampledLogger {
    return &SampledLogger{
        logger:    logger,
        sampler:   rate.NewLimiter(rate.Limit(infoRate), 1),
        errorRate: rate.NewLimiter(rate.Limit(errorRate), 1),
    }
}

func (sl *SampledLogger) Info(msg string, fields ...zap.Field) {
    if sl.sampler.Allow() {
        sl.logger.Info(msg, fields...)
    }
}

func (sl *SampledLogger) Error(msg string, fields ...zap.Field) {
    if sl.errorRate.Allow() {
        sl.logger.Error(msg, fields...)
    }
}
```

### 6.5 监控告警最佳实践

**告警规则设计**:

```yaml
# Prometheus 告警规则最佳实践
groups:
  - name: application_alerts
    interval: 30s
    rules:
      # 错误率告警
      - alert: HighErrorRate
        expr: rate(http_request_errors_total[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors/second"

      # 延迟告警
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1.0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High latency detected"
          description: "P95 latency is {{ $value }} seconds"

      # 资源使用告警
      - alert: HighMemoryUsage
        expr: go_memstats_heap_inuse_bytes / go_memstats_heap_sys_bytes > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value | humanizePercentage }}"
```

**告警路由配置**:

```yaml
# AlertManager 路由配置
route:
  receiver: 'default'
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h

  routes:
    # 严重告警：立即通知
    - match:
        severity: critical
      receiver: 'critical-alerts'
      continue: true

    # 警告告警：延迟通知
    - match:
        severity: warning
      receiver: 'warning-alerts'
      group_wait: 5m

receivers:
  - name: 'critical-alerts'
    webhook_configs:
      - url: 'http://alert-service/critical'
        send_resolved: true

  - name: 'warning-alerts'
    email_configs:
      - to: 'team@example.com'
        send_resolved: true
```

### 6.6 性能监控最佳实践

**关键指标监控**:

```go
// 关键业务指标监控
var (
    // 黄金信号（Google SRE）
    requestRate = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "request_rate_total",
            Help: "Request rate",
        },
        []string{"method", "endpoint"},
    )

    errorRate = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "error_rate_total",
            Help: "Error rate",
        },
        []string{"method", "endpoint", "error_type"},
    )

    latency = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "request_latency_seconds",
            Help:    "Request latency",
            Buckets: prometheus.DefBuckets,
        },
        []string{"method", "endpoint"},
    )

    saturation = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "resource_saturation",
            Help: "Resource saturation",
        },
        []string{"resource"}, // cpu, memory, connections
    )
)

// 监控中间件
func MonitoringMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()

        rw := &responseWriter{ResponseWriter: w, statusCode: 200}
        next.ServeHTTP(rw, r)

        duration := time.Since(start).Seconds()

        // 记录指标
        requestRate.WithLabelValues(r.Method, r.URL.Path).Inc()
        latency.WithLabelValues(r.Method, r.URL.Path).Observe(duration)

        if rw.statusCode >= 400 {
            errorRate.WithLabelValues(r.Method, r.URL.Path, http.StatusText(rw.statusCode)).Inc()
        }
    })
}
```

### 6.7 故障排查最佳实践

**日志关联**:

```go
// 日志与追踪关联
func LogWithTrace(ctx context.Context, logger *zap.Logger, msg string, fields ...zap.Field) {
    span := trace.SpanFromContext(ctx)
    if span.IsRecording() {
        spanCtx := span.SpanContext()
        fields = append(fields,
            zap.String("trace_id", spanCtx.TraceID().String()),
            zap.String("span_id", spanCtx.SpanID().String()),
        )
    }

    logger.Info(msg, fields...)
}
```

**性能分析集成**:

```go
// pprof 集成
import _ "net/http/pprof"

func init() {
    go func() {
        log.Println(http.ListenAndServe("localhost:6060", nil))
    }()
}

// 性能分析中间件
func ProfilingMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        if r.URL.Path == "/debug/pprof/" {
            pprof.Index(w, r)
            return
        }
        next.ServeHTTP(w, r)
    })
}
```

### 6.8 可观测性最佳实践总结

**核心原则**:

1. **指标设计**:
   - 使用黄金信号（延迟、错误率、吞吐量、饱和度）
   - 指标命名规范（`service_component_metric_unit`）
   - 合理使用标签（避免高基数）

2. **追踪策略**:
   - 使用智能采样（错误和慢请求高采样率）
   - 批量导出追踪数据
   - 合理设置追踪深度

3. **日志管理**:
   - 使用结构化日志
   - 异步日志写入
   - 日志采样和过滤
   - 日志与追踪关联

4. **告警设计**:
   - 告警规则清晰明确
   - 避免告警风暴
   - 告警分级和路由
   - 告警收敛和去重

5. **性能优化**:
   - 减少可观测性开销
   - 使用采样和过滤
   - 批量处理和异步写入
   - 监控可观测性系统本身

6. **故障排查**:
   - 日志、指标、追踪关联
   - 使用分布式追踪定位问题
   - 性能分析工具集成
   - 建立故障排查流程
