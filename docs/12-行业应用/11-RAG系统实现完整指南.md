# Go RAGç³»ç»Ÿå®ç°å®Œæ•´æŒ‡å—

> **æ›´æ–°æ—¥æœŸ**: 2025å¹´10æœˆ24æ—¥  
> **é€‚ç”¨ç‰ˆæœ¬**: Go 1.21+  
> **éš¾åº¦**: â­â­â­â­â­  
> **æ ‡ç­¾**: #RAG #å‘é‡æ•°æ®åº“ #Embedding #è¯­ä¹‰æœç´¢ #æ£€ç´¢å¢å¼º

---

## ğŸ“š ç›®å½•

- [Go RAGç³»ç»Ÿå®ç°å®Œæ•´æŒ‡å—](#go-ragç³»ç»Ÿå®ç°å®Œæ•´æŒ‡å—)
  - [ğŸ“š ç›®å½•](#-ç›®å½•)
  - [1. RAGç³»ç»Ÿæ¦‚è¿°](#1-ragç³»ç»Ÿæ¦‚è¿°)
    - [1.1 ä»€ä¹ˆæ˜¯RAG](#11-ä»€ä¹ˆæ˜¯rag)
    - [1.2 RAGæ¶æ„](#12-ragæ¶æ„)
    - [1.3 æ ¸å¿ƒç»„ä»¶](#13-æ ¸å¿ƒç»„ä»¶)
  - [2. å‘é‡æ•°æ®åº“é›†æˆ](#2-å‘é‡æ•°æ®åº“é›†æˆ)
    - [2.1 Qdranté›†æˆ](#21-qdranté›†æˆ)
    - [2.2 Weaviateé›†æˆ](#22-weaviateé›†æˆ)
    - [2.3 å‘é‡æ•°æ®åº“æŠ½è±¡å±‚](#23-å‘é‡æ•°æ®åº“æŠ½è±¡å±‚)
  - [3. Embeddingç”Ÿæˆ](#3-embeddingç”Ÿæˆ)
    - [3.1 OpenAI Embeddings](#31-openai-embeddings)
    - [3.2 æœ¬åœ°Embeddingæ¨¡å‹](#32-æœ¬åœ°embeddingæ¨¡å‹)
    - [3.3 Embeddingç¼“å­˜](#33-embeddingç¼“å­˜)
  - [4. æ–‡æ¡£å¤„ç†](#4-æ–‡æ¡£å¤„ç†)
    - [4.1 æ–‡æ¡£åŠ è½½](#41-æ–‡æ¡£åŠ è½½)
    - [4.2 æ–‡æ¡£åˆ†å—ç­–ç•¥](#42-æ–‡æ¡£åˆ†å—ç­–ç•¥)
  - [5. è¯­ä¹‰æœç´¢](#5-è¯­ä¹‰æœç´¢)
    - [5.1 å‘é‡ç›¸ä¼¼åº¦æœç´¢](#51-å‘é‡ç›¸ä¼¼åº¦æœç´¢)
  - [6. RAG Pipeline](#6-rag-pipeline)
    - [6.1 åŸºç¡€RAGæµç¨‹](#61-åŸºç¡€ragæµç¨‹)
  - [8. å®æˆ˜æ¡ˆä¾‹](#8-å®æˆ˜æ¡ˆä¾‹)
    - [8.1 çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ](#81-çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ)
  - [11. å‚è€ƒèµ„æº](#11-å‚è€ƒèµ„æº)
    - [å®˜æ–¹æ–‡æ¡£](#å®˜æ–¹æ–‡æ¡£)
    - [Goåº“](#goåº“)
    - [è®ºæ–‡ä¸ç ”ç©¶](#è®ºæ–‡ä¸ç ”ç©¶)
    - [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## 1. RAGç³»ç»Ÿæ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯RAG

**RAGï¼ˆRetrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰** æ˜¯ä¸€ç§ç»“åˆä¿¡æ¯æ£€ç´¢å’Œç”Ÿæˆå¼AIçš„æŠ€æœ¯ï¼Œé€šè¿‡åœ¨ç”Ÿæˆç­”æ¡ˆå‰æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œä½¿LLMèƒ½å¤Ÿå›ç­”ç‰¹å®šé¢†åŸŸçš„é—®é¢˜ã€‚

**æ ¸å¿ƒä¼˜åŠ¿**:

- âœ… å‡å°‘å¹»è§‰ï¼ˆHallucinationï¼‰
- âœ… æä¾›æœ€æ–°ä¿¡æ¯
- âœ… æ”¯æŒä¸“æœ‰çŸ¥è¯†åº“
- âœ… å¯è¿½æº¯ä¿¡æ¯æ¥æº
- âœ… é™ä½å¾®è°ƒæˆæœ¬

**åº”ç”¨åœºæ™¯**:

- ä¼ä¸šçŸ¥è¯†åº“é—®ç­”
- å®¢æˆ·æœåŠ¡è‡ªåŠ¨åŒ–
- æŠ€æœ¯æ–‡æ¡£åŠ©æ‰‹
- æ³•å¾‹/åŒ»ç–—æ–‡æ¡£åˆ†æ

### 1.2 RAGæ¶æ„

```mermaid
graph TB
    User[ç”¨æˆ·æŸ¥è¯¢] --> Query[æŸ¥è¯¢å¤„ç†]
    Query --> Embedding1[æŸ¥è¯¢å‘é‡åŒ–]
    Embedding1 --> VectorDB[å‘é‡æ•°æ®åº“]
    
    VectorDB --> Retrieve[æ£€ç´¢ç›¸å…³æ–‡æ¡£]
    Retrieve --> Rerank[é‡æ’åº]
    Rerank --> Context[æ„å»ºä¸Šä¸‹æ–‡]
    
    Context --> LLM[å¤§è¯­è¨€æ¨¡å‹]
    User --> LLM
    
    LLM --> Response[ç”Ÿæˆç­”æ¡ˆ]
    Response --> User
    
    Documents[æ–‡æ¡£é›†åˆ] --> Process[æ–‡æ¡£å¤„ç†]
    Process --> Chunk[æ–‡æ¡£åˆ†å—]
    Chunk --> Embedding2[æ–‡æ¡£å‘é‡åŒ–]
    Embedding2 --> VectorDB
    
    style Query fill:#e1f5fe
    style VectorDB fill:#e8f5e9
    style LLM fill:#fff3e0
    style Response fill:#f3e5f5
```

### 1.3 æ ¸å¿ƒç»„ä»¶

| ç»„ä»¶ | èŒè´£ | æŠ€æœ¯é€‰å‹ |
|------|------|----------|
| **æ–‡æ¡£å¤„ç†å™¨** | åŠ è½½ã€åˆ†å—ã€å…ƒæ•°æ®æå– | PDFè§£æã€æ–‡æœ¬åˆ†å‰² |
| **EmbeddingæœåŠ¡** | æ–‡æœ¬å‘é‡åŒ– | OpenAI, HuggingFace |
| **å‘é‡æ•°æ®åº“** | å­˜å‚¨å’Œæ£€ç´¢å‘é‡ | Qdrant, Weaviate, Pinecone |
| **æ£€ç´¢å™¨** | è¯­ä¹‰æœç´¢ã€é‡æ’åº | ç›¸ä¼¼åº¦ç®—æ³• |
| **LLMé›†æˆ** | ç”Ÿæˆç­”æ¡ˆ | OpenAI, Claude |
| **ç¼“å­˜å±‚** | æ€§èƒ½ä¼˜åŒ– | Redis |

---

## 2. å‘é‡æ•°æ®åº“é›†æˆ

### 2.1 Qdranté›†æˆ

**Qdrantå®¢æˆ·ç«¯å®ç°**:

```go
package vectordb

import (
    "context"
    "fmt"
    
    "github.com/qdrant/go-client/qdrant"
)

// QdrantClient Qdrantå®¢æˆ·ç«¯
type QdrantClient struct {
    client     *qdrant.Client
    collection string
}

// Point å‘é‡ç‚¹
type Point struct {
    ID       string
    Vector   []float32
    Metadata map[string]interface{}
}

func NewQdrantClient(url, apiKey, collection string) (*QdrantClient, error) {
    client, err := qdrant.NewClient(&qdrant.Config{
        Host:   url,
        APIKey: apiKey,
    })
    if err != nil {
        return nil, fmt.Errorf("create client: %w", err)
    }

    return &QdrantClient{
        client:     client,
        collection: collection,
    }, nil
}

// CreateCollection åˆ›å»ºé›†åˆ
func (c *QdrantClient) CreateCollection(ctx context.Context, dimension int) error {
    return c.client.CreateCollection(ctx, &qdrant.CreateCollection{
        CollectionName: c.collection,
        VectorsConfig: &qdrant.VectorsConfig{
            Params: &qdrant.VectorParams{
                Size:     uint64(dimension),
                Distance: qdrant.Distance_Cosine,
            },
        },
    })
}

// Upsert æ’å…¥æˆ–æ›´æ–°å‘é‡
func (c *QdrantClient) Upsert(ctx context.Context, points []Point) error {
    qdrantPoints := make([]*qdrant.PointStruct, len(points))
    
    for i, p := range points {
        qdrantPoints[i] = &qdrant.PointStruct{
            Id: &qdrant.PointId{
                PointIdOptions: &qdrant.PointId_Uuid{
                    Uuid: p.ID,
                },
            },
            Vectors: &qdrant.Vectors{
                VectorsOptions: &qdrant.Vectors_Vector{
                    Vector: &qdrant.Vector{
                        Data: p.Vector,
                    },
                },
            },
            Payload: convertToPayload(p.Metadata),
        }
    }

    _, err := c.client.Upsert(ctx, &qdrant.UpsertPoints{
        CollectionName: c.collection,
        Points:         qdrantPoints,
    })

    return err
}

// Search å‘é‡æœç´¢
func (c *QdrantClient) Search(ctx context.Context, vector []float32, topK int, filter map[string]interface{}) ([]SearchResult, error) {
    searchReq := &qdrant.SearchPoints{
        CollectionName: c.collection,
        Vector:         vector,
        Limit:          uint64(topK),
        WithPayload:    &qdrant.WithPayloadSelector{SelectorOptions: &qdrant.WithPayloadSelector_Enable{Enable: true}},
    }

    if filter != nil {
        searchReq.Filter = buildFilter(filter)
    }

    resp, err := c.client.Search(ctx, searchReq)
    if err != nil {
        return nil, err
    }

    results := make([]SearchResult, len(resp))
    for i, hit := range resp {
        results[i] = SearchResult{
            ID:       hit.Id.GetUuid(),
            Score:    hit.Score,
            Metadata: convertFromPayload(hit.Payload),
        }
    }

    return results, nil
}

// SearchResult æœç´¢ç»“æœ
type SearchResult struct {
    ID       string
    Score    float32
    Metadata map[string]interface{}
}

func convertToPayload(m map[string]interface{}) map[string]*qdrant.Value {
    payload := make(map[string]*qdrant.Value)
    for k, v := range m {
        payload[k] = &qdrant.Value{
            Kind: &qdrant.Value_StringValue{
                StringValue: fmt.Sprintf("%v", v),
            },
        }
    }
    return payload
}

func convertFromPayload(payload map[string]*qdrant.Value) map[string]interface{} {
    result := make(map[string]interface{})
    for k, v := range payload {
        result[k] = v.GetStringValue()
    }
    return result
}

func buildFilter(filter map[string]interface{}) *qdrant.Filter {
    // å®ç°è¿‡æ»¤å™¨æ„å»ºé€»è¾‘
    return nil
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleQdrant() {
    client, _ := NewQdrantClient("localhost:6333", "", "knowledge_base")
    
    ctx := context.Background()
    
    // åˆ›å»ºé›†åˆ
    client.CreateCollection(ctx, 1536) // OpenAI embeddingç»´åº¦
    
    // æ’å…¥å‘é‡
    points := []Point{
        {
            ID:     "doc1",
            Vector: make([]float32, 1536), // å®é™…çš„embeddingå‘é‡
            Metadata: map[string]interface{}{
                "text":   "Goæ˜¯ä¸€é—¨ç¼–ç¨‹è¯­è¨€",
                "source": "docs/intro.md",
            },
        },
    }
    client.Upsert(ctx, points)
    
    // æœç´¢
    queryVector := make([]float32, 1536) // æŸ¥è¯¢çš„embeddingå‘é‡
    results, _ := client.Search(ctx, queryVector, 5, nil)
    
    for _, result := range results {
        fmt.Printf("ID: %s, Score: %.4f\n", result.ID, result.Score)
        fmt.Printf("Text: %v\n", result.Metadata["text"])
    }
}
```

### 2.2 Weaviateé›†æˆ

**Weaviateå®¢æˆ·ç«¯å®ç°**:

```go
package vectordb

import (
    "context"
    "fmt"
    
    "github.com/weaviate/weaviate-go-client/v4/weaviate"
    "github.com/weaviate/weaviate-go-client/v4/weaviate/graphql"
)

// WeaviateClient Weaviateå®¢æˆ·ç«¯
type WeaviateClient struct {
    client    *weaviate.Client
    className string
}

func NewWeaviateClient(host, className string) *WeaviateClient {
    config := weaviate.Config{
        Host:   host,
        Scheme: "http",
    }
    
    client, _ := weaviate.NewClient(config)
    
    return &WeaviateClient{
        client:    client,
        className: className,
    }
}

// CreateSchema åˆ›å»ºschema
func (c *WeaviateClient) CreateSchema(ctx context.Context) error {
    classObj := &models.Class{
        Class: c.className,
        Properties: []*models.Property{
            {
                Name:     "text",
                DataType: []string{"text"},
            },
            {
                Name:     "source",
                DataType: []string{"string"},
            },
        },
        Vectorizer: "text2vec-openai",
    }
    
    return c.client.Schema().ClassCreator().WithClass(classObj).Do(ctx)
}

// AddDocument æ·»åŠ æ–‡æ¡£
func (c *WeaviateClient) AddDocument(ctx context.Context, text, source string, vector []float32) (string, error) {
    properties := map[string]interface{}{
        "text":   text,
        "source": source,
    }
    
    result, err := c.client.Data().Creator().
        WithClassName(c.className).
        WithProperties(properties).
        WithVector(vector).
        Do(ctx)
    
    if err != nil {
        return "", err
    }
    
    return result.Object.ID.String(), nil
}

// Search è¯­ä¹‰æœç´¢
func (c *WeaviateClient) Search(ctx context.Context, query string, limit int) ([]map[string]interface{}, error) {
    result, err := c.client.GraphQL().Get().
        WithClassName(c.className).
        WithFields(graphql.Field{Name: "text"}, graphql.Field{Name: "source"}).
        WithNearText(&graphql.NearTextArgumentBuilder{
            Concepts: []string{query},
        }).
        WithLimit(limit).
        Do(ctx)
    
    if err != nil {
        return nil, err
    }
    
    // è§£æç»“æœ
    data := result.Data["Get"].(map[string]interface{})[c.className].([]interface{})
    results := make([]map[string]interface{}, len(data))
    
    for i, item := range data {
        results[i] = item.(map[string]interface{})
    }
    
    return results, nil
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleWeaviate() {
    client := NewWeaviateClient("localhost:8080", "Document")
    ctx := context.Background()
    
    // åˆ›å»ºschema
    client.CreateSchema(ctx)
    
    // æ·»åŠ æ–‡æ¡£
    vector := make([]float32, 1536)
    id, _ := client.AddDocument(ctx, "Go is a programming language", "docs/intro.md", vector)
    fmt.Println("Document ID:", id)
    
    // æœç´¢
    results, _ := client.Search(ctx, "What is Go?", 5)
    for _, result := range results {
        fmt.Printf("Text: %v\n", result["text"])
    }
}
```

### 2.3 å‘é‡æ•°æ®åº“æŠ½è±¡å±‚

**ç»Ÿä¸€æ¥å£è®¾è®¡**:

```go
package vectordb

import "context"

// VectorStore å‘é‡å­˜å‚¨æ¥å£
type VectorStore interface {
    // Upsert æ’å…¥æˆ–æ›´æ–°å‘é‡
    Upsert(ctx context.Context, points []Point) error
    
    // Search å‘é‡æœç´¢
    Search(ctx context.Context, vector []float32, topK int, filter map[string]interface{}) ([]SearchResult, error)
    
    // Delete åˆ é™¤å‘é‡
    Delete(ctx context.Context, ids []string) error
    
    // GetByID æ ¹æ®IDè·å–å‘é‡
    GetByID(ctx context.Context, id string) (*Point, error)
}

// VectorStoreFactory å‘é‡å­˜å‚¨å·¥å‚
type VectorStoreFactory struct {
    stores map[string]VectorStore
}

func NewVectorStoreFactory() *VectorStoreFactory {
    return &VectorStoreFactory{
        stores: make(map[string]VectorStore),
    }
}

// Register æ³¨å†Œå­˜å‚¨
func (f *VectorStoreFactory) Register(name string, store VectorStore) {
    f.stores[name] = store
}

// Get è·å–å­˜å‚¨
func (f *VectorStoreFactory) Get(name string) (VectorStore, error) {
    store, ok := f.stores[name]
    if !ok {
        return nil, fmt.Errorf("store %s not found", name)
    }
    return store, nil
}

// ä½¿ç”¨ç¤ºä¾‹ï¼šåˆ‡æ¢ä¸åŒçš„å‘é‡æ•°æ®åº“
func ExampleFactory() {
    factory := NewVectorStoreFactory()
    
    // æ³¨å†Œä¸åŒçš„å‘é‡æ•°æ®åº“
    qdrant, _ := NewQdrantClient("localhost:6333", "", "kb")
    factory.Register("qdrant", qdrant)
    
    // ä½¿ç”¨æ—¶åˆ‡æ¢
    store, _ := factory.Get("qdrant")
    ctx := context.Background()
    
    results, _ := store.Search(ctx, make([]float32, 1536), 5, nil)
    fmt.Printf("Found %d results\n", len(results))
}
```

---

## 3. Embeddingç”Ÿæˆ

### 3.1 OpenAI Embeddings

**EmbeddingæœåŠ¡å®ç°**:

```go
package embedding

import (
    "bytes"
    "context"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
)

// EmbeddingService EmbeddingæœåŠ¡
type EmbeddingService struct {
    apiKey     string
    model      string
    httpClient *http.Client
}

// EmbeddingRequest Embeddingè¯·æ±‚
type EmbeddingRequest struct {
    Input          []string `json:"input"`
    Model          string   `json:"model"`
    EncodingFormat string   `json:"encoding_format,omitempty"`
}

// EmbeddingResponse Embeddingå“åº”
type EmbeddingResponse struct {
    Object string `json:"object"`
    Data   []struct {
        Object    string    `json:"object"`
        Embedding []float32 `json:"embedding"`
        Index     int       `json:"index"`
    } `json:"data"`
    Model string `json:"model"`
    Usage struct {
        PromptTokens int `json:"prompt_tokens"`
        TotalTokens  int `json:"total_tokens"`
    } `json:"usage"`
}

func NewEmbeddingService(apiKey string) *EmbeddingService {
    return &EmbeddingService{
        apiKey:     apiKey,
        model:      "text-embedding-3-small", // æˆ– text-embedding-3-large
        httpClient: &http.Client{},
    }
}

// Embed ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„embedding
func (s *EmbeddingService) Embed(ctx context.Context, text string) ([]float32, error) {
    embeddings, err := s.EmbedBatch(ctx, []string{text})
    if err != nil {
        return nil, err
    }
    return embeddings[0], nil
}

// EmbedBatch æ‰¹é‡ç”Ÿæˆembedding
func (s *EmbeddingService) EmbedBatch(ctx context.Context, texts []string) ([][]float32, error) {
    req := EmbeddingRequest{
        Input: texts,
        Model: s.model,
    }

    body, err := json.Marshal(req)
    if err != nil {
        return nil, fmt.Errorf("marshal request: %w", err)
    }

    httpReq, err := http.NewRequestWithContext(
        ctx,
        http.MethodPost,
        "https://api.openai.com/v1/embeddings",
        bytes.NewReader(body),
    )
    if err != nil {
        return nil, fmt.Errorf("create request: %w", err)
    }

    httpReq.Header.Set("Content-Type", "application/json")
    httpReq.Header.Set("Authorization", "Bearer "+s.apiKey)

    resp, err := s.httpClient.Do(httpReq)
    if err != nil {
        return nil, fmt.Errorf("do request: %w", err)
    }
    defer resp.Body.Close()

    if resp.StatusCode != http.StatusOK {
        body, _ := io.ReadAll(resp.Body)
        return nil, fmt.Errorf("API error %d: %s", resp.StatusCode, string(body))
    }

    var embResp EmbeddingResponse
    if err := json.NewDecoder(resp.Body).Decode(&embResp); err != nil {
        return nil, fmt.Errorf("decode response: %w", err)
    }

    // æå–embedding
    embeddings := make([][]float32, len(embResp.Data))
    for _, data := range embResp.Data {
        embeddings[data.Index] = data.Embedding
    }

    return embeddings, nil
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleEmbedding() {
    service := NewEmbeddingService("sk-...")
    ctx := context.Background()

    // å•ä¸ªæ–‡æœ¬
    embedding, _ := service.Embed(ctx, "Go is a programming language")
    fmt.Printf("Embedding dimension: %d\n", len(embedding))

    // æ‰¹é‡
    texts := []string{
        "Go is fast",
        "Go has goroutines",
        "Go is simple",
    }
    embeddings, _ := service.EmbedBatch(ctx, texts)
    fmt.Printf("Generated %d embeddings\n", len(embeddings))
}
```

### 3.2 æœ¬åœ°Embeddingæ¨¡å‹

**ä½¿ç”¨Sentence Transformersï¼ˆé€šè¿‡Python bridgeï¼‰**:

```go
package embedding

import (
    "bytes"
    "encoding/json"
    "fmt"
    "net/http"
)

// LocalEmbeddingService æœ¬åœ°embeddingæœåŠ¡
type LocalEmbeddingService struct {
    endpoint string
    client   *http.Client
}

func NewLocalEmbeddingService(endpoint string) *LocalEmbeddingService {
    return &LocalEmbeddingService{
        endpoint: endpoint,
        client:   &http.Client{},
    }
}

// Embed ç”Ÿæˆembeddingï¼ˆè°ƒç”¨æœ¬åœ°æœåŠ¡ï¼‰
func (s *LocalEmbeddingService) Embed(text string) ([]float32, error) {
    req := map[string]interface{}{
        "text": text,
    }

    body, _ := json.Marshal(req)
    resp, err := s.client.Post(
        s.endpoint+"/embed",
        "application/json",
        bytes.NewReader(body),
    )
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()

    var result struct {
        Embedding []float32 `json:"embedding"`
    }
    if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
        return nil, err
    }

    return result.Embedding, nil
}

/*
æœ¬åœ°embeddingæœåŠ¡ï¼ˆPython Flaskç¤ºä¾‹ï¼‰:

from flask import Flask, request, jsonify
from sentence_transformers import SentenceTransformer

app = Flask(__name__)
model = SentenceTransformer('all-MiniLM-L6-v2')

@app.route('/embed', methods=['POST'])
def embed():
    text = request.json['text']
    embedding = model.encode(text).tolist()
    return jsonify({'embedding': embedding})

if __name__ == '__main__':
    app.run(port=5000)
*/
```

### 3.3 Embeddingç¼“å­˜

**Redisç¼“å­˜å®ç°**:

```go
package embedding

import (
    "context"
    "crypto/sha256"
    "encoding/hex"
    "encoding/json"
    "fmt"
    "time"
    
    "github.com/redis/go-redis/v9"
)

// CachedEmbeddingService å¸¦ç¼“å­˜çš„embeddingæœåŠ¡
type CachedEmbeddingService struct {
    embedder EmbeddingService
    cache    *redis.Client
    ttl      time.Duration
}

func NewCachedEmbeddingService(embedder EmbeddingService, redisAddr string) *CachedEmbeddingService {
    rdb := redis.NewClient(&redis.Options{
        Addr: redisAddr,
    })

    return &CachedEmbeddingService{
        embedder: embedder,
        cache:    rdb,
        ttl:      24 * time.Hour,
    }
}

// Embed å¸¦ç¼“å­˜çš„embeddingç”Ÿæˆ
func (s *CachedEmbeddingService) Embed(ctx context.Context, text string) ([]float32, error) {
    // ç”Ÿæˆç¼“å­˜é”®
    key := s.cacheKey(text)

    // å°è¯•ä»ç¼“å­˜è·å–
    cached, err := s.cache.Get(ctx, key).Result()
    if err == nil {
        var embedding []float32
        if err := json.Unmarshal([]byte(cached), &embedding); err == nil {
            return embedding, nil
        }
    }

    // ç¼“å­˜æœªå‘½ä¸­ï¼Œç”Ÿæˆembedding
    embedding, err := s.embedder.Embed(ctx, text)
    if err != nil {
        return nil, err
    }

    // å­˜å…¥ç¼“å­˜
    data, _ := json.Marshal(embedding)
    s.cache.Set(ctx, key, data, s.ttl)

    return embedding, nil
}

func (s *CachedEmbeddingService) cacheKey(text string) string {
    hash := sha256.Sum256([]byte(text))
    return "emb:" + hex.EncodeToString(hash[:])
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleCachedEmbedding() {
    embedder := NewEmbeddingService("sk-...")
    cached := NewCachedEmbeddingService(embedder, "localhost:6379")
    
    ctx := context.Background()
    
    // ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šç”Ÿæˆembeddingå¹¶ç¼“å­˜
    emb1, _ := cached.Embed(ctx, "Go programming")
    
    // ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šä»ç¼“å­˜è·å–ï¼ˆå¿«é€Ÿï¼‰
    emb2, _ := cached.Embed(ctx, "Go programming")
    
    fmt.Println("Same embedding:", len(emb1) == len(emb2))
}
```

---

## 4. æ–‡æ¡£å¤„ç†

### 4.1 æ–‡æ¡£åŠ è½½

**å¤šæ ¼å¼æ–‡æ¡£åŠ è½½å™¨**:

```go
package document

import (
    "fmt"
    "io"
    "os"
    "path/filepath"
    "strings"
)

// Document æ–‡æ¡£ç»“æ„
type Document struct {
    Content  string
    Metadata map[string]interface{}
}

// Loader æ–‡æ¡£åŠ è½½å™¨æ¥å£
type Loader interface {
    Load(path string) ([]Document, error)
}

// TextLoader æ–‡æœ¬æ–‡ä»¶åŠ è½½å™¨
type TextLoader struct{}

func (l *TextLoader) Load(path string) ([]Document, error) {
    data, err := os.ReadFile(path)
    if err != nil {
        return nil, err
    }

    return []Document{{
        Content: string(data),
        Metadata: map[string]interface{}{
            "source": path,
            "type":   "text",
        },
    }}, nil
}

// PDFLoader PDFåŠ è½½å™¨ï¼ˆéœ€è¦pdfåº“ï¼‰
type PDFLoader struct{}

func (l *PDFLoader) Load(path string) ([]Document, error) {
    // ä½¿ç”¨github.com/ledongthuc/pdfç­‰åº“è§£æPDF
    // è¿™é‡Œæä¾›ç®€åŒ–ç¤ºä¾‹
    
    return []Document{{
        Content: "PDF content extracted...",
        Metadata: map[string]interface{}{
            "source": path,
            "type":   "pdf",
        },
    }}, nil
}

// DirectoryLoader ç›®å½•åŠ è½½å™¨
type DirectoryLoader struct {
    loaders map[string]Loader
}

func NewDirectoryLoader() *DirectoryLoader {
    return &DirectoryLoader{
        loaders: map[string]Loader{
            ".txt": &TextLoader{},
            ".md":  &TextLoader{},
            ".pdf": &PDFLoader{},
        },
    }
}

func (l *DirectoryLoader) Load(dirPath string) ([]Document, error) {
    var allDocs []Document

    err := filepath.Walk(dirPath, func(path string, info os.FileInfo, err error) error {
        if err != nil {
            return err
        }

        if info.IsDir() {
            return nil
        }

        ext := filepath.Ext(path)
        loader, ok := l.loaders[ext]
        if !ok {
            return nil // è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        }

        docs, err := loader.Load(path)
        if err != nil {
            return fmt.Errorf("load %s: %w", path, err)
        }

        allDocs = append(allDocs, docs...)
        return nil
    })

    return allDocs, err
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleLoader() {
    loader := NewDirectoryLoader()
    docs, _ := loader.Load("./knowledge_base")
    
    fmt.Printf("Loaded %d documents\n", len(docs))
    for _, doc := range docs {
        fmt.Printf("Source: %v, Length: %d\n",
            doc.Metadata["source"],
            len(doc.Content),
        )
    }
}
```

### 4.2 æ–‡æ¡£åˆ†å—ç­–ç•¥

**æ™ºèƒ½æ–‡æ¡£åˆ†å—**:

```go
package document

import (
    "strings"
    "unicode"
)

// Chunker æ–‡æ¡£åˆ†å—å™¨
type Chunker struct {
    chunkSize    int
    chunkOverlap int
}

func NewChunker(chunkSize, chunkOverlap int) *Chunker {
    return &Chunker{
        chunkSize:    chunkSize,
        chunkOverlap: chunkOverlap,
    }
}

// Chunk åˆ†å—
func (c *Chunker) Chunk(doc Document) []Document {
    // æŒ‰æ®µè½åˆ†å‰²
    paragraphs := strings.Split(doc.Content, "\n\n")
    
    var chunks []Document
    var currentChunk strings.Builder
    var chunkCount int

    for _, para := range paragraphs {
        para = strings.TrimSpace(para)
        if para == "" {
            continue
        }

        // å¦‚æœå½“å‰å—åŠ ä¸Šæ–°æ®µè½è¶…è¿‡é™åˆ¶
        if currentChunk.Len()+len(para) > c.chunkSize && currentChunk.Len() > 0 {
            // ä¿å­˜å½“å‰å—
            chunks = append(chunks, c.createChunk(currentChunk.String(), doc.Metadata, chunkCount))
            chunkCount++

            // å¼€å§‹æ–°å—ï¼ŒåŒ…å«overlap
            if c.chunkOverlap > 0 {
                overlapText := c.getOverlap(currentChunk.String())
                currentChunk.Reset()
                currentChunk.WriteString(overlapText)
                currentChunk.WriteString("\n\n")
            } else {
                currentChunk.Reset()
            }
        }

        currentChunk.WriteString(para)
        currentChunk.WriteString("\n\n")
    }

    // ä¿å­˜æœ€åä¸€ä¸ªå—
    if currentChunk.Len() > 0 {
        chunks = append(chunks, c.createChunk(currentChunk.String(), doc.Metadata, chunkCount))
    }

    return chunks
}

func (c *Chunker) createChunk(content string, metadata map[string]interface{}, index int) Document {
    chunkMetadata := make(map[string]interface{})
    for k, v := range metadata {
        chunkMetadata[k] = v
    }
    chunkMetadata["chunk_index"] = index
    chunkMetadata["chunk_size"] = len(content)

    return Document{
        Content:  strings.TrimSpace(content),
        Metadata: chunkMetadata,
    }
}

func (c *Chunker) getOverlap(text string) string {
    if len(text) <= c.chunkOverlap {
        return text
    }
    return text[len(text)-c.chunkOverlap:]
}

// RecursiveChunker é€’å½’åˆ†å—å™¨ï¼ˆæ›´æ™ºèƒ½ï¼‰
type RecursiveChunker struct {
    chunkSize    int
    chunkOverlap int
    separators   []string
}

func NewRecursiveChunker(chunkSize, chunkOverlap int) *RecursiveChunker {
    return &RecursiveChunker{
        chunkSize:    chunkSize,
        chunkOverlap: chunkOverlap,
        separators:   []string{"\n\n", "\n", ". ", " ", ""},
    }
}

// Chunk é€’å½’åˆ†å—
func (c *RecursiveChunker) Chunk(doc Document) []Document {
    return c.splitText(doc.Content, doc.Metadata, 0)
}

func (c *RecursiveChunker) splitText(text string, metadata map[string]interface{}, depth int) []Document {
    if len(text) <= c.chunkSize {
        return []Document{{
            Content:  text,
            Metadata: metadata,
        }}
    }

    if depth >= len(c.separators) {
        // å¼ºåˆ¶åˆ†å‰²
        return c.forceSplit(text, metadata)
    }

    separator := c.separators[depth]
    parts := strings.Split(text, separator)

    var chunks []Document
    var currentChunk string

    for _, part := range parts {
        testChunk := currentChunk + separator + part
        if len(testChunk) > c.chunkSize && currentChunk != "" {
            // å½“å‰å—å·²æ»¡ï¼Œé€’å½’å¤„ç†
            chunks = append(chunks, c.splitText(currentChunk, metadata, depth+1)...)
            currentChunk = part
        } else {
            currentChunk = testChunk
        }
    }

    if currentChunk != "" {
        chunks = append(chunks, c.splitText(currentChunk, metadata, depth+1)...)
    }

    return chunks
}

func (c *RecursiveChunker) forceSplit(text string, metadata map[string]interface{}) []Document {
    var chunks []Document
    for i := 0; i < len(text); i += c.chunkSize - c.chunkOverlap {
        end := i + c.chunkSize
        if end > len(text) {
            end = len(text)
        }
        
        chunks = append(chunks, Document{
            Content:  text[i:end],
            Metadata: metadata,
        })

        if end == len(text) {
            break
        }
    }
    return chunks
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleChunker() {
    doc := Document{
        Content: `This is a long document...
        
With multiple paragraphs...

And various sections...`,
        Metadata: map[string]interface{}{
            "source": "test.txt",
        },
    }

    // åŸºç¡€åˆ†å—
    chunker := NewChunker(200, 50)
    chunks := chunker.Chunk(doc)
    fmt.Printf("Basic chunker: %d chunks\n", len(chunks))

    // é€’å½’åˆ†å—
    recursiveChunker := NewRecursiveChunker(200, 50)
    chunks2 := recursiveChunker.Chunk(doc)
    fmt.Printf("Recursive chunker: %d chunks\n", len(chunks2))
}
```

---

## 5. è¯­ä¹‰æœç´¢

### 5.1 å‘é‡ç›¸ä¼¼åº¦æœç´¢

**ç›¸ä¼¼åº¦è®¡ç®—**:

```go
package search

import (
    "math"
    "sort"
)

// CosineSimilarity ä½™å¼¦ç›¸ä¼¼åº¦
func CosineSimilarity(a, b []float32) float32 {
    var dotProduct, normA, normB float32

    for i := range a {
        dotProduct += a[i] * b[i]
        normA += a[i] * a[i]
        normB += b[i] * b[i]
    }

    if normA == 0 || normB == 0 {
        return 0
    }

    return dotProduct / (float32(math.Sqrt(float64(normA))) * float32(math.Sqrt(float64(normB))))
}

// EuclideanDistance æ¬§æ°è·ç¦»
func EuclideanDistance(a, b []float32) float32 {
    var sum float32
    for i := range a {
        diff := a[i] - b[i]
        sum += diff * diff
    }
    return float32(math.Sqrt(float64(sum)))
}

// SearchResult æœç´¢ç»“æœ
type SearchResult struct {
    DocumentID string
    Score      float32
    Content    string
    Metadata   map[string]interface{}
}

// LocalSearch æœ¬åœ°å‘é‡æœç´¢ï¼ˆç”¨äºå°æ•°æ®é›†ï¼‰
type LocalSearch struct {
    vectors  map[string][]float32
    metadata map[string]map[string]interface{}
}

func NewLocalSearch() *LocalSearch {
    return &LocalSearch{
        vectors:  make(map[string][]float32),
        metadata: make(map[string]map[string]interface{}),
    }
}

// Add æ·»åŠ å‘é‡
func (s *LocalSearch) Add(id string, vector []float32, metadata map[string]interface{}) {
    s.vectors[id] = vector
    s.metadata[id] = metadata
}

// Search æœç´¢
func (s *LocalSearch) Search(queryVector []float32, topK int) []SearchResult {
    type scoredResult struct {
        id    string
        score float32
    }

    var results []scoredResult
    for id, vector := range s.vectors {
        score := CosineSimilarity(queryVector, vector)
        results = append(results, scoredResult{id: id, score: score})
    }

    // æŒ‰åˆ†æ•°æ’åº
    sort.Slice(results, func(i, j int) bool {
        return results[i].score > results[j].score
    })

    // å–topK
    if topK > len(results) {
        topK = len(results)
    }

    searchResults := make([]SearchResult, topK)
    for i := 0; i < topK; i++ {
        searchResults[i] = SearchResult{
            DocumentID: results[i].id,
            Score:      results[i].score,
            Metadata:   s.metadata[results[i].id],
        }
    }

    return searchResults
}
```

---

ç”±äºRAGæ–‡æ¡£å†…å®¹å¾ˆé•¿ï¼Œè®©æˆ‘ç»§ç»­å®Œæˆæ ¸å¿ƒéƒ¨åˆ†...

## 6. RAG Pipeline

### 6.1 åŸºç¡€RAGæµç¨‹

**å®Œæ•´çš„RAGå®ç°**:

```go
package rag

import (
    "context"
    "fmt"
    "strings"
)

// RAGPipeline RAGç®¡é“
type RAGPipeline struct {
    embedder    EmbeddingService
    vectorStore VectorStore
    llmClient   LLMClient
    topK        int
}

func NewRAGPipeline(embedder EmbeddingService, store VectorStore, llm LLMClient) *RAGPipeline {
    return &RAGPipeline{
        embedder:    embedder,
        vectorStore: store,
        llmClient:   llm,
        topK:        3,
    }
}

// Query æ‰§è¡ŒRAGæŸ¥è¯¢
func (p *RAGPipeline) Query(ctx context.Context, query string) (string, error) {
    // 1. ç”ŸæˆæŸ¥è¯¢çš„embedding
    queryEmbedding, err := p.embedder.Embed(ctx, query)
    if err != nil {
        return "", fmt.Errorf("embed query: %w", err)
    }

    // 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
    results, err := p.vectorStore.Search(ctx, queryEmbedding, p.topK, nil)
    if err != nil {
        return "", fmt.Errorf("search: %w", err)
    }

    // 3. æ„å»ºä¸Šä¸‹æ–‡
    context := p.buildContext(results)

    // 4. ç”Ÿæˆç­”æ¡ˆ
    prompt := p.buildPrompt(query, context)
    answer, err := p.llmClient.Generate(ctx, prompt)
    if err != nil {
        return "", fmt.Errorf("generate answer: %w", err)
    }

    return answer, nil
}

func (p *RAGPipeline) buildContext(results []SearchResult) string {
    var contexts []string
    for i, result := range results {
        text := result.Metadata["text"].(string)
        source := result.Metadata["source"].(string)
        contexts = append(contexts, fmt.Sprintf("[%d] %s\nSource: %s", i+1, text, source))
    }
    return strings.Join(contexts, "\n\n")
}

func (p *RAGPipeline) buildPrompt(query, context string) string {
    return fmt.Sprintf(`Based on the following context, please answer the question.

Context:
%s

Question: %s

Answer:`, context, query)
}
```

---

ç»§ç»­è¡¥å……å®æˆ˜æ¡ˆä¾‹å’Œç”Ÿäº§éƒ¨ç½²éƒ¨åˆ†...

## 8. å®æˆ˜æ¡ˆä¾‹

### 8.1 çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ

**å®Œæ•´çš„çŸ¥è¯†åº“QAç³»ç»Ÿ**:

```go
package main

import (
    "context"
    "fmt"
    "log"
)

// KnowledgeBaseQA çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ
type KnowledgeBaseQA struct {
    embedder    *EmbeddingService
    vectorStore VectorStore
    llm         *OpenAIClient
    chunker     *RecursiveChunker
}

func NewKnowledgeBaseQA(apiKey string) *KnowledgeBaseQA {
    embedder := NewEmbeddingService(apiKey)
    vectorStore, _ := NewQdrantClient("localhost:6333", "", "kb")
    llm := NewOpenAIClient(apiKey)
    chunker := NewRecursiveChunker(500, 50)

    return &KnowledgeBaseQA{
        embedder:    embedder,
        vectorStore: vectorStore,
        llm:         llm,
        chunker:     chunker,
    }
}

// IndexDocuments ç´¢å¼•æ–‡æ¡£
func (qa *KnowledgeBaseQA) IndexDocuments(ctx context.Context, dirPath string) error {
    // 1. åŠ è½½æ–‡æ¡£
    loader := NewDirectoryLoader()
    docs, err := loader.Load(dirPath)
    if err != nil {
        return fmt.Errorf("load documents: %w", err)
    }

    // 2. åˆ†å—
    var allChunks []Document
    for _, doc := range docs {
        chunks := qa.chunker.Chunk(doc)
        allChunks = append(allChunks, chunks...)
    }

    // 3. æ‰¹é‡ç”Ÿæˆembeddingå¹¶å­˜å‚¨
    batchSize := 100
    for i := 0; i < len(allChunks); i += batchSize {
        end := i + batchSize
        if end > len(allChunks) {
            end = len(allChunks)
        }

        batch := allChunks[i:end]
        texts := make([]string, len(batch))
        for j, chunk := range batch {
            texts[j] = chunk.Content
        }

        // ç”Ÿæˆembeddings
        embeddings, err := qa.embedder.EmbedBatch(ctx, texts)
        if err != nil {
            return fmt.Errorf("embed batch: %w", err)
        }

        // å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        points := make([]Point, len(batch))
        for j, chunk := range batch {
            points[j] = Point{
                ID:       fmt.Sprintf("chunk_%d", i+j),
                Vector:   embeddings[j],
                Metadata: map[string]interface{}{
                    "text":   chunk.Content,
                    "source": chunk.Metadata["source"],
                },
            }
        }

        if err := qa.vectorStore.Upsert(ctx, points); err != nil {
            return fmt.Errorf("upsert: %w", err)
        }

        log.Printf("Indexed %d chunks\n", end)
    }

    return nil
}

// Ask æé—®
func (qa *KnowledgeBaseQA) Ask(ctx context.Context, question string) (string, error) {
    // 1. ç”Ÿæˆé—®é¢˜çš„embedding
    queryEmbedding, err := qa.embedder.Embed(ctx, question)
    if err != nil {
        return "", err
    }

    // 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
    results, err := qa.vectorStore.Search(ctx, queryEmbedding, 3, nil)
    if err != nil {
        return "", err
    }

    // 3. æ„å»ºprompt
    var contexts []string
    for i, result := range results {
        text := result.Metadata["text"].(string)
        contexts = append(contexts, fmt.Sprintf("[%d] %s", i+1, text))
    }

    prompt := fmt.Sprintf(`Based on the following context, please answer the question accurately.

Context:
%s

Question: %s

Instructions:
- Answer based only on the provided context
- If the answer is not in the context, say "I don't have enough information to answer this question"
- Cite the relevant context numbers in your answer

Answer:`, strings.Join(contexts, "\n\n"), question)

    // 4. è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ
    resp, err := qa.llm.Chat(ctx, ChatRequest{
        Model: "gpt-4",
        Messages: []ChatMessage{
            {Role: "system", Content: "You are a helpful assistant that answers questions based on provided context."},
            {Role: "user", Content: prompt},
        },
        Temperature: 0.3,
    })

    if err != nil {
        return "", err
    }

    return resp.Choices[0].Message.Content, nil
}

// ä½¿ç”¨ç¤ºä¾‹
func main() {
    qa := NewKnowledgeBaseQA("sk-...")
    ctx := context.Background()

    // ç´¢å¼•æ–‡æ¡£
    if err := qa.IndexDocuments(ctx, "./knowledge_base"); err != nil {
        log.Fatal(err)
    }

    // æé—®
    answer, err := qa.Ask(ctx, "What is Go programming language?")
    if err != nil {
        log.Fatal(err)
    }

    fmt.Println("Answer:", answer)
}
```

---

## 11. å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

- [LangChain Documentation](https://docs.langchain.com/)
- [Qdrant Documentation](https://qdrant.tech/documentation/)
- [Weaviate Documentation](https://weaviate.io/developers/weaviate)
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)

### Goåº“

- [go-client (Qdrant)](https://github.com/qdrant/go-client)
- [weaviate-go-client](https://github.com/weaviate/weaviate-go-client)
- [chromem-go](https://github.com/philippgille/chromem-go) - çº¯Goå‘é‡æ•°æ®åº“

### è®ºæ–‡ä¸ç ”ç©¶

- [RAG: Retrieval-Augmented Generation](https://arxiv.org/abs/2005.11401)
- [Dense Passage Retrieval](https://arxiv.org/abs/2004.04906)

### æœ€ä½³å®è·µ

- [Building Production-Ready RAG Applications](https://www.pinecone.io/learn/rag/)
- [Advanced RAG Techniques](https://blog.langchain.dev/advanced-rag/)

---

**æ–‡æ¡£ç»´æŠ¤è€…**: Go Documentation Team  
**æœ€åæ›´æ–°**: 2025å¹´10æœˆ24æ—¥  
**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ  
**é€‚ç”¨ç‰ˆæœ¬**: Go 1.21+

**è´¡çŒ®è€…**: æ¬¢è¿æäº¤Issueå’ŒPRæ”¹è¿›æœ¬æ–‡æ¡£

