# Go LLMåº”ç”¨å¼€å‘å®Œæ•´æŒ‡å—

> **æ›´æ–°æ—¥æœŸ**: 2025å¹´10æœˆ24æ—¥  
> **é€‚ç”¨ç‰ˆæœ¬**: Go 1.21+  
> **éš¾åº¦**: â­â­â­â­â­  
> **æ ‡ç­¾**: #LLM #OpenAI #Anthropic #ChatGPT #Claude #AIåº”ç”¨

---

## ğŸ“š ç›®å½•

- [Go LLMåº”ç”¨å¼€å‘å®Œæ•´æŒ‡å—](#go-llmåº”ç”¨å¼€å‘å®Œæ•´æŒ‡å—)
  - [ğŸ“š ç›®å½•](#-ç›®å½•)
  - [1. LLMåº”ç”¨æ¶æ„](#1-llmåº”ç”¨æ¶æ„)
    - [1.1 å…¸å‹LLMåº”ç”¨æ¶æ„](#11-å…¸å‹llmåº”ç”¨æ¶æ„)
    - [1.2 Goåœ¨LLMåº”ç”¨ä¸­çš„ä¼˜åŠ¿](#12-goåœ¨llmåº”ç”¨ä¸­çš„ä¼˜åŠ¿)
    - [1.3 æ ¸å¿ƒç»„ä»¶](#13-æ ¸å¿ƒç»„ä»¶)
  - [2. LLM APIé›†æˆ](#2-llm-apié›†æˆ)
    - [2.1 OpenAI API](#21-openai-api)
    - [2.2 Anthropic Claude API](#22-anthropic-claude-api)
    - [2.3 ç»Ÿä¸€LLMå®¢æˆ·ç«¯æ¥å£](#23-ç»Ÿä¸€llmå®¢æˆ·ç«¯æ¥å£)
  - [3. Promptå·¥ç¨‹](#3-promptå·¥ç¨‹)
    - [3.1 Promptæ¨¡æ¿ç®¡ç†](#31-promptæ¨¡æ¿ç®¡ç†)
    - [3.2 åŠ¨æ€Promptæ„å»º](#32-åŠ¨æ€promptæ„å»º)
    - [3.3 Few-Shot Learning](#33-few-shot-learning)
    - [3.4 Chain of Thought](#34-chain-of-thought)
  - [4. æµå¼å“åº”å¤„ç†](#4-æµå¼å“åº”å¤„ç†)
    - [4.1 SSEæµå¼è¾“å‡º](#41-sseæµå¼è¾“å‡º)
    - [4.2 WebSocketå®æ—¶é€šä¿¡](#42-websocketå®æ—¶é€šä¿¡)
  - [5. Function Calling](#5-function-calling)
    - [5.1 å‡½æ•°å®šä¹‰](#51-å‡½æ•°å®šä¹‰)
    - [5.2 å‡½æ•°æ‰§è¡Œå™¨](#52-å‡½æ•°æ‰§è¡Œå™¨)
  - [11. å®æˆ˜æ¡ˆä¾‹](#11-å®æˆ˜æ¡ˆä¾‹)
    - [11.1 æ™ºèƒ½èŠå¤©æœºå™¨äºº](#111-æ™ºèƒ½èŠå¤©æœºå™¨äºº)
    - [11.2 æ–‡æ¡£æ‘˜è¦æœåŠ¡](#112-æ–‡æ¡£æ‘˜è¦æœåŠ¡)
  - [12. ç”Ÿäº§éƒ¨ç½²](#12-ç”Ÿäº§éƒ¨ç½²)
    - [12.1 é…ç½®ç®¡ç†](#121-é…ç½®ç®¡ç†)
    - [12.2 ç›‘æ§ä¸æ—¥å¿—](#122-ç›‘æ§ä¸æ—¥å¿—)
    - [12.3 å®‰å…¨æœ€ä½³å®è·µ](#123-å®‰å…¨æœ€ä½³å®è·µ)
  - [13. å‚è€ƒèµ„æº](#13-å‚è€ƒèµ„æº)
    - [å®˜æ–¹æ–‡æ¡£](#å®˜æ–¹æ–‡æ¡£)
    - [Goåº“](#goåº“)
    - [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## 1. LLMåº”ç”¨æ¶æ„

### 1.1 å…¸å‹LLMåº”ç”¨æ¶æ„

```mermaid
graph TB
    Client[å®¢æˆ·ç«¯] --> API[APIç½‘å…³]
    API --> Auth[è®¤è¯/æˆæƒ]
    Auth --> RateLimit[é™æµå™¨]
    RateLimit --> Router[è·¯ç”±å™¨]
    
    Router --> Chat[èŠå¤©æœåŠ¡]
    Router --> Completion[è¡¥å…¨æœåŠ¡]
    Router --> Embedding[å‘é‡åŒ–æœåŠ¡]
    
    Chat --> PromptEngine[Promptå¼•æ“]
    Completion --> PromptEngine
    
    PromptEngine --> Cache[ç¼“å­˜å±‚]
    Cache --> LLMClient[LLMå®¢æˆ·ç«¯]
    
    LLMClient --> OpenAI[OpenAI API]
    LLMClient --> Claude[Claude API]
    LLMClient --> Custom[è‡ªæ‰˜ç®¡æ¨¡å‹]
    
    Chat --> VectorDB[å‘é‡æ•°æ®åº“]
    Embedding --> VectorDB
    
    style API fill:#e1f5fe
    style Chat fill:#fff3e0
    style LLMClient fill:#e8f5e9
    style VectorDB fill:#f3e5f5
```

### 1.2 Goåœ¨LLMåº”ç”¨ä¸­çš„ä¼˜åŠ¿

**æ€§èƒ½ä¼˜åŠ¿**:

- âœ… é«˜å¹¶å‘å¤„ç†ï¼ˆgoroutineï¼‰
- âœ… ä½å»¶è¿Ÿå“åº”
- âœ… é«˜æ•ˆçš„å†…å­˜ç®¡ç†
- âœ… åŸç”ŸHTTP/2æ”¯æŒ

**å·¥ç¨‹ä¼˜åŠ¿**:

- âœ… ç®€å•çš„éƒ¨ç½²ï¼ˆå•ä¸€äºŒè¿›åˆ¶ï¼‰
- âœ… ä¼˜ç§€çš„å¹¶å‘åŸè¯­
- âœ… å¼ºç±»å‹ç³»ç»Ÿ
- âœ… ä¸°å¯Œçš„æ ‡å‡†åº“

**é€‚ç”¨åœºæ™¯**:

- LLM APIç½‘å…³
- é«˜å¹¶å‘èŠå¤©æœåŠ¡
- å®æ—¶æµå¼å“åº”
- å¾®æœåŠ¡æ¶æ„

### 1.3 æ ¸å¿ƒç»„ä»¶

| ç»„ä»¶ | èŒè´£ | å…³é”®æŠ€æœ¯ |
|------|------|----------|
| **LLMå®¢æˆ·ç«¯** | APIè°ƒç”¨ã€é‡è¯•ã€æµå¼å¤„ç† | HTTP Client, SSE |
| **Promptå¼•æ“** | æ¨¡æ¿ç®¡ç†ã€åŠ¨æ€æ„å»º | text/template |
| **ç¼“å­˜å±‚** | å“åº”ç¼“å­˜ã€æˆæœ¬ä¼˜åŒ– | Redis, å†…å­˜ç¼“å­˜ |
| **å‘é‡å­˜å‚¨** | Embeddingså­˜å‚¨ã€è¯­ä¹‰æœç´¢ | Qdrant, Weaviate |
| **ç›‘æ§ç³»ç»Ÿ** | æ€§èƒ½ç›‘æ§ã€æˆæœ¬è¿½è¸ª | Prometheus, Grafana |

---

## 2. LLM APIé›†æˆ

### 2.1 OpenAI API

**å®Œæ•´çš„OpenAIå®¢æˆ·ç«¯å®ç°**:

```go
package llm

import (
    "bytes"
    "context"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
    "time"
)

// OpenAIClient OpenAIå®¢æˆ·ç«¯
type OpenAIClient struct {
    apiKey     string
    baseURL    string
    httpClient *http.Client
}

// ChatMessage èŠå¤©æ¶ˆæ¯
type ChatMessage struct {
    Role    string `json:"role"`    // system, user, assistant
    Content string `json:"content"`
}

// ChatRequest èŠå¤©è¯·æ±‚
type ChatRequest struct {
    Model       string        `json:"model"`
    Messages    []ChatMessage `json:"messages"`
    Temperature float64       `json:"temperature,omitempty"`
    MaxTokens   int           `json:"max_tokens,omitempty"`
    Stream      bool          `json:"stream,omitempty"`
}

// ChatResponse èŠå¤©å“åº”
type ChatResponse struct {
    ID      string `json:"id"`
    Object  string `json:"object"`
    Created int64  `json:"created"`
    Model   string `json:"model"`
    Choices []struct {
        Index   int         `json:"index"`
        Message ChatMessage `json:"message"`
        Finish  string      `json:"finish_reason"`
    } `json:"choices"`
    Usage struct {
        PromptTokens     int `json:"prompt_tokens"`
        CompletionTokens int `json:"completion_tokens"`
        TotalTokens      int `json:"total_tokens"`
    } `json:"usage"`
}

func NewOpenAIClient(apiKey string) *OpenAIClient {
    return &OpenAIClient{
        apiKey:  apiKey,
        baseURL: "https://api.openai.com/v1",
        httpClient: &http.Client{
            Timeout: 60 * time.Second,
        },
    }
}

// Chat å‘é€èŠå¤©è¯·æ±‚
func (c *OpenAIClient) Chat(ctx context.Context, req ChatRequest) (*ChatResponse, error) {
    // æ„å»ºè¯·æ±‚ä½“
    body, err := json.Marshal(req)
    if err != nil {
        return nil, fmt.Errorf("marshal request: %w", err)
    }

    // åˆ›å»ºHTTPè¯·æ±‚
    httpReq, err := http.NewRequestWithContext(
        ctx,
        http.MethodPost,
        c.baseURL+"/chat/completions",
        bytes.NewReader(body),
    )
    if err != nil {
        return nil, fmt.Errorf("create request: %w", err)
    }

    // è®¾ç½®headers
    httpReq.Header.Set("Content-Type", "application/json")
    httpReq.Header.Set("Authorization", "Bearer "+c.apiKey)

    // å‘é€è¯·æ±‚
    resp, err := c.httpClient.Do(httpReq)
    if err != nil {
        return nil, fmt.Errorf("do request: %w", err)
    }
    defer resp.Body.Close()

    // æ£€æŸ¥çŠ¶æ€ç 
    if resp.StatusCode != http.StatusOK {
        body, _ := io.ReadAll(resp.Body)
        return nil, fmt.Errorf("API error %d: %s", resp.StatusCode, string(body))
    }

    // è§£æå“åº”
    var chatResp ChatResponse
    if err := json.NewDecoder(resp.Body).Decode(&chatResp); err != nil {
        return nil, fmt.Errorf("decode response: %w", err)
    }

    return &chatResp, nil
}

// ChatStream æµå¼èŠå¤©
func (c *OpenAIClient) ChatStream(
    ctx context.Context,
    req ChatRequest,
    callback func(chunk string) error,
) error {
    req.Stream = true

    body, err := json.Marshal(req)
    if err != nil {
        return fmt.Errorf("marshal request: %w", err)
    }

    httpReq, err := http.NewRequestWithContext(
        ctx,
        http.MethodPost,
        c.baseURL+"/chat/completions",
        bytes.NewReader(body),
    )
    if err != nil {
        return fmt.Errorf("create request: %w", err)
    }

    httpReq.Header.Set("Content-Type", "application/json")
    httpReq.Header.Set("Authorization", "Bearer "+c.apiKey)
    httpReq.Header.Set("Accept", "text/event-stream")

    resp, err := c.httpClient.Do(httpReq)
    if err != nil {
        return fmt.Errorf("do request: %w", err)
    }
    defer resp.Body.Close()

    if resp.StatusCode != http.StatusOK {
        body, _ := io.ReadAll(resp.Body)
        return fmt.Errorf("API error %d: %s", resp.StatusCode, string(body))
    }

    // è¯»å–SSEæµ
    reader := bufio.NewReader(resp.Body)
    for {
        line, err := reader.ReadBytes('\n')
        if err != nil {
            if err == io.EOF {
                break
            }
            return err
        }

        // è§£æSSEæ•°æ®
        if bytes.HasPrefix(line, []byte("data: ")) {
            data := bytes.TrimPrefix(line, []byte("data: "))
            data = bytes.TrimSpace(data)

            if string(data) == "[DONE]" {
                break
            }

            var chunk struct {
                Choices []struct {
                    Delta struct {
                        Content string `json:"content"`
                    } `json:"delta"`
                } `json:"choices"`
            }

            if err := json.Unmarshal(data, &chunk); err != nil {
                continue
            }

            if len(chunk.Choices) > 0 && chunk.Choices[0].Delta.Content != "" {
                if err := callback(chunk.Choices[0].Delta.Content); err != nil {
                    return err
                }
            }
        }
    }

    return nil
}

// ä½¿ç”¨ç¤ºä¾‹
func Example() {
    client := NewOpenAIClient("sk-...")

    // 1. æ™®é€šèŠå¤©
    resp, err := client.Chat(context.Background(), ChatRequest{
        Model: "gpt-4",
        Messages: []ChatMessage{
            {Role: "system", Content: "You are a helpful assistant."},
            {Role: "user", Content: "Hello, how are you?"},
        },
        Temperature: 0.7,
        MaxTokens:   1000,
    })
    if err != nil {
        panic(err)
    }

    fmt.Println(resp.Choices[0].Message.Content)
    fmt.Printf("Tokens used: %d\n", resp.Usage.TotalTokens)

    // 2. æµå¼èŠå¤©
    err = client.ChatStream(context.Background(), ChatRequest{
        Model: "gpt-4",
        Messages: []ChatMessage{
            {Role: "user", Content: "Write a short poem about Go"},
        },
    }, func(chunk string) error {
        fmt.Print(chunk)
        return nil
    })
    if err != nil {
        panic(err)
    }
}
```

### 2.2 Anthropic Claude API

**Claudeå®¢æˆ·ç«¯å®ç°**:

```go
package llm

import (
    "bytes"
    "context"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
    "time"
)

// ClaudeClient Anthropic Claudeå®¢æˆ·ç«¯
type ClaudeClient struct {
    apiKey     string
    baseURL    string
    httpClient *http.Client
}

// ClaudeMessage Claudeæ¶ˆæ¯æ ¼å¼
type ClaudeMessage struct {
    Role    string `json:"role"`    // user, assistant
    Content string `json:"content"`
}

// ClaudeRequest Claudeè¯·æ±‚
type ClaudeRequest struct {
    Model     string          `json:"model"`
    Messages  []ClaudeMessage `json:"messages"`
    MaxTokens int             `json:"max_tokens"`
    System    string          `json:"system,omitempty"`
    Stream    bool            `json:"stream,omitempty"`
}

// ClaudeResponse Claudeå“åº”
type ClaudeResponse struct {
    ID      string `json:"id"`
    Type    string `json:"type"`
    Role    string `json:"role"`
    Content []struct {
        Type string `json:"type"`
        Text string `json:"text"`
    } `json:"content"`
    Model        string `json:"model"`
    StopReason   string `json:"stop_reason"`
    StopSequence string `json:"stop_sequence"`
    Usage        struct {
        InputTokens  int `json:"input_tokens"`
        OutputTokens int `json:"output_tokens"`
    } `json:"usage"`
}

func NewClaudeClient(apiKey string) *ClaudeClient {
    return &ClaudeClient{
        apiKey:  apiKey,
        baseURL: "https://api.anthropic.com/v1",
        httpClient: &http.Client{
            Timeout: 60 * time.Second,
        },
    }
}

// Chat å‘é€æ¶ˆæ¯ç»™Claude
func (c *ClaudeClient) Chat(ctx context.Context, req ClaudeRequest) (*ClaudeResponse, error) {
    body, err := json.Marshal(req)
    if err != nil {
        return nil, fmt.Errorf("marshal request: %w", err)
    }

    httpReq, err := http.NewRequestWithContext(
        ctx,
        http.MethodPost,
        c.baseURL+"/messages",
        bytes.NewReader(body),
    )
    if err != nil {
        return nil, fmt.Errorf("create request: %w", err)
    }

    // Claudeç‰¹å®šçš„headers
    httpReq.Header.Set("Content-Type", "application/json")
    httpReq.Header.Set("x-api-key", c.apiKey)
    httpReq.Header.Set("anthropic-version", "2023-06-01")

    resp, err := c.httpClient.Do(httpReq)
    if err != nil {
        return nil, fmt.Errorf("do request: %w", err)
    }
    defer resp.Body.Close()

    if resp.StatusCode != http.StatusOK {
        body, _ := io.ReadAll(resp.Body)
        return nil, fmt.Errorf("API error %d: %s", resp.StatusCode, string(body))
    }

    var claudeResp ClaudeResponse
    if err := json.NewDecoder(resp.Body).Decode(&claudeResp); err != nil {
        return nil, fmt.Errorf("decode response: %w", err)
    }

    return &claudeResp, nil
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleClaude() {
    client := NewClaudeClient("sk-ant-...")

    resp, err := client.Chat(context.Background(), ClaudeRequest{
        Model: "claude-3-sonnet-20240229",
        Messages: []ClaudeMessage{
            {Role: "user", Content: "Hello, Claude!"},
        },
        MaxTokens: 1000,
        System:    "You are a helpful assistant.",
    })
    if err != nil {
        panic(err)
    }

    if len(resp.Content) > 0 {
        fmt.Println(resp.Content[0].Text)
    }
    fmt.Printf("Tokens: Input=%d, Output=%d\n",
        resp.Usage.InputTokens,
        resp.Usage.OutputTokens,
    )
}
```

### 2.3 ç»Ÿä¸€LLMå®¢æˆ·ç«¯æ¥å£

**æŠ½è±¡æ¥å£è®¾è®¡**:

```go
package llm

import "context"

// LLMProvider LLMæä¾›å•†æ¥å£
type LLMProvider interface {
    // Chat å‘é€èŠå¤©è¯·æ±‚
    Chat(ctx context.Context, req ChatRequest) (*ChatResponse, error)
    
    // ChatStream æµå¼èŠå¤©
    ChatStream(ctx context.Context, req ChatRequest, callback func(string) error) error
    
    // Name æä¾›å•†åç§°
    Name() string
}

// UnifiedClient ç»Ÿä¸€çš„LLMå®¢æˆ·ç«¯
type UnifiedClient struct {
    providers map[string]LLMProvider
    default   string
}

func NewUnifiedClient() *UnifiedClient {
    return &UnifiedClient{
        providers: make(map[string]LLMProvider),
    }
}

// RegisterProvider æ³¨å†Œæä¾›å•†
func (c *UnifiedClient) RegisterProvider(name string, provider LLMProvider) {
    c.providers[name] = provider
    if c.default == "" {
        c.default = name
    }
}

// SetDefault è®¾ç½®é»˜è®¤æä¾›å•†
func (c *UnifiedClient) SetDefault(name string) {
    c.default = name
}

// Chat ä½¿ç”¨æŒ‡å®šæˆ–é»˜è®¤æä¾›å•†
func (c *UnifiedClient) Chat(ctx context.Context, provider string, req ChatRequest) (*ChatResponse, error) {
    if provider == "" {
        provider = c.default
    }

    p, ok := c.providers[provider]
    if !ok {
        return nil, fmt.Errorf("provider %s not found", provider)
    }

    return p.Chat(ctx, req)
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleUnified() {
    client := NewUnifiedClient()

    // æ³¨å†Œå¤šä¸ªæä¾›å•†
    client.RegisterProvider("openai", NewOpenAIClient("sk-..."))
    client.RegisterProvider("claude", NewClaudeClient("sk-ant-..."))

    client.SetDefault("openai")

    // ä½¿ç”¨é»˜è®¤æä¾›å•†ï¼ˆOpenAIï¼‰
    resp1, _ := client.Chat(context.Background(), "", ChatRequest{
        Model: "gpt-4",
        Messages: []ChatMessage{
            {Role: "user", Content: "Hello"},
        },
    })

    // ä½¿ç”¨Claude
    resp2, _ := client.Chat(context.Background(), "claude", ChatRequest{
        Model: "claude-3-sonnet-20240229",
        Messages: []ChatMessage{
            {Role: "user", Content: "Hello"},
        },
    })
}
```

---

## 3. Promptå·¥ç¨‹

### 3.1 Promptæ¨¡æ¿ç®¡ç†

**æ¨¡æ¿ç³»ç»Ÿå®ç°**:

```go
package prompt

import (
    "bytes"
    "fmt"
    "text/template"
)

// Template Promptæ¨¡æ¿
type Template struct {
    name string
    tmpl *template.Template
}

// TemplateManager æ¨¡æ¿ç®¡ç†å™¨
type TemplateManager struct {
    templates map[string]*Template
}

func NewTemplateManager() *TemplateManager {
    return &TemplateManager{
        templates: make(map[string]*Template),
    }
}

// Register æ³¨å†Œæ¨¡æ¿
func (m *TemplateManager) Register(name, content string) error {
    tmpl, err := template.New(name).Parse(content)
    if err != nil {
        return fmt.Errorf("parse template: %w", err)
    }

    m.templates[name] = &Template{
        name: name,
        tmpl: tmpl,
    }
    return nil
}

// Render æ¸²æŸ“æ¨¡æ¿
func (m *TemplateManager) Render(name string, data interface{}) (string, error) {
    tmpl, ok := m.templates[name]
    if !ok {
        return "", fmt.Errorf("template %s not found", name)
    }

    var buf bytes.Buffer
    if err := tmpl.tmpl.Execute(&buf, data); err != nil {
        return "", fmt.Errorf("execute template: %w", err)
    }

    return buf.String(), nil
}

// é¢„å®šä¹‰æ¨¡æ¿
func SetupDefaultTemplates(m *TemplateManager) {
    // æ‘˜è¦æ¨¡æ¿
    m.Register("summarize", `
Please summarize the following text concisely:

Text: {{.Text}}

Provide a summary in {{.MaxSentences}} sentences or less.
`)

    // ç¿»è¯‘æ¨¡æ¿
    m.Register("translate", `
Translate the following text from {{.SourceLang}} to {{.TargetLang}}:

{{.Text}}
`)

    // ä»£ç è§£é‡Šæ¨¡æ¿
    m.Register("explain_code", `
Explain the following {{.Language}} code in simple terms:

` + "```{{.Language}}\n{{.Code}}\n```" + `

Include:
1. What the code does
2. Key concepts used
3. Potential issues or improvements
`)

    // é—®ç­”æ¨¡æ¿
    m.Register("qa", `
Context: {{.Context}}

Question: {{.Question}}

Please provide a detailed answer based on the context provided.
`)
}

// ä½¿ç”¨ç¤ºä¾‹
func Example() {
    manager := NewTemplateManager()
    SetupDefaultTemplates(manager)

    // æ¸²æŸ“æ‘˜è¦æ¨¡æ¿
    prompt, _ := manager.Render("summarize", map[string]interface{}{
        "Text":         "Long article text...",
        "MaxSentences": 3,
    })

    // æ¸²æŸ“ç¿»è¯‘æ¨¡æ¿
    prompt, _ = manager.Render("translate", map[string]interface{}{
        "SourceLang": "English",
        "TargetLang": "Chinese",
        "Text":       "Hello, world!",
    })

    // æ¸²æŸ“ä»£ç è§£é‡Šæ¨¡æ¿
    prompt, _ = manager.Render("explain_code", map[string]interface{}{
        "Language": "Go",
        "Code": `func fibonacci(n int) int {
    if n <= 1 {
        return n
    }
    return fibonacci(n-1) + fibonacci(n-2)
}`,
    })
}
```

### 3.2 åŠ¨æ€Promptæ„å»º

**æ„å»ºå™¨æ¨¡å¼**:

```go
package prompt

import (
    "fmt"
    "strings"
)

// Builder Promptæ„å»ºå™¨
type Builder struct {
    parts []string
}

func NewBuilder() *Builder {
    return &Builder{
        parts: make([]string, 0),
    }
}

// AddSystem æ·»åŠ ç³»ç»Ÿæç¤º
func (b *Builder) AddSystem(content string) *Builder {
    b.parts = append(b.parts, fmt.Sprintf("[System]\n%s\n", content))
    return b
}

// AddContext æ·»åŠ ä¸Šä¸‹æ–‡
func (b *Builder) AddContext(context string) *Builder {
    b.parts = append(b.parts, fmt.Sprintf("[Context]\n%s\n", context))
    return b
}

// AddExamples æ·»åŠ ç¤ºä¾‹
func (b *Builder) AddExamples(examples []Example) *Builder {
    if len(examples) == 0 {
        return b
    }

    b.parts = append(b.parts, "[Examples]")
    for i, ex := range examples {
        b.parts = append(b.parts, fmt.Sprintf("\nExample %d:", i+1))
        b.parts = append(b.parts, fmt.Sprintf("Input: %s", ex.Input))
        b.parts = append(b.parts, fmt.Sprintf("Output: %s\n", ex.Output))
    }
    return b
}

// AddInstruction æ·»åŠ æŒ‡ä»¤
func (b *Builder) AddInstruction(instruction string) *Builder {
    b.parts = append(b.parts, fmt.Sprintf("[Instruction]\n%s\n", instruction))
    return b
}

// AddQuery æ·»åŠ æŸ¥è¯¢
func (b *Builder) AddQuery(query string) *Builder {
    b.parts = append(b.parts, fmt.Sprintf("[Query]\n%s", query))
    return b
}

// Build æ„å»ºæœ€ç»ˆprompt
func (b *Builder) Build() string {
    return strings.Join(b.parts, "\n")
}

type Example struct {
    Input  string
    Output string
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleBuilder() {
    prompt := NewBuilder().
        AddSystem("You are a helpful coding assistant.").
        AddContext("The user is learning Go programming.").
        AddExamples([]Example{
            {
                Input:  "How to create a slice?",
                Output: "Use make([]Type, length, capacity) or []Type{values...}",
            },
            {
                Input:  "How to iterate a map?",
                Output: "Use for key, value := range myMap { ... }",
            },
        }).
        AddInstruction("Provide clear, concise answers with code examples.").
        AddQuery("How do I handle errors in Go?").
        Build()

    fmt.Println(prompt)
}
```

### 3.3 Few-Shot Learning

**Few-Shotç¤ºä¾‹ç®¡ç†**:

```go
package prompt

// FewShotManager Few-Shotç¤ºä¾‹ç®¡ç†å™¨
type FewShotManager struct {
    examples []Example
    maxExamples int
}

func NewFewShotManager(maxExamples int) *FewShotManager {
    return &FewShotManager{
        examples:    make([]Example, 0),
        maxExamples: maxExamples,
    }
}

// AddExample æ·»åŠ ç¤ºä¾‹
func (m *FewShotManager) AddExample(input, output string) {
    m.examples = append(m.examples, Example{
        Input:  input,
        Output: output,
    })

    // ä¿æŒæœ€å¤§æ•°é‡
    if len(m.examples) > m.maxExamples {
        m.examples = m.examples[len(m.examples)-m.maxExamples:]
    }
}

// GetExamples è·å–ç¤ºä¾‹
func (m *FewShotManager) GetExamples() []Example {
    return m.examples
}

// BuildPrompt æ„å»ºFew-Shot prompt
func (m *FewShotManager) BuildPrompt(task, query string) string {
    builder := NewBuilder().
        AddSystem(fmt.Sprintf("Task: %s", task))

    if len(m.examples) > 0 {
        builder.AddExamples(m.examples)
    }

    return builder.AddQuery(query).Build()
}

// ä½¿ç”¨ç¤ºä¾‹ï¼šæƒ…æ„Ÿåˆ†ç±»
func ExampleFewShot() {
    manager := NewFewShotManager(5)

    // æ·»åŠ ç¤ºä¾‹
    manager.AddExample(
        "The product is amazing! Best purchase ever.",
        "Positive",
    )
    manager.AddExample(
        "Terrible quality, broke after one use.",
        "Negative",
    )
    manager.AddExample(
        "It's okay, nothing special.",
        "Neutral",
    )

    // æ„å»ºprompt
    prompt := manager.BuildPrompt(
        "Sentiment Classification",
        "This is exactly what I needed!",
    )

    fmt.Println(prompt)
}
```

### 3.4 Chain of Thought

**CoTå®ç°**:

```go
package prompt

// CoTBuilder Chain of Thoughtæ„å»ºå™¨
type CoTBuilder struct {
    problem string
    steps   []string
}

func NewCoTBuilder(problem string) *CoTBuilder {
    return &CoTBuilder{
        problem: problem,
        steps:   make([]string, 0),
    }
}

// AddStep æ·»åŠ æ¨ç†æ­¥éª¤
func (b *CoTBuilder) AddStep(step string) *CoTBuilder {
    b.steps = append(b.steps, step)
    return b
}

// Build æ„å»ºCoT prompt
func (b *CoTBuilder) Build() string {
    var sb strings.Builder

    sb.WriteString("Let's solve this step by step:\n\n")
    sb.WriteString(fmt.Sprintf("Problem: %s\n\n", b.problem))

    for i, step := range b.steps {
        sb.WriteString(fmt.Sprintf("Step %d: %s\n", i+1, step))
    }

    sb.WriteString("\nBased on these steps, please provide the final answer.")

    return sb.String()
}

// BuildAutoCoT è‡ªåŠ¨ç”ŸæˆCoT prompt
func BuildAutoCoT(problem string) string {
    return fmt.Sprintf(`%s

Let's approach this step-by-step:
1. First, let's identify what we know
2. Then, let's determine what we need to find
3. Next, let's plan our solution strategy
4. Finally, let's execute the plan and verify

Please think through each step carefully.`, problem)
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleCoT() {
    // æ‰‹åŠ¨æ„å»ºCoT
    prompt := NewCoTBuilder("A store sold 48 apples in the morning and 36 in the afternoon. How many apples were sold in total?").
        AddStep("Identify the numbers: morning = 48, afternoon = 36").
        AddStep("Determine the operation: addition (finding total)").
        AddStep("Calculate: 48 + 36 = 84").
        Build()

    // è‡ªåŠ¨CoT
    autoPrompt := BuildAutoCoT("What is the sum of all even numbers from 1 to 100?")

    fmt.Println(prompt)
    fmt.Println(autoPrompt)
}
```

---

## 4. æµå¼å“åº”å¤„ç†

### 4.1 SSEæµå¼è¾“å‡º

**HTTP SSEæœåŠ¡å™¨å®ç°**:

```go
package api

import (
    "bufio"
    "context"
    "fmt"
    "net/http"
    "time"
)

// StreamHandler SSEæµå¼å¤„ç†å™¨
type StreamHandler struct {
    llmClient *llm.OpenAIClient
}

func NewStreamHandler(client *llm.OpenAIClient) *StreamHandler {
    return &StreamHandler{
        llmClient: client,
    }
}

// HandleStream å¤„ç†æµå¼è¯·æ±‚
func (h *StreamHandler) HandleStream(w http.ResponseWriter, r *http.Request) {
    // è®¾ç½®SSE headers
    w.Header().Set("Content-Type", "text/event-stream")
    w.Header().Set("Cache-Control", "no-cache")
    w.Header().Set("Connection", "keep-alive")
    w.Header().Set("Access-Control-Allow-Origin", "*")

    flusher, ok := w.(http.Flusher)
    if !ok {
        http.Error(w, "Streaming not supported", http.StatusInternalServerError)
        return
    }

    // è§£æè¯·æ±‚
    var req ChatRequest
    if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
        http.Error(w, err.Error(), http.StatusBadRequest)
        return
    }

    // æµå¼è°ƒç”¨LLM
    ctx := r.Context()
    err := h.llmClient.ChatStream(ctx, req, func(chunk string) error {
        // å‘é€SSEäº‹ä»¶
        fmt.Fprintf(w, "data: %s\n\n", chunk)
        flusher.Flush()

        // æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦æ–­å¼€
        select {
        case <-ctx.Done():
            return ctx.Err()
        default:
            return nil
        }
    })

    if err != nil {
        fmt.Fprintf(w, "data: [ERROR] %s\n\n", err.Error())
        flusher.Flush()
    }

    // å‘é€ç»“æŸæ ‡è®°
    fmt.Fprintf(w, "data: [DONE]\n\n")
    flusher.Flush()
}

// å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹ï¼ˆJavaScriptï¼‰
/*
const eventSource = new EventSource('/api/stream');

eventSource.onmessage = (event) => {
    if (event.data === '[DONE]') {
        eventSource.close();
        return;
    }
    
    if (event.data.startsWith('[ERROR]')) {
        console.error('Stream error:', event.data);
        return;
    }
    
    // æ˜¾ç¤ºæµå¼å†…å®¹
    document.getElementById('output').textContent += event.data;
};

eventSource.onerror = (error) => {
    console.error('SSE error:', error);
    eventSource.close();
};
*/
```

### 4.2 WebSocketå®æ—¶é€šä¿¡

**WebSocketæœåŠ¡å™¨å®ç°**:

```go
package api

import (
    "context"
    "encoding/json"
    "log"
    "net/http"
    
    "github.com/gorilla/websocket"
)

var upgrader = websocket.Upgrader{
    CheckOrigin: func(r *http.Request) bool {
        return true // ç”Ÿäº§ç¯å¢ƒéœ€è¦æ›´ä¸¥æ ¼çš„æ£€æŸ¥
    },
}

// WSHandler WebSocketå¤„ç†å™¨
type WSHandler struct {
    llmClient *llm.OpenAIClient
}

func NewWSHandler(client *llm.OpenAIClient) *WSHandler {
    return &WSHandler{
        llmClient: client,
    }
}

// HandleWS å¤„ç†WebSocketè¿æ¥
func (h *WSHandler) HandleWS(w http.ResponseWriter, r *http.Request) {
    conn, err := upgrader.Upgrade(w, r, nil)
    if err != nil {
        log.Printf("Upgrade error: %v", err)
        return
    }
    defer conn.Close()

    for {
        // è¯»å–å®¢æˆ·ç«¯æ¶ˆæ¯
        var req ChatRequest
        if err := conn.ReadJSON(&req); err != nil {
            if websocket.IsCloseError(err, websocket.CloseNormalClosure) {
                break
            }
            log.Printf("Read error: %v", err)
            break
        }

        // æµå¼å¤„ç†
        ctx := context.Background()
        err = h.llmClient.ChatStream(ctx, req, func(chunk string) error {
            // å‘é€chunkåˆ°å®¢æˆ·ç«¯
            msg := map[string]string{
                "type": "chunk",
                "data": chunk,
            }
            return conn.WriteJSON(msg)
        })

        if err != nil {
            conn.WriteJSON(map[string]string{
                "type":  "error",
                "error": err.Error(),
            })
            continue
        }

        // å‘é€å®Œæˆæ¶ˆæ¯
        conn.WriteJSON(map[string]string{
            "type": "done",
        })
    }
}

// å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹ï¼ˆJavaScriptï¼‰
/*
const ws = new WebSocket('ws://localhost:8080/ws');

ws.onopen = () => {
    ws.send(JSON.stringify({
        model: 'gpt-4',
        messages: [
            {role: 'user', content: 'Hello!'}
        ]
    }));
};

ws.onmessage = (event) => {
    const msg = JSON.parse(event.data);
    
    switch(msg.type) {
        case 'chunk':
            document.getElementById('output').textContent += msg.data;
            break;
        case 'done':
            console.log('Stream completed');
            break;
        case 'error':
            console.error('Error:', msg.error);
            break;
    }
};
*/
```

---

## 5. Function Calling

### 5.1 å‡½æ•°å®šä¹‰

**Functionå®šä¹‰å’Œæ³¨å†Œ**:

```go
package function

import (
    "encoding/json"
    "fmt"
)

// Function å‡½æ•°å®šä¹‰
type Function struct {
    Name        string                 `json:"name"`
    Description string                 `json:"description"`
    Parameters  map[string]interface{} `json:"parameters"`
    Handler     func(args map[string]interface{}) (interface{}, error) `json:"-"`
}

// FunctionRegistry å‡½æ•°æ³¨å†Œè¡¨
type FunctionRegistry struct {
    functions map[string]*Function
}

func NewFunctionRegistry() *FunctionRegistry {
    return &FunctionRegistry{
        functions: make(map[string]*Function),
    }
}

// Register æ³¨å†Œå‡½æ•°
func (r *FunctionRegistry) Register(fn *Function) {
    r.functions[fn.Name] = fn
}

// Get è·å–å‡½æ•°
func (r *FunctionRegistry) Get(name string) (*Function, bool) {
    fn, ok := r.functions[name]
    return fn, ok
}

// GetFunctionSpecs è·å–æ‰€æœ‰å‡½æ•°è§„æ ¼ï¼ˆç”¨äºAPIè°ƒç”¨ï¼‰
func (r *FunctionRegistry) GetFunctionSpecs() []map[string]interface{} {
    specs := make([]map[string]interface{}, 0, len(r.functions))
    
    for _, fn := range r.functions {
        specs = append(specs, map[string]interface{}{
            "name":        fn.Name,
            "description": fn.Description,
            "parameters":  fn.Parameters,
        })
    }
    
    return specs
}

// é¢„å®šä¹‰å‡½æ•°ç¤ºä¾‹
func SetupDefaultFunctions(registry *FunctionRegistry) {
    // è·å–å¤©æ°”
    registry.Register(&Function{
        Name:        "get_weather",
        Description: "Get the current weather for a location",
        Parameters: map[string]interface{}{
            "type": "object",
            "properties": map[string]interface{}{
                "location": map[string]interface{}{
                    "type":        "string",
                    "description": "City name, e.g. San Francisco",
                },
                "unit": map[string]interface{}{
                    "type": "string",
                    "enum": []string{"celsius", "fahrenheit"},
                },
            },
            "required": []string{"location"},
        },
        Handler: func(args map[string]interface{}) (interface{}, error) {
            location := args["location"].(string)
            unit := "celsius"
            if u, ok := args["unit"].(string); ok {
                unit = u
            }
            
            // å®é™…å®ç°ä¸­åº”è¯¥è°ƒç”¨çœŸå®çš„å¤©æ°”API
            return map[string]interface{}{
                "location":    location,
                "temperature": 22,
                "unit":        unit,
                "condition":   "sunny",
            }, nil
        },
    })

    // æœç´¢çŸ¥è¯†åº“
    registry.Register(&Function{
        Name:        "search_knowledge_base",
        Description: "Search the knowledge base for relevant information",
        Parameters: map[string]interface{}{
            "type": "object",
            "properties": map[string]interface{}{
                "query": map[string]interface{}{
                    "type":        "string",
                    "description": "Search query",
                },
                "top_k": map[string]interface{}{
                    "type":        "number",
                    "description": "Number of results to return",
                },
            },
            "required": []string{"query"},
        },
        Handler: func(args map[string]interface{}) (interface{}, error) {
            query := args["query"].(string)
            topK := 5
            if k, ok := args["top_k"].(float64); ok {
                topK = int(k)
            }
            
            // å®é™…å®ç°ä¸­åº”è¯¥æŸ¥è¯¢å‘é‡æ•°æ®åº“
            return []string{
                fmt.Sprintf("Result 1 for: %s", query),
                fmt.Sprintf("Result 2 for: %s", query),
            }, nil
        },
    })

    // æ‰§è¡Œè®¡ç®—
    registry.Register(&Function{
        Name:        "calculator",
        Description: "Perform mathematical calculations",
        Parameters: map[string]interface{}{
            "type": "object",
            "properties": map[string]interface{}{
                "expression": map[string]interface{}{
                    "type":        "string",
                    "description": "Mathematical expression to evaluate",
                },
            },
            "required": []string{"expression"},
        },
        Handler: func(args map[string]interface{}) (interface{}, error) {
            expr := args["expression"].(string)
            // å®é™…å®ç°ä¸­åº”è¯¥ä½¿ç”¨å®‰å…¨çš„è¡¨è¾¾å¼æ±‚å€¼å™¨
            return map[string]interface{}{
                "expression": expr,
                "result":     42, // ç¤ºä¾‹ç»“æœ
            }, nil
        },
    })
}
```

### 5.2 å‡½æ•°æ‰§è¡Œå™¨

**Function Callingå®Œæ•´æµç¨‹**:

```go
package function

import (
    "context"
    "encoding/json"
    "fmt"
)

// Executor å‡½æ•°æ‰§è¡Œå™¨
type Executor struct {
    registry  *FunctionRegistry
    llmClient *llm.OpenAIClient
}

func NewExecutor(registry *FunctionRegistry, client *llm.OpenAIClient) *Executor {
    return &Executor{
        registry:  registry,
        llmClient: client,
    }
}

// Execute æ‰§è¡ŒFunction Callingæµç¨‹
func (e *Executor) Execute(ctx context.Context, messages []ChatMessage) (*ChatResponse, error) {
    // 1. æ„å»ºå¸¦å‡½æ•°çš„è¯·æ±‚
    req := ChatRequest{
        Model:     "gpt-4",
        Messages:  messages,
        Functions: e.registry.GetFunctionSpecs(),
    }

    // 2. è°ƒç”¨LLM
    resp, err := e.llmClient.Chat(ctx, req)
    if err != nil {
        return nil, err
    }

    // 3. æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å‡½æ•°
    if resp.Choices[0].FinishReason == "function_call" {
        funcCall := resp.Choices[0].Message.FunctionCall
        
        // 4. æ‰§è¡Œå‡½æ•°
        fn, ok := e.registry.Get(funcCall.Name)
        if !ok {
            return nil, fmt.Errorf("function %s not found", funcCall.Name)
        }

        var args map[string]interface{}
        if err := json.Unmarshal([]byte(funcCall.Arguments), &args); err != nil {
            return nil, fmt.Errorf("parse arguments: %w", err)
        }

        result, err := fn.Handler(args)
        if err != nil {
            return nil, fmt.Errorf("execute function: %w", err)
        }

        // 5. å°†å‡½æ•°ç»“æœè¿”å›ç»™LLM
        resultJSON, _ := json.Marshal(result)
        messages = append(messages, ChatMessage{
            Role:    "function",
            Name:    funcCall.Name,
            Content: string(resultJSON),
        })

        // 6. é€’å½’è°ƒç”¨ï¼Œè®©LLMæ ¹æ®å‡½æ•°ç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        return e.Execute(ctx, messages)
    }

    // æ²¡æœ‰å‡½æ•°è°ƒç”¨ï¼Œè¿”å›ç»“æœ
    return resp, nil
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleFunctionCalling() {
    // è®¾ç½®
    registry := NewFunctionRegistry()
    SetupDefaultFunctions(registry)
    
    client := llm.NewOpenAIClient("sk-...")
    executor := NewExecutor(registry, client)

    // æ‰§è¡Œ
    messages := []ChatMessage{
        {Role: "user", Content: "What's the weather like in San Francisco?"},
    }

    resp, err := executor.Execute(context.Background(), messages)
    if err != nil {
        panic(err)
    }

    fmt.Println(resp.Choices[0].Message.Content)
    // è¾“å‡º: "The weather in San Francisco is currently sunny with a temperature of 22Â°C."
}
```

---

## 11. å®æˆ˜æ¡ˆä¾‹

### 11.1 æ™ºèƒ½èŠå¤©æœºå™¨äºº

**å®Œæ•´çš„èŠå¤©æœºå™¨äººå®ç°**:

```go
package chatbot

import (
    "context"
    "fmt"
    "sync"
    "time"
)

// ChatBot èŠå¤©æœºå™¨äºº
type ChatBot struct {
    llmClient    *llm.OpenAIClient
    sessions     map[string]*Session
    mu           sync.RWMutex
    maxHistory   int
    systemPrompt string
}

// Session ä¼šè¯
type Session struct {
    ID       string
    Messages []ChatMessage
    Created  time.Time
    Updated  time.Time
}

func NewChatBot(client *llm.OpenAIClient, systemPrompt string) *ChatBot {
    return &ChatBot{
        llmClient:    client,
        sessions:     make(map[string]*Session),
        maxHistory:   20,
        systemPrompt: systemPrompt,
    }
}

// CreateSession åˆ›å»ºä¼šè¯
func (b *ChatBot) CreateSession(sessionID string) {
    b.mu.Lock()
    defer b.mu.Unlock()

    b.sessions[sessionID] = &Session{
        ID:       sessionID,
        Messages: []ChatMessage{
            {Role: "system", Content: b.systemPrompt},
        },
        Created: time.Now(),
        Updated: time.Now(),
    }
}

// Chat èŠå¤©
func (b *ChatBot) Chat(ctx context.Context, sessionID, message string) (string, error) {
    b.mu.Lock()
    session, ok := b.sessions[sessionID]
    if !ok {
        b.mu.Unlock()
        return "", fmt.Errorf("session not found")
    }

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    session.Messages = append(session.Messages, ChatMessage{
        Role:    "user",
        Content: message,
    })

    // ä¿æŒå†å²è®°å½•åœ¨é™åˆ¶å†…
    if len(session.Messages) > b.maxHistory {
        // ä¿ç•™systemæ¶ˆæ¯ + æœ€è¿‘çš„æ¶ˆæ¯
        session.Messages = append(
            session.Messages[:1],
            session.Messages[len(session.Messages)-b.maxHistory+1:]...,
        )
    }

    messages := session.Messages
    b.mu.Unlock()

    // è°ƒç”¨LLM
    resp, err := b.llmClient.Chat(ctx, ChatRequest{
        Model:       "gpt-4",
        Messages:    messages,
        Temperature: 0.7,
    })
    if err != nil {
        return "", err
    }

    reply := resp.Choices[0].Message.Content

    // ä¿å­˜åŠ©æ‰‹å›å¤
    b.mu.Lock()
    session.Messages = append(session.Messages, ChatMessage{
        Role:    "assistant",
        Content: reply,
    })
    session.Updated = time.Now()
    b.mu.Unlock()

    return reply, nil
}

// ChatStream æµå¼èŠå¤©
func (b *ChatBot) ChatStream(
    ctx context.Context,
    sessionID, message string,
    callback func(string) error,
) error {
    b.mu.Lock()
    session, ok := b.sessions[sessionID]
    if !ok {
        b.mu.Unlock()
        return fmt.Errorf("session not found")
    }

    session.Messages = append(session.Messages, ChatMessage{
        Role:    "user",
        Content: message,
    })

    messages := session.Messages
    b.mu.Unlock()

    // æµå¼è°ƒç”¨
    var fullReply string
    err := b.llmClient.ChatStream(ctx, ChatRequest{
        Model:    "gpt-4",
        Messages: messages,
    }, func(chunk string) error {
        fullReply += chunk
        return callback(chunk)
    })

    if err != nil {
        return err
    }

    // ä¿å­˜å®Œæ•´å›å¤
    b.mu.Lock()
    session.Messages = append(session.Messages, ChatMessage{
        Role:    "assistant",
        Content: fullReply,
    })
    session.Updated = time.Now()
    b.mu.Unlock()

    return nil
}

// GetHistory è·å–å†å²
func (b *ChatBot) GetHistory(sessionID string) ([]ChatMessage, error) {
    b.mu.RLock()
    defer b.mu.RUnlock()

    session, ok := b.sessions[sessionID]
    if !ok {
        return nil, fmt.Errorf("session not found")
    }

    return session.Messages, nil
}

// HTTP Handler
type ChatBotHandler struct {
    bot *ChatBot
}

func NewChatBotHandler(bot *ChatBot) *ChatBotHandler {
    return &ChatBotHandler{bot: bot}
}

func (h *ChatBotHandler) HandleChat(w http.ResponseWriter, r *http.Request) {
    var req struct {
        SessionID string `json:"session_id"`
        Message   string `json:"message"`
    }

    if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
        http.Error(w, err.Error(), http.StatusBadRequest)
        return
    }

    reply, err := h.bot.Chat(r.Context(), req.SessionID, req.Message)
    if err != nil {
        http.Error(w, err.Error(), http.StatusInternalServerError)
        return
    }

    json.NewEncoder(w).Encode(map[string]string{
        "reply": reply,
    })
}

// ä½¿ç”¨ç¤ºä¾‹
func Example() {
    client := llm.NewOpenAIClient("sk-...")
    bot := NewChatBot(client, "You are a helpful assistant.")

    // åˆ›å»ºä¼šè¯
    sessionID := "user-123"
    bot.CreateSession(sessionID)

    // èŠå¤©
    reply, _ := bot.Chat(context.Background(), sessionID, "Hello!")
    fmt.Println(reply)

    reply, _ = bot.Chat(context.Background(), sessionID, "What's your name?")
    fmt.Println(reply)

    // æŸ¥çœ‹å†å²
    history, _ := bot.GetHistory(sessionID)
    for _, msg := range history {
        fmt.Printf("%s: %s\n", msg.Role, msg.Content)
    }
}
```

### 11.2 æ–‡æ¡£æ‘˜è¦æœåŠ¡

**æ™ºèƒ½æ–‡æ¡£æ‘˜è¦**:

```go
package summarizer

import (
    "context"
    "fmt"
    "strings"
)

// Summarizer æ–‡æ¡£æ‘˜è¦å™¨
type Summarizer struct {
    llmClient   *llm.OpenAIClient
    chunkSize   int
    maxTokens   int
}

func NewSummarizer(client *llm.OpenAIClient) *Summarizer {
    return &Summarizer{
        llmClient: client,
        chunkSize: 2000, // å­—ç¬¦æ•°
        maxTokens: 500,
    }
}

// SummarizeText æ‘˜è¦æ–‡æœ¬
func (s *Summarizer) SummarizeText(ctx context.Context, text string) (string, error) {
    // å¦‚æœæ–‡æœ¬è¾ƒçŸ­ï¼Œç›´æ¥æ‘˜è¦
    if len(text) <= s.chunkSize {
        return s.summarizeChunk(ctx, text)
    }

    // é•¿æ–‡æœ¬ï¼šåˆ†å—æ‘˜è¦åå†æ€»ç»“
    chunks := s.splitIntoChunks(text, s.chunkSize)
    summaries := make([]string, 0, len(chunks))

    for i, chunk := range chunks {
        summary, err := s.summarizeChunk(ctx, chunk)
        if err != nil {
            return "", fmt.Errorf("summarize chunk %d: %w", i, err)
        }
        summaries = append(summaries, summary)
    }

    // åˆå¹¶æ‰€æœ‰æ‘˜è¦å¹¶å†æ¬¡æ€»ç»“
    combined := strings.Join(summaries, "\n\n")
    return s.summarizeChunk(ctx, combined)
}

// summarizeChunk æ‘˜è¦å•ä¸ªå—
func (s *Summarizer) summarizeChunk(ctx context.Context, text string) (string, error) {
    prompt := fmt.Sprintf(`Please provide a concise summary of the following text:

%s

Summary:`, text)

    resp, err := s.llmClient.Chat(ctx, ChatRequest{
        Model: "gpt-4",
        Messages: []ChatMessage{
            {
                Role: "system",
                Content: "You are an expert at summarizing documents concisely while preserving key information.",
            },
            {
                Role:    "user",
                Content: prompt,
            },
        },
        MaxTokens:   s.maxTokens,
        Temperature: 0.3,
    })

    if err != nil {
        return "", err
    }

    return resp.Choices[0].Message.Content, nil
}

// splitIntoChunks åˆ†å—
func (s *Summarizer) splitIntoChunks(text string, chunkSize int) []string {
    var chunks []string
    words := strings.Fields(text)
    
    var current strings.Builder
    for _, word := range words {
        if current.Len()+len(word)+1 > chunkSize {
            chunks = append(chunks, current.String())
            current.Reset()
        }
        
        if current.Len() > 0 {
            current.WriteString(" ")
        }
        current.WriteString(word)
    }
    
    if current.Len() > 0 {
        chunks = append(chunks, current.String())
    }
    
    return chunks
}

// SummarizeWithBulletPoints ç”Ÿæˆè¦ç‚¹æ‘˜è¦
func (s *Summarizer) SummarizeWithBulletPoints(ctx context.Context, text string) ([]string, error) {
    prompt := fmt.Sprintf(`Summarize the following text in bullet points:

%s

Provide 3-5 key points:`, text)

    resp, err := s.llmClient.Chat(ctx, ChatRequest{
        Model: "gpt-4",
        Messages: []ChatMessage{
            {Role: "system", Content: "You are a summarization expert."},
            {Role: "user", Content: prompt},
        },
        MaxTokens: 300,
    })

    if err != nil {
        return nil, err
    }

    // è§£æè¦ç‚¹
    content := resp.Choices[0].Message.Content
    lines := strings.Split(content, "\n")
    
    var bullets []string
    for _, line := range lines {
        line = strings.TrimSpace(line)
        if strings.HasPrefix(line, "-") || strings.HasPrefix(line, "â€¢") || strings.HasPrefix(line, "*") {
            bullets = append(bullets, strings.TrimPrefix(strings.TrimPrefix(strings.TrimPrefix(line, "-"), "â€¢"), "*"))
        }
    }
    
    return bullets, nil
}

// ä½¿ç”¨ç¤ºä¾‹
func Example() {
    client := llm.NewOpenAIClient("sk-...")
    summarizer := NewSummarizer(client)

    longText := `[Long document content...]`

    // ç”Ÿæˆæ‘˜è¦
    summary, _ := summarizer.SummarizeText(context.Background(), longText)
    fmt.Println("Summary:", summary)

    // ç”Ÿæˆè¦ç‚¹
    bullets, _ := summarizer.SummarizeWithBulletPoints(context.Background(), longText)
    for i, bullet := range bullets {
        fmt.Printf("%d. %s\n", i+1, bullet)
    }
}
```

---

## 12. ç”Ÿäº§éƒ¨ç½²

### 12.1 é…ç½®ç®¡ç†

**ç¯å¢ƒé…ç½®**:

```go
package config

import (
    "fmt"
    "os"
    "strconv"
)

// LLMConfig LLMé…ç½®
type LLMConfig struct {
    OpenAIKey      string
    ClaudeKey      string
    DefaultModel   string
    MaxTokens      int
    Temperature    float64
    Timeout        int
    RetryAttempts  int
    CacheEnabled   bool
    CacheTTL       int
}

// LoadConfig åŠ è½½é…ç½®
func LoadConfig() (*LLMConfig, error) {
    config := &LLMConfig{
        OpenAIKey:     getEnv("OPENAI_API_KEY", ""),
        ClaudeKey:     getEnv("CLAUDE_API_KEY", ""),
        DefaultModel:  getEnv("LLM_DEFAULT_MODEL", "gpt-4"),
        MaxTokens:     getEnvInt("LLM_MAX_TOKENS", 2000),
        Temperature:   getEnvFloat("LLM_TEMPERATURE", 0.7),
        Timeout:       getEnvInt("LLM_TIMEOUT", 60),
        RetryAttempts: getEnvInt("LLM_RETRY_ATTEMPTS", 3),
        CacheEnabled:  getEnvBool("LLM_CACHE_ENABLED", true),
        CacheTTL:      getEnvInt("LLM_CACHE_TTL", 3600),
    }

    // éªŒè¯å¿…éœ€é…ç½®
    if config.OpenAIKey == "" && config.ClaudeKey == "" {
        return nil, fmt.Errorf("at least one API key must be provided")
    }

    return config, nil
}

func getEnv(key, defaultValue string) string {
    if value := os.Getenv(key); value != "" {
        return value
    }
    return defaultValue
}

func getEnvInt(key string, defaultValue int) int {
    if value := os.Getenv(key); value != "" {
        if intValue, err := strconv.Atoi(value); err == nil {
            return intValue
        }
    }
    return defaultValue
}

func getEnvFloat(key string, defaultValue float64) float64 {
    if value := os.Getenv(key); value != "" {
        if floatValue, err := strconv.ParseFloat(value, 64); err == nil {
            return floatValue
        }
    }
    return defaultValue
}

func getEnvBool(key string, defaultValue bool) bool {
    if value := os.Getenv(key); value != "" {
        if boolValue, err := strconv.ParseBool(value); err == nil {
            return boolValue
        }
    }
    return defaultValue
}
```

### 12.2 ç›‘æ§ä¸æ—¥å¿—

**ç›‘æ§æŒ‡æ ‡**:

```go
package monitoring

import (
    "time"
    
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    // LLMè¯·æ±‚è®¡æ•°
    llmRequestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "llm_requests_total",
            Help: "Total number of LLM requests",
        },
        []string{"model", "status"},
    )

    // LLMè¯·æ±‚å»¶è¿Ÿ
    llmRequestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "llm_request_duration_seconds",
            Help:    "Duration of LLM requests",
            Buckets: prometheus.DefBuckets,
        },
        []string{"model"},
    )

    // Tokenä½¿ç”¨é‡
    llmTokensUsed = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "llm_tokens_used_total",
            Help: "Total number of tokens used",
        },
        []string{"model", "type"}, // type: prompt, completion
    )

    // LLMæˆæœ¬
    llmCost = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "llm_cost_total_dollars",
            Help: "Total LLM API cost in dollars",
        },
        []string{"model"},
    )
)

// Metrics LLMæŒ‡æ ‡æ”¶é›†å™¨
type Metrics struct{}

func NewMetrics() *Metrics {
    return &Metrics{}
}

// RecordRequest è®°å½•è¯·æ±‚
func (m *Metrics) RecordRequest(model string, duration time.Duration, promptTokens, completionTokens int, success bool) {
    status := "success"
    if !success {
        status := "error"
    }

    llmRequestsTotal.WithLabelValues(model, status).Inc()
    llmRequestDuration.WithLabelValues(model).Observe(duration.Seconds())
    
    llmTokensUsed.WithLabelValues(model, "prompt").Add(float64(promptTokens))
    llmTokensUsed.WithLabelValues(model, "completion").Add(float64(completionTokens))

    // è®¡ç®—æˆæœ¬ï¼ˆç¤ºä¾‹ä»·æ ¼ï¼‰
    cost := calculateCost(model, promptTokens, completionTokens)
    llmCost.WithLabelValues(model).Add(cost)
}

func calculateCost(model string, promptTokens, completionTokens int) float64 {
    // GPT-4å®šä»·ï¼ˆ2025å¹´ç¤ºä¾‹ï¼‰
    if model == "gpt-4" {
        promptCost := float64(promptTokens) * 0.03 / 1000
        completionCost := float64(completionTokens) * 0.06 / 1000
        return promptCost + completionCost
    }
    return 0
}
```

### 12.3 å®‰å…¨æœ€ä½³å®è·µ

**å®‰å…¨æªæ–½**:

```go
package security

import (
    "context"
    "fmt"
    "regexp"
    "strings"
)

// ContentModerator å†…å®¹å®¡æ ¸å™¨
type ContentModerator struct {
    bannedPatterns []*regexp.Regexp
    maxLength      int
}

func NewContentModerator() *ContentModerator {
    return &ContentModerator{
        bannedPatterns: []*regexp.Regexp{
            regexp.MustCompile(`\b(password|api[_\-]?key|secret|token)\b`),
            // æ·»åŠ æ›´å¤šæ•æ„Ÿè¯æ¨¡å¼
        },
        maxLength: 10000,
    }
}

// CheckContent æ£€æŸ¥å†…å®¹
func (m *ContentModerator) CheckContent(content string) error {
    // é•¿åº¦æ£€æŸ¥
    if len(content) > m.maxLength {
        return fmt.Errorf("content too long: %d > %d", len(content), m.maxLength)
    }

    // æ•æ„Ÿä¿¡æ¯æ£€æŸ¥
    for _, pattern := range m.bannedPatterns {
        if pattern.MatchString(strings.ToLower(content)) {
            return fmt.Errorf("content contains sensitive information")
        }
    }

    return nil
}

// RateLimiter APIé™æµå™¨
type RateLimiter struct {
    // ä½¿ç”¨golang.org/x/time/rate
}

// SecureClient å®‰å…¨çš„LLMå®¢æˆ·ç«¯åŒ…è£…
type SecureClient struct {
    client    *llm.OpenAIClient
    moderator *ContentModerator
    limiter   *RateLimiter
}

func (c *SecureClient) Chat(ctx context.Context, req ChatRequest) (*ChatResponse, error) {
    // 1. å†…å®¹å®¡æ ¸
    for _, msg := range req.Messages {
        if err := c.moderator.CheckContent(msg.Content); err != nil {
            return nil, fmt.Errorf("content moderation failed: %w", err)
        }
    }

    // 2. é™æµæ£€æŸ¥
    if err := c.limiter.Wait(ctx); err != nil {
        return nil, fmt.Errorf("rate limit exceeded: %w", err)
    }

    // 3. è°ƒç”¨LLM
    return c.client.Chat(ctx, req)
}
```

---

## 13. å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

- [OpenAI API Documentation](https://platform.openai.com/docs)
- [Anthropic Claude API](https://docs.anthropic.com/claude/reference)
- [Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)

### Goåº“

- [go-openai](https://github.com/sashabaranov/go-openai) - OpenAI Goå®¢æˆ·ç«¯
- [langchaingo](https://github.com/tmc/langchaingo) - LangChain Goå®ç°
- [chromem-go](https://github.com/philippgille/chromem-go) - å‘é‡æ•°æ®åº“

### æœ€ä½³å®è·µ

- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [LLM Application Patterns](https://martinfowler.com/articles/2023-chatgpt-xu-hao.html)

---

**æ–‡æ¡£ç»´æŠ¤è€…**: Go Documentation Team  
**æœ€åæ›´æ–°**: 2025å¹´10æœˆ24æ—¥  
**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ  
**é€‚ç”¨ç‰ˆæœ¬**: Go 1.21+

**è´¡çŒ®è€…**: æ¬¢è¿æäº¤Issueå’ŒPRæ”¹è¿›æœ¬æ–‡æ¡£
