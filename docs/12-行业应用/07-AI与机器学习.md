# Go AIä¸æœºå™¨å­¦ä¹ å¼€å‘å®Œå…¨æŒ‡å—

> **ç®€ä»‹**: Goè¯­è¨€åœ¨AIå’Œæœºå™¨å­¦ä¹ é¢†åŸŸçš„å®Œæ•´å®è·µï¼Œæ¶µç›–æ¨ç†æœåŠ¡ã€æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹éƒ¨ç½²ç­‰æ ¸å¿ƒåœºæ™¯

---

## ğŸ“š ç›®å½•

- [Go AIä¸æœºå™¨å­¦ä¹ å¼€å‘å®Œå…¨æŒ‡å—](#go-aiä¸æœºå™¨å­¦ä¹ å¼€å‘å®Œå…¨æŒ‡å—)
  - [ğŸ“š ç›®å½•](#-ç›®å½•)
  - [1. AI/MLæ¶æ„æ¦‚è¿°](#1-aimlæ¶æ„æ¦‚è¿°)
    - [å…¸å‹MLç³»ç»Ÿæ¶æ„](#å…¸å‹mlç³»ç»Ÿæ¶æ„)
    - [Goåœ¨AI/MLä¸­çš„å®šä½](#goåœ¨aimlä¸­çš„å®šä½)
  - [2. æ•°æ®å¤„ç†](#2-æ•°æ®å¤„ç†)
    - [æ•°æ®åŠ è½½ä¸é¢„å¤„ç†](#æ•°æ®åŠ è½½ä¸é¢„å¤„ç†)
    - [ç‰¹å¾å·¥ç¨‹](#ç‰¹å¾å·¥ç¨‹)
  - [3. æ¨¡å‹æ¨ç†](#3-æ¨¡å‹æ¨ç†)
    - [ONNX Runtimeé›†æˆ](#onnx-runtimeé›†æˆ)
    - [TensorFlow Liteé›†æˆ](#tensorflow-liteé›†æˆ)
  - [4. æ¨ç†æœåŠ¡](#4-æ¨ç†æœåŠ¡)
    - [HTTPæ¨ç†æœåŠ¡](#httpæ¨ç†æœåŠ¡)
    - [gRPCæ¨ç†æœåŠ¡](#grpcæ¨ç†æœåŠ¡)
  - [5. æ¨¡å‹éƒ¨ç½²](#5-æ¨¡å‹éƒ¨ç½²)
    - [å®¹å™¨åŒ–éƒ¨ç½²](#å®¹å™¨åŒ–éƒ¨ç½²)
    - [æ¨¡å‹ç‰ˆæœ¬ç®¡ç†](#æ¨¡å‹ç‰ˆæœ¬ç®¡ç†)
  - [6. æ‰¹é‡é¢„æµ‹](#6-æ‰¹é‡é¢„æµ‹)
    - [æ‰¹å¤„ç†å¼•æ“](#æ‰¹å¤„ç†å¼•æ“)
    - [åˆ†å¸ƒå¼é¢„æµ‹](#åˆ†å¸ƒå¼é¢„æµ‹)
  - [7. ç‰¹å¾å­˜å‚¨](#7-ç‰¹å¾å­˜å‚¨)
    - [ç‰¹å¾Storeå®ç°](#ç‰¹å¾storeå®ç°)
    - [ç‰¹å¾ç®¡é“](#ç‰¹å¾ç®¡é“)
  - [8. æ¨¡å‹ç›‘æ§](#8-æ¨¡å‹ç›‘æ§)
    - [æ€§èƒ½ç›‘æ§](#æ€§èƒ½ç›‘æ§)
    - [æ•°æ®æ¼‚ç§»æ£€æµ‹](#æ•°æ®æ¼‚ç§»æ£€æµ‹)
  - [9. è‡ªç„¶è¯­è¨€å¤„ç†](#9-è‡ªç„¶è¯­è¨€å¤„ç†)
    - [æ–‡æœ¬é¢„å¤„ç†](#æ–‡æœ¬é¢„å¤„ç†)
    - [æƒ…æ„Ÿåˆ†ææœåŠ¡](#æƒ…æ„Ÿåˆ†ææœåŠ¡)
  - [10. è®¡ç®—æœºè§†è§‰](#10-è®¡ç®—æœºè§†è§‰)
    - [å›¾åƒé¢„å¤„ç†](#å›¾åƒé¢„å¤„ç†)
    - [ç›®æ ‡æ£€æµ‹æœåŠ¡](#ç›®æ ‡æ£€æµ‹æœåŠ¡)
  - [11. å®æˆ˜é¡¹ç›®ï¼šå›¾åƒåˆ†ç±»API](#11-å®æˆ˜é¡¹ç›®å›¾åƒåˆ†ç±»api)
    - [ç³»ç»Ÿæ¶æ„](#ç³»ç»Ÿæ¶æ„)
    - [æ ¸å¿ƒå®ç°](#æ ¸å¿ƒå®ç°)
  - [12. æ€§èƒ½ä¼˜åŒ–](#12-æ€§èƒ½ä¼˜åŒ–)
  - [13. æœ€ä½³å®è·µ](#13-æœ€ä½³å®è·µ)
  - [14. å¼€æºé¡¹ç›®æ¨è](#14-å¼€æºé¡¹ç›®æ¨è)

---

## 1. AI/MLæ¶æ„æ¦‚è¿°

### å…¸å‹MLç³»ç»Ÿæ¶æ„

```mermaid
graph TB
    Client[å®¢æˆ·ç«¯] --> API[APIç½‘å…³]
    API --> LoadBalancer[è´Ÿè½½å‡è¡¡]
    LoadBalancer --> Service1[æ¨ç†æœåŠ¡1]
    LoadBalancer --> Service2[æ¨ç†æœåŠ¡2]
    LoadBalancer --> Service3[æ¨ç†æœåŠ¡3]
    
    Service1 --> ModelStore[æ¨¡å‹å­˜å‚¨]
    Service2 --> ModelStore
    Service3 --> ModelStore
    
    Service1 --> FeatureStore[ç‰¹å¾å­˜å‚¨]
    Service2 --> FeatureStore
    Service3 --> FeatureStore
    
    Service1 --> Monitoring[ç›‘æ§ç³»ç»Ÿ]
    Service2 --> Monitoring
    Service3 --> Monitoring
    
    style API fill:#e1f5fe
    style Service1 fill:#fff3e0
    style Service2 fill:#fff3e0
    style Service3 fill:#fff3e0
    style ModelStore fill:#e8f5e9
    style Monitoring fill:#f3e5f5
```

### Goåœ¨AI/MLä¸­çš„å®šä½

**ä¼˜åŠ¿**:

- âœ… é«˜æ€§èƒ½æ¨ç†æœåŠ¡
- âœ… é«˜å¹¶å‘å¤„ç†èƒ½åŠ›
- âœ… ç®€å•çš„éƒ¨ç½²å’Œè¿ç»´
- âœ… ä¼˜ç§€çš„ç½‘ç»œç¼–ç¨‹æ”¯æŒ
- âœ… å®¹å™¨åŒ–å‹å¥½

**å±€é™**:

- âŒ æ¨¡å‹è®­ç»ƒç”Ÿæ€ä¸å¦‚Python
- âŒ ç¬¬ä¸‰æ–¹MLåº“ç›¸å¯¹è¾ƒå°‘
- âŒ ç§‘å­¦è®¡ç®—åº“ä¸å¦‚Pythonä¸°å¯Œ

**æœ€ä½³å®è·µ**:

- ä½¿ç”¨Pythonè¿›è¡Œæ¨¡å‹è®­ç»ƒ
- ä½¿ç”¨Goéƒ¨ç½²æ¨ç†æœåŠ¡
- é€šè¿‡ONNXç­‰æ ¼å¼è½¬æ¢æ¨¡å‹

---

## 2. æ•°æ®å¤„ç†

### æ•°æ®åŠ è½½ä¸é¢„å¤„ç†

```go
package data

import (
    "encoding/csv"
    "os"
    "strconv"
)

// Dataset æ•°æ®é›†
type Dataset struct {
    Features [][]float64
    Labels   []float64
}

// LoadCSV åŠ è½½CSVæ•°æ®
func LoadCSV(filename string) (*Dataset, error) {
    file, err := os.Open(filename)
    if err != nil {
        return nil, err
    }
    defer file.Close()
    
    reader := csv.NewReader(file)
    records, err := reader.ReadAll()
    if err != nil {
        return nil, err
    }
    
    dataset := &Dataset{
        Features: make([][]float64, 0),
        Labels:   make([]float64, 0),
    }
    
    // è·³è¿‡æ ‡é¢˜è¡Œ
    for i := 1; i < len(records); i++ {
        record := records[i]
        
        // è§£æç‰¹å¾
        features := make([]float64, len(record)-1)
        for j := 0; j < len(record)-1; j++ {
            val, _ := strconv.ParseFloat(record[j], 64)
            features[j] = val
        }
        
        // è§£ææ ‡ç­¾
        label, _ := strconv.ParseFloat(record[len(record)-1], 64)
        
        dataset.Features = append(dataset.Features, features)
        dataset.Labels = append(dataset.Labels, label)
    }
    
    return dataset, nil
}

// Normalize æ•°æ®å½’ä¸€åŒ–
func (d *Dataset) Normalize() {
    if len(d.Features) == 0 {
        return
    }
    
    numFeatures := len(d.Features[0])
    
    // è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å‡å€¼å’Œæ ‡å‡†å·®
    means := make([]float64, numFeatures)
    stds := make([]float64, numFeatures)
    
    // è®¡ç®—å‡å€¼
    for _, features := range d.Features {
        for j, val := range features {
            means[j] += val
        }
    }
    
    for j := range means {
        means[j] /= float64(len(d.Features))
    }
    
    // è®¡ç®—æ ‡å‡†å·®
    for _, features := range d.Features {
        for j, val := range features {
            diff := val - means[j]
            stds[j] += diff * diff
        }
    }
    
    for j := range stds {
        stds[j] = math.Sqrt(stds[j] / float64(len(d.Features)))
    }
    
    // å½’ä¸€åŒ–
    for i := range d.Features {
        for j := range d.Features[i] {
            if stds[j] != 0 {
                d.Features[i][j] = (d.Features[i][j] - means[j]) / stds[j]
            }
        }
    }
}

// Split åˆ†å‰²æ•°æ®é›†
func (d *Dataset) Split(ratio float64) (*Dataset, *Dataset) {
    splitIdx := int(float64(len(d.Features)) * ratio)
    
    train := &Dataset{
        Features: d.Features[:splitIdx],
        Labels:   d.Labels[:splitIdx],
    }
    
    test := &Dataset{
        Features: d.Features[splitIdx:],
        Labels:   d.Labels[splitIdx:],
    }
    
    return train, test
}
```

### ç‰¹å¾å·¥ç¨‹

```go
// FeatureTransformer ç‰¹å¾è½¬æ¢å™¨
type FeatureTransformer struct {
    transformers []Transformer
}

type Transformer interface {
    Fit(data [][]float64)
    Transform(data [][]float64) [][]float64
}

func NewFeatureTransformer() *FeatureTransformer {
    return &FeatureTransformer{
        transformers: make([]Transformer, 0),
    }
}

// AddTransformer æ·»åŠ è½¬æ¢å™¨
func (ft *FeatureTransformer) AddTransformer(t Transformer) {
    ft.transformers = append(ft.transformers, t)
}

// FitTransform æ‹Ÿåˆå¹¶è½¬æ¢
func (ft *FeatureTransformer) FitTransform(data [][]float64) [][]float64 {
    result := data
    for _, transformer := range ft.transformers {
        transformer.Fit(result)
        result = transformer.Transform(result)
    }
    return result
}

// Transform è½¬æ¢
func (ft *FeatureTransformer) Transform(data [][]float64) [][]float64 {
    result := data
    for _, transformer := range ft.transformers {
        result = transformer.Transform(result)
    }
    return result
}

// StandardScaler æ ‡å‡†åŒ–è½¬æ¢å™¨
type StandardScaler struct {
    means []float64
    stds  []float64
}

func NewStandardScaler() *StandardScaler {
    return &StandardScaler{}
}

func (s *StandardScaler) Fit(data [][]float64) {
    if len(data) == 0 {
        return
    }
    
    numFeatures := len(data[0])
    s.means = make([]float64, numFeatures)
    s.stds = make([]float64, numFeatures)
    
    // è®¡ç®—å‡å€¼
    for _, row := range data {
        for j, val := range row {
            s.means[j] += val
        }
    }
    
    for j := range s.means {
        s.means[j] /= float64(len(data))
    }
    
    // è®¡ç®—æ ‡å‡†å·®
    for _, row := range data {
        for j, val := range row {
            diff := val - s.means[j]
            s.stds[j] += diff * diff
        }
    }
    
    for j := range s.stds {
        s.stds[j] = math.Sqrt(s.stds[j] / float64(len(data)))
        if s.stds[j] == 0 {
            s.stds[j] = 1
        }
    }
}

func (s *StandardScaler) Transform(data [][]float64) [][]float64 {
    result := make([][]float64, len(data))
    
    for i, row := range data {
        result[i] = make([]float64, len(row))
        for j, val := range row {
            result[i][j] = (val - s.means[j]) / s.stds[j]
        }
    }
    
    return result
}
```

---

## 3. æ¨¡å‹æ¨ç†

### ONNX Runtimeé›†æˆ

```go
package inference

import (
    "github.com/yalue/onnxruntime_go"
)

// ONNXModel ONNXæ¨¡å‹
type ONNXModel struct {
    session *onnxruntime_go.Session
    input   *onnxruntime_go.Tensor
    output  *onnxruntime_go.Tensor
}

func NewONNXModel(modelPath string) (*ONNXModel, error) {
    // åˆå§‹åŒ–ONNX Runtime
    err := onnxruntime_go.InitializeEnvironment()
    if err != nil {
        return nil, err
    }
    
    // åˆ›å»ºä¼šè¯
    session, err := onnxruntime_go.NewSession(modelPath, nil)
    if err != nil {
        return nil, err
    }
    
    return &ONNXModel{
        session: session,
    }, nil
}

// Predict é¢„æµ‹
func (m *ONNXModel) Predict(input []float32) ([]float32, error) {
    // åˆ›å»ºè¾“å…¥å¼ é‡
    inputShape := []int64{1, int64(len(input))}
    inputTensor, err := onnxruntime_go.NewTensor(inputShape, input)
    if err != nil {
        return nil, err
    }
    defer inputTensor.Destroy()
    
    // è¿è¡Œæ¨ç†
    outputs, err := m.session.Run([]onnxruntime_go.Value{inputTensor})
    if err != nil {
        return nil, err
    }
    
    // è·å–è¾“å‡º
    outputTensor := outputs[0].(*onnxruntime_go.Tensor)
    outputData := outputTensor.GetData().([]float32)
    
    return outputData, nil
}

func (m *ONNXModel) Close() error {
    if m.session != nil {
        return m.session.Destroy()
    }
    return nil
}
```

### TensorFlow Liteé›†æˆ

```go
// TFLiteModel TensorFlow Liteæ¨¡å‹
type TFLiteModel struct {
    interpreter *tflite.Interpreter
}

func NewTFLiteModel(modelPath string) (*TFLiteModel, error) {
    // åŠ è½½æ¨¡å‹
    model := tflite.NewModelFromFile(modelPath)
    if model == nil {
        return nil, errors.New("failed to load model")
    }
    
    // åˆ›å»ºè§£é‡Šå™¨
    options := tflite.NewInterpreterOptions()
    options.SetNumThread(4)
    
    interpreter := tflite.NewInterpreter(model, options)
    if interpreter == nil {
        return nil, errors.New("failed to create interpreter")
    }
    
    // åˆ†é…å¼ é‡
    if status := interpreter.AllocateTensors(); status != tflite.OK {
        return nil, errors.New("failed to allocate tensors")
    }
    
    return &TFLiteModel{
        interpreter: interpreter,
    }, nil
}

// Predict é¢„æµ‹
func (m *TFLiteModel) Predict(input []float32) ([]float32, error) {
    // è·å–è¾“å…¥å¼ é‡
    inputTensor := m.interpreter.GetInputTensor(0)
    
    // å¤åˆ¶è¾“å…¥æ•°æ®
    copy(inputTensor.Float32s(), input)
    
    // æ‰§è¡Œæ¨ç†
    if status := m.interpreter.Invoke(); status != tflite.OK {
        return nil, errors.New("inference failed")
    }
    
    // è·å–è¾“å‡º
    outputTensor := m.interpreter.GetOutputTensor(0)
    output := make([]float32, outputTensor.Dim(1))
    copy(output, outputTensor.Float32s())
    
    return output, nil
}

func (m *TFLiteModel) Close() {
    if m.interpreter != nil {
        m.interpreter.Delete()
    }
}
```

---

## 4. æ¨ç†æœåŠ¡

### HTTPæ¨ç†æœåŠ¡

```go
package server

import (
    "encoding/json"
    "net/http"
    
    "github.com/gorilla/mux"
)

// InferenceServer æ¨ç†æœåŠ¡å™¨
type InferenceServer struct {
    model  Model
    router *mux.Router
}

type Model interface {
    Predict(input []float32) ([]float32, error)
}

type PredictRequest struct {
    Inputs [][]float32 `json:"inputs"`
}

type PredictResponse struct {
    Predictions [][]float32 `json:"predictions"`
    Latency     int64       `json:"latency_ms"`
}

func NewInferenceServer(model Model) *InferenceServer {
    server := &InferenceServer{
        model:  model,
        router: mux.NewRouter(),
    }
    
    server.setupRoutes()
    return server
}

func (s *InferenceServer) setupRoutes() {
    s.router.HandleFunc("/predict", s.handlePredict).Methods("POST")
    s.router.HandleFunc("/health", s.handleHealth).Methods("GET")
    s.router.HandleFunc("/metrics", s.handleMetrics).Methods("GET")
}

func (s *InferenceServer) handlePredict(w http.ResponseWriter, r *http.Request) {
    start := time.Now()
    
    var req PredictRequest
    if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
        http.Error(w, err.Error(), http.StatusBadRequest)
        return
    }
    
    // æ‰¹é‡é¢„æµ‹
    predictions := make([][]float32, 0, len(req.Inputs))
    for _, input := range req.Inputs {
        output, err := s.model.Predict(input)
        if err != nil {
            http.Error(w, err.Error(), http.StatusInternalServerError)
            return
        }
        predictions = append(predictions, output)
    }
    
    latency := time.Since(start).Milliseconds()
    
    resp := PredictResponse{
        Predictions: predictions,
        Latency:     latency,
    }
    
    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(resp)
}

func (s *InferenceServer) handleHealth(w http.ResponseWriter, r *http.Request) {
    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(map[string]string{
        "status": "healthy",
    })
}

func (s *InferenceServer) handleMetrics(w http.ResponseWriter, r *http.Request) {
    // è¿”å›Prometheusæ ¼å¼çš„æŒ‡æ ‡
    w.Header().Set("Content-Type", "text/plain")
    fmt.Fprintf(w, "# HELP inference_requests_total Total number of inference requests\n")
    fmt.Fprintf(w, "# TYPE inference_requests_total counter\n")
    fmt.Fprintf(w, "inference_requests_total 123\n")
}

func (s *InferenceServer) Start(addr string) error {
    log.Printf("Starting inference server on %s", addr)
    return http.ListenAndServe(addr, s.router)
}
```

### gRPCæ¨ç†æœåŠ¡

```go
// inference.proto
/*
syntax = "proto3";

package inference;

service InferenceService {
    rpc Predict(PredictRequest) returns (PredictResponse);
    rpc PredictStream(stream PredictRequest) returns (stream PredictResponse);
}

message PredictRequest {
    repeated float inputs = 1;
}

message PredictResponse {
    repeated float outputs = 1;
    int64 latency_ms = 2;
}
*/

// grpc_server.go
package server

import (
    "context"
    "time"
    
    "google.golang.org/grpc"
    pb "inference/proto"
)

type GRPCServer struct {
    pb.UnimplementedInferenceServiceServer
    model Model
}

func NewGRPCServer(model Model) *GRPCServer {
    return &GRPCServer{model: model}
}

func (s *GRPCServer) Predict(ctx context.Context, req *pb.PredictRequest) (*pb.PredictResponse, error) {
    start := time.Now()
    
    output, err := s.model.Predict(req.Inputs)
    if err != nil {
        return nil, err
    }
    
    latency := time.Since(start).Milliseconds()
    
    return &pb.PredictResponse{
        Outputs:   output,
        LatencyMs: latency,
    }, nil
}

func (s *GRPCServer) PredictStream(stream pb.InferenceService_PredictStreamServer) error {
    for {
        req, err := stream.Recv()
        if err == io.EOF {
            return nil
        }
        if err != nil {
            return err
        }
        
        start := time.Now()
        output, err := s.model.Predict(req.Inputs)
        if err != nil {
            return err
        }
        
        latency := time.Since(start).Milliseconds()
        
        if err := stream.Send(&pb.PredictResponse{
            Outputs:   output,
            LatencyMs: latency,
        }); err != nil {
            return err
        }
    }
}

func (s *GRPCServer) Start(addr string) error {
    lis, err := net.Listen("tcp", addr)
    if err != nil {
        return err
    }
    
    grpcServer := grpc.NewServer()
    pb.RegisterInferenceServiceServer(grpcServer, s)
    
    log.Printf("Starting gRPC server on %s", addr)
    return grpcServer.Serve(lis)
}
```

---

## 5. æ¨¡å‹éƒ¨ç½²

### å®¹å™¨åŒ–éƒ¨ç½²

```dockerfile
# Dockerfile
FROM golang:1.21-alpine AS builder

WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY go.mod go.sum ./
RUN go mod download

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN CGO_ENABLED=0 GOOS=linux go build -o /inference-server cmd/server/main.go

# è¿è¡Œé˜¶æ®µ
FROM alpine:latest

RUN apk --no-cache add ca-certificates

WORKDIR /root/

# å¤åˆ¶äºŒè¿›åˆ¶æ–‡ä»¶
COPY --from=builder /inference-server .

# å¤åˆ¶æ¨¡å‹æ–‡ä»¶
COPY models/ ./models/

# æš´éœ²ç«¯å£
EXPOSE 8080

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD wget --no-verbose --tries=1 --spider http://localhost:8080/health || exit 1

# å¯åŠ¨æœåŠ¡
CMD ["./inference-server"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  inference-server:
    build: .
    ports:
      - "8080:8080"
    volumes:
      - ./models:/root/models
    environment:
      - MODEL_PATH=/root/models/model.onnx
      - NUM_WORKERS=4
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
```

### æ¨¡å‹ç‰ˆæœ¬ç®¡ç†

```go
package model

import (
    "sync"
)

// ModelRegistry æ¨¡å‹æ³¨å†Œè¡¨
type ModelRegistry struct {
    models map[string]*ModelVersion
    mu     sync.RWMutex
}

type ModelVersion struct {
    Version string
    Model   Model
    Metrics *ModelMetrics
}

type ModelMetrics struct {
    RequestCount int64
    ErrorCount   int64
    AvgLatency   float64
}

func NewModelRegistry() *ModelRegistry {
    return &ModelRegistry{
        models: make(map[string]*ModelVersion),
    }
}

// Register æ³¨å†Œæ¨¡å‹
func (r *ModelRegistry) Register(name, version string, model Model) {
    r.mu.Lock()
    defer r.mu.Unlock()
    
    key := fmt.Sprintf("%s:%s", name, version)
    r.models[key] = &ModelVersion{
        Version: version,
        Model:   model,
        Metrics: &ModelMetrics{},
    }
}

// Get è·å–æ¨¡å‹
func (r *ModelRegistry) Get(name, version string) (*ModelVersion, error) {
    r.mu.RLock()
    defer r.mu.RUnlock()
    
    key := fmt.Sprintf("%s:%s", name, version)
    model, exists := r.models[key]
    if !exists {
        return nil, errors.New("model not found")
    }
    
    return model, nil
}

// GetLatest è·å–æœ€æ–°ç‰ˆæœ¬
func (r *ModelRegistry) GetLatest(name string) (*ModelVersion, error) {
    r.mu.RLock()
    defer r.mu.RUnlock()
    
    var latestVersion *ModelVersion
    for key, version := range r.models {
        if strings.HasPrefix(key, name+":") {
            if latestVersion == nil || version.Version > latestVersion.Version {
                latestVersion = version
            }
        }
    }
    
    if latestVersion == nil {
        return nil, errors.New("model not found")
    }
    
    return latestVersion, nil
}

// List åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
func (r *ModelRegistry) List() []string {
    r.mu.RLock()
    defer r.mu.RUnlock()
    
    keys := make([]string, 0, len(r.models))
    for key := range r.models {
        keys = append(keys, key)
    }
    
    return keys
}

// UpdateMetrics æ›´æ–°æŒ‡æ ‡
func (r *ModelRegistry) UpdateMetrics(name, version string, latency float64, success bool) {
    r.mu.Lock()
    defer r.mu.Unlock()
    
    key := fmt.Sprintf("%s:%s", name, version)
    if model, exists := r.models[key]; exists {
        model.Metrics.RequestCount++
        if !success {
            model.Metrics.ErrorCount++
        }
        
        // æ›´æ–°å¹³å‡å»¶è¿Ÿ
        oldAvg := model.Metrics.AvgLatency
        n := float64(model.Metrics.RequestCount)
        model.Metrics.AvgLatency = (oldAvg*(n-1) + latency) / n
    }
}
```

---

## 6. æ‰¹é‡é¢„æµ‹

### æ‰¹å¤„ç†å¼•æ“

```go
package batch

import (
    "context"
    "sync"
)

// BatchPredictor æ‰¹é‡é¢„æµ‹å™¨
type BatchPredictor struct {
    model      Model
    batchSize  int
    workers    int
}

type PredictionJob struct {
    ID     string
    Input  []float32
    Result chan PredictionResult
}

type PredictionResult struct {
    Output []float32
    Error  error
}

func NewBatchPredictor(model Model, batchSize, workers int) *BatchPredictor {
    return &BatchPredictor{
        model:     model,
        batchSize: batchSize,
        workers:   workers,
    }
}

// Process å¤„ç†æ‰¹é‡é¢„æµ‹
func (p *BatchPredictor) Process(ctx context.Context, jobs <-chan PredictionJob) {
    var wg sync.WaitGroup
    
    for i := 0; i < p.workers; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            p.worker(ctx, jobs)
        }()
    }
    
    wg.Wait()
}

func (p *BatchPredictor) worker(ctx context.Context, jobs <-chan PredictionJob) {
    batch := make([]PredictionJob, 0, p.batchSize)
    
    for {
        select {
        case <-ctx.Done():
            p.processBatch(batch)
            return
            
        case job, ok := <-jobs:
            if !ok {
                p.processBatch(batch)
                return
            }
            
            batch = append(batch, job)
            if len(batch) >= p.batchSize {
                p.processBatch(batch)
                batch = batch[:0]
            }
        }
    }
}

func (p *BatchPredictor) processBatch(jobs []PredictionJob) {
    if len(jobs) == 0 {
        return
    }
    
    for _, job := range jobs {
        output, err := p.model.Predict(job.Input)
        job.Result <- PredictionResult{
            Output: output,
            Error:  err,
        }
        close(job.Result)
    }
}
```

### åˆ†å¸ƒå¼é¢„æµ‹

```go
// DistributedPredictor åˆ†å¸ƒå¼é¢„æµ‹å™¨
type DistributedPredictor struct {
    workers []string // workerèŠ‚ç‚¹åœ°å€
    client  *http.Client
}

func NewDistributedPredictor(workers []string) *DistributedPredictor {
    return &DistributedPredictor{
        workers: workers,
        client: &http.Client{
            Timeout: 30 * time.Second,
        },
    }
}

// Predict åˆ†å¸ƒå¼é¢„æµ‹
func (p *DistributedPredictor) Predict(ctx context.Context, inputs [][]float32) ([][]float32, error) {
    // å°†è¾“å…¥åˆ†é…åˆ°ä¸åŒçš„worker
    chunks := p.chunkInputs(inputs, len(p.workers))
    
    var wg sync.WaitGroup
    results := make([][]float32, len(inputs))
    errors := make([]error, len(chunks))
    
    for i, chunk := range chunks {
        wg.Add(1)
        go func(workerIdx int, input [][]float32) {
            defer wg.Done()
            
            output, err := p.predictOnWorker(ctx, p.workers[workerIdx], input)
            if err != nil {
                errors[workerIdx] = err
                return
            }
            
            // å¤åˆ¶ç»“æœ
            startIdx := workerIdx * len(chunk)
            copy(results[startIdx:], output)
        }(i, chunk)
    }
    
    wg.Wait()
    
    // æ£€æŸ¥é”™è¯¯
    for _, err := range errors {
        if err != nil {
            return nil, err
        }
    }
    
    return results, nil
}

func (p *DistributedPredictor) predictOnWorker(ctx context.Context, workerURL string, inputs [][]float32) ([][]float32, error) {
    req := PredictRequest{Inputs: inputs}
    body, _ := json.Marshal(req)
    
    httpReq, err := http.NewRequestWithContext(ctx, "POST", workerURL+"/predict", bytes.NewReader(body))
    if err != nil {
        return nil, err
    }
    
    httpReq.Header.Set("Content-Type", "application/json")
    
    resp, err := p.client.Do(httpReq)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    
    var result PredictResponse
    if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
        return nil, err
    }
    
    return result.Predictions, nil
}

func (p *DistributedPredictor) chunkInputs(inputs [][]float32, numChunks int) [][][]float32 {
    chunkSize := (len(inputs) + numChunks - 1) / numChunks
    chunks := make([][][]float32, 0, numChunks)
    
    for i := 0; i < len(inputs); i += chunkSize {
        end := i + chunkSize
        if end > len(inputs) {
            end = len(inputs)
        }
        chunks = append(chunks, inputs[i:end])
    }
    
    return chunks
}
```

---

## 7. ç‰¹å¾å­˜å‚¨

### ç‰¹å¾Storeå®ç°

```go
package feature

import (
    "context"
    "encoding/json"
    "time"
    
    "github.com/go-redis/redis/v8"
)

// FeatureStore ç‰¹å¾å­˜å‚¨
type FeatureStore struct {
    redis *redis.Client
}

type Feature struct {
    EntityID  string                 `json:"entity_id"`
    Features  map[string]interface{} `json:"features"`
    Timestamp time.Time              `json:"timestamp"`
}

func NewFeatureStore(redisAddr string) *FeatureStore {
    client := redis.NewClient(&redis.Options{
        Addr: redisAddr,
    })
    
    return &FeatureStore{redis: client}
}

// Set å­˜å‚¨ç‰¹å¾
func (fs *FeatureStore) Set(ctx context.Context, entityID string, features map[string]interface{}) error {
    feature := Feature{
        EntityID:  entityID,
        Features:  features,
        Timestamp: time.Now(),
    }
    
    data, err := json.Marshal(feature)
    if err != nil {
        return err
    }
    
    key := fmt.Sprintf("feature:%s", entityID)
    return fs.redis.Set(ctx, key, data, 24*time.Hour).Err()
}

// Get è·å–ç‰¹å¾
func (fs *FeatureStore) Get(ctx context.Context, entityID string) (*Feature, error) {
    key := fmt.Sprintf("feature:%s", entityID)
    
    data, err := fs.redis.Get(ctx, key).Result()
    if err != nil {
        return nil, err
    }
    
    var feature Feature
    if err := json.Unmarshal([]byte(data), &feature); err != nil {
        return nil, err
    }
    
    return &feature, nil
}

// GetBatch æ‰¹é‡è·å–ç‰¹å¾
func (fs *FeatureStore) GetBatch(ctx context.Context, entityIDs []string) ([]*Feature, error) {
    keys := make([]string, len(entityIDs))
    for i, id := range entityIDs {
        keys[i] = fmt.Sprintf("feature:%s", id)
    }
    
    results, err := fs.redis.MGet(ctx, keys...).Result()
    if err != nil {
        return nil, err
    }
    
    features := make([]*Feature, 0, len(results))
    for _, result := range results {
        if result == nil {
            continue
        }
        
        var feature Feature
        if err := json.Unmarshal([]byte(result.(string)), &feature); err != nil {
            continue
        }
        
        features = append(features, &feature)
    }
    
    return features, nil
}
```

### ç‰¹å¾ç®¡é“

```go
// FeaturePipeline ç‰¹å¾ç®¡é“
type FeaturePipeline struct {
    extractors []FeatureExtractor
    store      *FeatureStore
}

type FeatureExtractor interface {
    Extract(ctx context.Context, entityID string) (map[string]interface{}, error)
}

func NewFeaturePipeline(store *FeatureStore) *FeaturePipeline {
    return &FeaturePipeline{
        extractors: make([]FeatureExtractor, 0),
        store:      store,
    }
}

// AddExtractor æ·»åŠ ç‰¹å¾æå–å™¨
func (fp *FeaturePipeline) AddExtractor(extractor FeatureExtractor) {
    fp.extractors = append(fp.extractors, extractor)
}

// Process å¤„ç†ç‰¹å¾æå–
func (fp *FeaturePipeline) Process(ctx context.Context, entityID string) error {
    allFeatures := make(map[string]interface{})
    
    for _, extractor := range fp.extractors {
        features, err := extractor.Extract(ctx, entityID)
        if err != nil {
            log.Printf("Feature extraction failed: %v", err)
            continue
        }
        
        for k, v := range features {
            allFeatures[k] = v
        }
    }
    
    return fp.store.Set(ctx, entityID, allFeatures)
}

// ç”¨æˆ·ç‰¹å¾æå–å™¨ç¤ºä¾‹
type UserFeatureExtractor struct {
    db *sql.DB
}

func (e *UserFeatureExtractor) Extract(ctx context.Context, entityID string) (map[string]interface{}, error) {
    var age int
    var country string
    
    err := e.db.QueryRowContext(ctx, 
        "SELECT age, country FROM users WHERE id = $1", 
        entityID,
    ).Scan(&age, &country)
    if err != nil {
        return nil, err
    }
    
    return map[string]interface{}{
        "age":     age,
        "country": country,
    }, nil
}
```

---

## 8. æ¨¡å‹ç›‘æ§

### æ€§èƒ½ç›‘æ§

```go
package monitoring

import (
    "time"
    
    "github.com/prometheus/client_golang/prometheus"
)

// ModelMonitor æ¨¡å‹ç›‘æ§
type ModelMonitor struct {
    requestCount    *prometheus.CounterVec
    requestDuration *prometheus.HistogramVec
    predictionValue *prometheus.GaugeVec
}

func NewModelMonitor() *ModelMonitor {
    monitor := &ModelMonitor{
        requestCount: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "model_requests_total",
                Help: "Total number of prediction requests",
            },
            []string{"model", "version", "status"},
        ),
        requestDuration: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name:    "model_request_duration_seconds",
                Help:    "Prediction request duration",
                Buckets: prometheus.DefBuckets,
            },
            []string{"model", "version"},
        ),
        predictionValue: prometheus.NewGaugeVec(
            prometheus.GaugeOpts{
                Name: "model_prediction_value",
                Help: "Model prediction values",
            },
            []string{"model", "version"},
        ),
    }
    
    prometheus.MustRegister(
        monitor.requestCount,
        monitor.requestDuration,
        monitor.predictionValue,
    )
    
    return monitor
}

// RecordRequest è®°å½•è¯·æ±‚
func (m *ModelMonitor) RecordRequest(modelName, version, status string, duration time.Duration) {
    m.requestCount.WithLabelValues(modelName, version, status).Inc()
    m.requestDuration.WithLabelValues(modelName, version).Observe(duration.Seconds())
}

// RecordPrediction è®°å½•é¢„æµ‹å€¼
func (m *ModelMonitor) RecordPrediction(modelName, version string, value float64) {
    m.predictionValue.WithLabelValues(modelName, version).Set(value)
}
```

### æ•°æ®æ¼‚ç§»æ£€æµ‹

```go
// DriftDetector æ¼‚ç§»æ£€æµ‹å™¨
type DriftDetector struct {
    baseline     *Statistics
    threshold    float64
    windowSize   int
    currentData  []float64
}

type Statistics struct {
    Mean   float64
    StdDev float64
    Min    float64
    Max    float64
}

func NewDriftDetector(baseline *Statistics, threshold float64, windowSize int) *DriftDetector {
    return &DriftDetector{
        baseline:    baseline,
        threshold:   threshold,
        windowSize:  windowSize,
        currentData: make([]float64, 0, windowSize),
    }
}

// Add æ·»åŠ æ•°æ®ç‚¹
func (d *DriftDetector) Add(value float64) bool {
    d.currentData = append(d.currentData, value)
    
    if len(d.currentData) > d.windowSize {
        d.currentData = d.currentData[1:]
    }
    
    if len(d.currentData) == d.windowSize {
        return d.detectDrift()
    }
    
    return false
}

func (d *DriftDetector) detectDrift() bool {
    current := d.calculateStatistics()
    
    // è®¡ç®—KLæ•£åº¦æˆ–å…¶ä»–åº¦é‡
    meanDiff := math.Abs(current.Mean - d.baseline.Mean)
    stdDevDiff := math.Abs(current.StdDev - d.baseline.StdDev)
    
    drift := (meanDiff/d.baseline.Mean + stdDevDiff/d.baseline.StdDev) / 2
    
    if drift > d.threshold {
        log.Printf("Data drift detected: %.2f", drift)
        return true
    }
    
    return false
}

func (d *DriftDetector) calculateStatistics() *Statistics {
    if len(d.currentData) == 0 {
        return &Statistics{}
    }
    
    // è®¡ç®—å‡å€¼
    sum := 0.0
    min := d.currentData[0]
    max := d.currentData[0]
    
    for _, val := range d.currentData {
        sum += val
        if val < min {
            min = val
        }
        if val > max {
            max = val
        }
    }
    
    mean := sum / float64(len(d.currentData))
    
    // è®¡ç®—æ ‡å‡†å·®
    variance := 0.0
    for _, val := range d.currentData {
        diff := val - mean
        variance += diff * diff
    }
    stdDev := math.Sqrt(variance / float64(len(d.currentData)))
    
    return &Statistics{
        Mean:   mean,
        StdDev: stdDev,
        Min:    min,
        Max:    max,
    }
}
```

---

## 9. è‡ªç„¶è¯­è¨€å¤„ç†

### æ–‡æœ¬é¢„å¤„ç†

```go
package nlp

import (
    "regexp"
    "strings"
    "unicode"
)

// TextPreprocessor æ–‡æœ¬é¢„å¤„ç†å™¨
type TextPreprocessor struct {
    stopwords map[string]bool
}

func NewTextPreprocessor(stopwords []string) *TextPreprocessor {
    stopwordMap := make(map[string]bool)
    for _, word := range stopwords {
        stopwordMap[word] = true
    }
    
    return &TextPreprocessor{
        stopwords: stopwordMap,
    }
}

// Clean æ¸…ç†æ–‡æœ¬
func (p *TextPreprocessor) Clean(text string) string {
    // è½¬å°å†™
    text = strings.ToLower(text)
    
    // ç§»é™¤URL
    urlPattern := regexp.MustCompile(`https?://\S+`)
    text = urlPattern.ReplaceAllString(text, "")
    
    // ç§»é™¤é‚®ç®±
    emailPattern := regexp.MustCompile(`\S+@\S+`)
    text = emailPattern.ReplaceAllString(text, "")
    
    // ç§»é™¤ç‰¹æ®Šå­—ç¬¦
    text = strings.Map(func(r rune) rune {
        if unicode.IsLetter(r) || unicode.IsSpace(r) {
            return r
        }
        return -1
    }, text)
    
    return text
}

// Tokenize åˆ†è¯
func (p *TextPreprocessor) Tokenize(text string) []string {
    return strings.Fields(text)
}

// RemoveStopwords ç§»é™¤åœç”¨è¯
func (p *TextPreprocessor) RemoveStopwords(tokens []string) []string {
    filtered := make([]string, 0)
    for _, token := range tokens {
        if !p.stopwords[token] {
            filtered = append(filtered, token)
        }
    }
    return filtered
}

// Process å®Œæ•´å¤„ç†æµç¨‹
func (p *TextPreprocessor) Process(text string) []string {
    text = p.Clean(text)
    tokens := p.Tokenize(text)
    tokens = p.RemoveStopwords(tokens)
    return tokens
}

// TF-IDFå®ç°
type TFIDF struct {
    vocab map[string]int
    idf   map[string]float64
}

func NewTFIDF() *TFIDF {
    return &TFIDF{
        vocab: make(map[string]int),
        idf:   make(map[string]float64),
    }
}

// Fit è®­ç»ƒ
func (t *TFIDF) Fit(documents [][]string) {
    // æ„å»ºè¯æ±‡è¡¨
    for _, doc := range documents {
        seen := make(map[string]bool)
        for _, word := range doc {
            if !seen[word] {
                t.vocab[word]++
                seen[word] = true
            }
        }
    }
    
    // è®¡ç®—IDF
    numDocs := float64(len(documents))
    for word, df := range t.vocab {
        t.idf[word] = math.Log(numDocs / float64(df))
    }
}

// Transform è½¬æ¢
func (t *TFIDF) Transform(documents [][]string) [][]float64 {
    result := make([][]float64, len(documents))
    
    for i, doc := range documents {
        tf := make(map[string]float64)
        for _, word := range doc {
            tf[word]++
        }
        
        // å½’ä¸€åŒ–TF
        for word := range tf {
            tf[word] /= float64(len(doc))
        }
        
        // è®¡ç®—TF-IDF
        vector := make([]float64, len(t.vocab))
        j := 0
        for word := range t.vocab {
            if idf, exists := t.idf[word]; exists {
                vector[j] = tf[word] * idf
            }
            j++
        }
        
        result[i] = vector
    }
    
    return result
}
```

### æƒ…æ„Ÿåˆ†ææœåŠ¡

```go
// SentimentAnalyzer æƒ…æ„Ÿåˆ†æå™¨
type SentimentAnalyzer struct {
    preprocessor *TextPreprocessor
    model        Model
}

type SentimentResult struct {
    Text      string  `json:"text"`
    Sentiment string  `json:"sentiment"` // positive, negative, neutral
    Score     float64 `json:"score"`
}

func NewSentimentAnalyzer(preprocessor *TextPreprocessor, model Model) *SentimentAnalyzer {
    return &SentimentAnalyzer{
        preprocessor: preprocessor,
        model:        model,
    }
}

// Analyze åˆ†ææƒ…æ„Ÿ
func (sa *SentimentAnalyzer) Analyze(text string) (*SentimentResult, error) {
    // é¢„å¤„ç†
    tokens := sa.preprocessor.Process(text)
    
    // ç‰¹å¾æå–ï¼ˆç®€åŒ–ç‰ˆï¼‰
    features := sa.extractFeatures(tokens)
    
    // æ¨¡å‹é¢„æµ‹
    output, err := sa.model.Predict(features)
    if err != nil {
        return nil, err
    }
    
    // è§£æç»“æœ
    sentiment, score := sa.parseOutput(output)
    
    return &SentimentResult{
        Text:      text,
        Sentiment: sentiment,
        Score:     score,
    }, nil
}

func (sa *SentimentAnalyzer) extractFeatures(tokens []string) []float32 {
    // ç®€åŒ–çš„ç‰¹å¾æå–
    features := make([]float32, 100)
    for i, token := range tokens {
        if i >= len(features) {
            break
        }
        features[i] = float32(len(token))
    }
    return features
}

func (sa *SentimentAnalyzer) parseOutput(output []float32) (string, float64) {
    if len(output) < 3 {
        return "unknown", 0
    }
    
    maxIdx := 0
    maxVal := output[0]
    
    for i, val := range output {
        if val > maxVal {
            maxVal = val
            maxIdx = i
        }
    }
    
    sentiments := []string{"negative", "neutral", "positive"}
    return sentiments[maxIdx], float64(maxVal)
}
```

---

## 10. è®¡ç®—æœºè§†è§‰

### å›¾åƒé¢„å¤„ç†

```go
package cv

import (
    "image"
    "image/color"
    
    "gocv.io/x/gocv"
)

// ImagePreprocessor å›¾åƒé¢„å¤„ç†å™¨
type ImagePreprocessor struct {
    targetSize image.Point
}

func NewImagePreprocessor(width, height int) *ImagePreprocessor {
    return &ImagePreprocessor{
        targetSize: image.Point{X: width, Y: height},
    }
}

// Preprocess é¢„å¤„ç†å›¾åƒ
func (ip *ImagePreprocessor) Preprocess(img gocv.Mat) ([]float32, error) {
    // è°ƒæ•´å¤§å°
    resized := gocv.NewMat()
    defer resized.Close()
    gocv.Resize(img, &resized, ip.targetSize, 0, 0, gocv.InterpolationLinear)
    
    // å½’ä¸€åŒ–
    normalized := gocv.NewMat()
    defer normalized.Close()
    resized.ConvertTo(&normalized, gocv.MatTypeCV32F)
    normalized.DivideFloat(255.0)
    
    // è½¬æ¢ä¸ºæ•°ç»„
    data := make([]float32, ip.targetSize.X*ip.targetSize.Y*3)
    for y := 0; y < ip.targetSize.Y; y++ {
        for x := 0; x < ip.targetSize.X; x++ {
            pixel := normalized.GetVecfAt(y, x)
            idx := (y*ip.targetSize.X + x) * 3
            data[idx] = pixel[0]     // B
            data[idx+1] = pixel[1]   // G
            data[idx+2] = pixel[2]   // R
        }
    }
    
    return data, nil
}

// LoadImage åŠ è½½å›¾åƒ
func LoadImage(path string) (gocv.Mat, error) {
    img := gocv.IMRead(path, gocv.IMReadColor)
    if img.Empty() {
        return gocv.Mat{}, errors.New("failed to load image")
    }
    return img, nil
}

// SaveImage ä¿å­˜å›¾åƒ
func SaveImage(path string, img gocv.Mat) error {
    return gocv.IMWrite(path, img)
}
```

### ç›®æ ‡æ£€æµ‹æœåŠ¡

```go
// ObjectDetector ç›®æ ‡æ£€æµ‹å™¨
type ObjectDetector struct {
    preprocessor *ImagePreprocessor
    model        Model
    classes      []string
}

type Detection struct {
    Class      string    `json:"class"`
    Confidence float64   `json:"confidence"`
    BBox       BoundingBox `json:"bbox"`
}

type BoundingBox struct {
    X      int `json:"x"`
    Y      int `json:"y"`
    Width  int `json:"width"`
    Height int `json:"height"`
}

func NewObjectDetector(preprocessor *ImagePreprocessor, model Model, classes []string) *ObjectDetector {
    return &ObjectDetector{
        preprocessor: preprocessor,
        model:        model,
        classes:      classes,
    }
}

// Detect æ£€æµ‹ç›®æ ‡
func (od *ObjectDetector) Detect(img gocv.Mat) ([]Detection, error) {
    // é¢„å¤„ç†
    input, err := od.preprocessor.Preprocess(img)
    if err != nil {
        return nil, err
    }
    
    // æ¨¡å‹æ¨ç†
    output, err := od.model.Predict(input)
    if err != nil {
        return nil, err
    }
    
    // è§£æè¾“å‡º
    detections := od.parseOutput(output, img.Cols(), img.Rows())
    
    return detections, nil
}

func (od *ObjectDetector) parseOutput(output []float32, imgWidth, imgHeight int) []Detection {
    // ç®€åŒ–çš„è¾“å‡ºè§£æï¼ˆå®é™…éœ€è¦æ ¹æ®æ¨¡å‹æ ¼å¼è°ƒæ•´ï¼‰
    detections := make([]Detection, 0)
    
    // å‡è®¾è¾“å‡ºæ ¼å¼: [class_id, confidence, x, y, w, h, ...]
    numDetections := len(output) / 6
    
    for i := 0; i < numDetections; i++ {
        idx := i * 6
        classID := int(output[idx])
        confidence := float64(output[idx+1])
        
        if confidence < 0.5 {
            continue
        }
        
        x := int(output[idx+2] * float32(imgWidth))
        y := int(output[idx+3] * float32(imgHeight))
        w := int(output[idx+4] * float32(imgWidth))
        h := int(output[idx+5] * float32(imgHeight))
        
        detections = append(detections, Detection{
            Class:      od.classes[classID],
            Confidence: confidence,
            BBox: BoundingBox{
                X:      x,
                Y:      y,
                Width:  w,
                Height: h,
            },
        })
    }
    
    return detections
}

// DrawDetections ç»˜åˆ¶æ£€æµ‹ç»“æœ
func (od *ObjectDetector) DrawDetections(img gocv.Mat, detections []Detection) {
    for _, det := range detections {
        // ç»˜åˆ¶è¾¹ç•Œæ¡†
        rect := image.Rect(
            det.BBox.X,
            det.BBox.Y,
            det.BBox.X+det.BBox.Width,
            det.BBox.Y+det.BBox.Height,
        )
        gocv.Rectangle(&img, rect, color.RGBA{0, 255, 0, 0}, 2)
        
        // ç»˜åˆ¶æ ‡ç­¾
        label := fmt.Sprintf("%s: %.2f", det.Class, det.Confidence)
        gocv.PutText(&img, label, 
            image.Point{X: det.BBox.X, Y: det.BBox.Y - 10},
            gocv.FontHersheyPlain, 1.2, color.RGBA{0, 255, 0, 0}, 2)
    }
}
```

---

## 11. å®æˆ˜é¡¹ç›®ï¼šå›¾åƒåˆ†ç±»API

### ç³»ç»Ÿæ¶æ„

```mermaid
graph TB
    Client[å®¢æˆ·ç«¯] --> NGINX[NGINX]
    NGINX --> API1[APIæœåŠ¡1]
    NGINX --> API2[APIæœåŠ¡2]
    NGINX --> API3[APIæœåŠ¡3]
    
    API1 --> Model[æ¨¡å‹æ¨ç†]
    API2 --> Model
    API3 --> Model
    
    Model --> ModelStore[(æ¨¡å‹å­˜å‚¨)]
    
    API1 --> Redis[(Redisç¼“å­˜)]
    API2 --> Redis
    API3 --> Redis
    
    API1 --> Prometheus[Prometheus]
    API2 --> Prometheus
    API3 --> Prometheus
    
    style NGINX fill:#e1f5fe
    style API1 fill:#fff3e0
    style Model fill:#f3e5f5
    style ModelStore fill:#e8f5e9
```

### æ ¸å¿ƒå®ç°

```go
// cmd/image-classifier/main.go
package main

import (
    "context"
    "log"
    "net/http"
    "os"
    "os/signal"
    "syscall"
    
    "image-classifier/internal/api"
    "image-classifier/internal/model"
    
    "github.com/gorilla/mux"
)

func main() {
    // åŠ è½½æ¨¡å‹
    inferenceModel, err := model.NewONNXModel("models/resnet50.onnx")
    if err != nil {
        log.Fatal(err)
    }
    defer inferenceModel.Close()
    
    // åˆ›å»ºAPIæœåŠ¡
    apiServer := api.NewImageClassifierAPI(inferenceModel)
    
    // è®¾ç½®è·¯ç”±
    router := mux.NewRouter()
    router.HandleFunc("/classify", apiServer.HandleClassify).Methods("POST")
    router.HandleFunc("/health", apiServer.HandleHealth).Methods("GET")
    
    // å¯åŠ¨æœåŠ¡å™¨
    srv := &http.Server{
        Addr:    ":8080",
        Handler: router,
    }
    
    go func() {
        log.Println("Server starting on :8080")
        if err := srv.ListenAndServe(); err != nil && err != http.ErrServerClosed {
            log.Fatal(err)
        }
    }()
    
    // ä¼˜é›…å…³é—­
    quit := make(chan os.Signal, 1)
    signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
    <-quit
    
    log.Println("Shutting down server...")
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()
    
    if err := srv.Shutdown(ctx); err != nil {
        log.Fatal(err)
    }
    
    log.Println("Server exited")
}
```

---

## 12. æ€§èƒ½ä¼˜åŒ–

1. **æ¨¡å‹ä¼˜åŒ–**
   - é‡åŒ–ï¼ˆINT8/FP16ï¼‰
   - å‰ªæ
   - è’¸é¦
   - ONNXä¼˜åŒ–

2. **æ¨ç†ä¼˜åŒ–**
   - æ‰¹å¤„ç†
   - æ¨¡å‹ç¼“å­˜
   - è¿æ¥æ± 
   - å¼‚æ­¥å¤„ç†

3. **èµ„æºç®¡ç†**
   - Goroutineæ± 
   - å†…å­˜å¤ç”¨
   - é›¶æ‹·è´
   - SIMDä¼˜åŒ–

---

## 13. æœ€ä½³å®è·µ

1. **æ¨¡å‹ç®¡ç†**
   - âœ… ç‰ˆæœ¬æ§åˆ¶
   - âœ… A/Bæµ‹è¯•
   - âœ… ç°åº¦å‘å¸ƒ
   - âœ… å›æ»šæœºåˆ¶

2. **ç›‘æ§å‘Šè­¦**
   - âœ… æ€§èƒ½æŒ‡æ ‡
   - âœ… ä¸šåŠ¡æŒ‡æ ‡
   - âœ… æ•°æ®æ¼‚ç§»
   - âœ… å¼‚å¸¸æ£€æµ‹

3. **å®‰å…¨æ€§**
   - âœ… è¾“å…¥éªŒè¯
   - âœ… æ¨¡å‹åŠ å¯†
   - âœ… APIé™æµ
   - âœ… è®¿é—®æ§åˆ¶

4. **å¯æ‰©å±•æ€§**
   - âœ… æ°´å¹³æ‰©å±•
   - âœ… è´Ÿè½½å‡è¡¡
   - âœ… ç¼“å­˜ç­–ç•¥
   - âœ… å®¹å™¨ç¼–æ’

---

## 14. å¼€æºé¡¹ç›®æ¨è

1. **Gonum**
   - åœ°å€: <https://github.com/gonum/gonum>
   - è¯´æ˜: Goç§‘å­¦è®¡ç®—åº“

2. **Gorgonia**
   - åœ°å€: <https://github.com/gorgonia/gorgonia>
   - è¯´æ˜: Goæœºå™¨å­¦ä¹ åº“

3. **GoCV**
   - åœ°å€: <https://github.com/hybridgroup/gocv>
   - è¯´æ˜: Goè®¡ç®—æœºè§†è§‰åº“

4. **Onnx-go**
   - åœ°å€: <https://github.com/owulveryck/onnx-go>
   - è¯´æ˜: Go ONNXå®ç°

5. **KFServing**
   - åœ°å€: <https://github.com/kserve/kserve>
   - è¯´æ˜: Kubernetesæ¨¡å‹æœåŠ¡

---

**æ–‡æ¡£ç»´æŠ¤è€…**: Go Documentation Team  
**æœ€åæ›´æ–°**: 2025å¹´10æœˆ24æ—¥  
**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ  
**é€‚ç”¨ç‰ˆæœ¬**: Go 1.21+
